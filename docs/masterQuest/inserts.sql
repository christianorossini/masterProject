-- MySQL dump 10.13  Distrib 5.7.28, for Linux (x86_64)
--
-- Host: localhost    Database: masterquestdb
-- ------------------------------------------------------
-- Server version	5.7.28-0ubuntu0.18.04.4

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Dumping data for table `ms_dtModel`
--

LOCK TABLES `ms_dtModel` WRITE;
/*!40000 ALTER TABLE `ms_dtModel` DISABLE KEYS */;
INSERT INTO `ms_dtModel` VALUES (2,'dt1.png','/**\r\n * Licensed to the Apache Software Foundation (ASF) under one or more\r\n * contributor license agreements.  See the NOTICE file distributed with\r\n * this work for additional information regarding copyright ownership.\r\n * The ASF licenses this file to You under the Apache License, Version 2.0\r\n * (the \"License\"); you may not use this file except in compliance with\r\n * the License.  You may obtain a copy of the License at\r\n *\r\n *     http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n\r\npackage org.apache.solr.search;\r\n\r\nimport org.apache.lucene.index.Term;\r\nimport org.apache.lucene.queryParser.ParseException;\r\nimport org.apache.lucene.queryParser.QueryParser;\r\nimport org.apache.lucene.search.BooleanClause;\r\nimport org.apache.lucene.search.BooleanQuery;\r\nimport org.apache.lucene.search.ConstantScoreQuery;\r\nimport org.apache.lucene.search.FuzzyQuery;\r\nimport org.apache.lucene.search.NumericRangeQuery;\r\nimport org.apache.lucene.search.PrefixQuery;\r\nimport org.apache.lucene.search.Query;\r\nimport org.apache.lucene.search.Sort;\r\nimport org.apache.lucene.search.SortField;\r\nimport org.apache.lucene.search.TermQuery;\r\nimport org.apache.lucene.search.TermRangeQuery;\r\nimport org.apache.lucene.search.WildcardQuery;\r\nimport org.apache.solr.common.SolrException;\r\nimport org.apache.solr.common.params.MapSolrParams;\r\nimport org.apache.solr.common.params.SolrParams;\r\nimport org.apache.solr.core.SolrCore;\r\nimport org.apache.solr.request.LocalSolrQueryRequest;\r\nimport org.apache.solr.request.SolrQueryRequest;\r\nimport org.apache.solr.schema.FieldType;\r\nimport org.apache.solr.schema.IndexSchema;\r\nimport org.apache.solr.schema.SchemaField;\r\nimport org.apache.solr.search.function.FunctionQuery;\r\nimport org.apache.solr.search.function.QueryValueSource;\r\nimport java.io.IOException;\r\nimport java.util.ArrayList;\r\nimport java.util.HashMap;\r\nimport java.util.List;\r\nimport java.util.Map;\r\n\r\n/**\r\n * Collection of static utilities useful for query parsing.\r\n *\r\n * @version $Id$\r\n */\r\npublic class QueryParsing {\r\n  public static final String OP = \"q.op\";  // the SolrParam used to override the QueryParser \"default operator\"\r\n  public static final String V = \"v\";      // value of this parameter\r\n  public static final String F = \"f\";      // field that a query or command pertains to\r\n  public static final String TYPE = \"type\";// type of this query or command\r\n  public static final String DEFTYPE = \"defType\"; // default type for any direct subqueries\r\n  public static final String LOCALPARAM_START = \"{!\";\r\n  public static final char LOCALPARAM_END = \'}\';\r\n  public static final String DOCID = \"_docid_\";\r\n  public static final String SCORE = \"score\";\r\n\r\n  // true if the value was specified by the \"v\" param (i.e. v=myval, or v=$param)\r\n  public static final String VAL_EXPLICIT = \"__VAL_EXPLICIT__\";\r\n\r\n\r\n  /**\r\n   * Helper utility for parsing a query using the Lucene QueryParser syntax.\r\n   *\r\n   * @param qs     query expression in standard Lucene syntax\r\n   * @param schema used for default operator (overridden by params) and passed to the query parser for field format analysis information\r\n   */\r\n  public static Query parseQuery(String qs, IndexSchema schema) {\r\n    return parseQuery(qs, null, schema);\r\n  }\r\n\r\n  /**\r\n   * Helper utility for parsing a query using the Lucene QueryParser syntax.\r\n   *\r\n   * @param qs           query expression in standard Lucene syntax\r\n   * @param defaultField default field used for unqualified search terms in the query expression\r\n   * @param schema       used for default operator (overridden by params) and passed to the query parser for field format analysis information\r\n   */\r\n  public static Query parseQuery(String qs, String defaultField, IndexSchema schema) {\r\n    try {\r\n      Query query = schema.getSolrQueryParser(defaultField).parse(qs);\r\n\r\n      if (SolrCore.log.isTraceEnabled()) {\r\n        SolrCore.log.trace(\"After QueryParser:\" + query);\r\n      }\r\n\r\n      return query;\r\n\r\n    } catch (ParseException e) {\r\n      SolrCore.log(e);\r\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error parsing Lucene query\", e);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Helper utility for parsing a query using the Lucene QueryParser syntax.\r\n   *\r\n   * @param qs           query expression in standard Lucene syntax\r\n   * @param defaultField default field used for unqualified search terms in the query expression\r\n   * @param params       used to determine the default operator, overriding the schema specified operator\r\n   * @param schema       used for default operator (overridden by params) and passed to the query parser for field format analysis information\r\n   */\r\n  public static Query parseQuery(String qs, String defaultField, SolrParams params, IndexSchema schema) {\r\n    try {\r\n      SolrQueryParser parser = schema.getSolrQueryParser(defaultField);\r\n      String opParam = params.get(OP);\r\n      if (opParam != null) {\r\n        parser.setDefaultOperator(\"AND\".equals(opParam) ? QueryParser.Operator.AND : QueryParser.Operator.OR);\r\n      }\r\n      Query query = parser.parse(qs);\r\n\r\n      if (SolrCore.log.isTraceEnabled()) {\r\n        SolrCore.log.trace(\"After QueryParser:\" + query);\r\n      }\r\n\r\n      return query;\r\n\r\n    } catch (ParseException e) {\r\n      SolrCore.log(e);\r\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Query parsing error: \" + e.getMessage(), e);\r\n    }\r\n  }\r\n\r\n\r\n  // note to self: something needs to detect infinite recursion when parsing queries\r\n  static int parseLocalParams(String txt, int start, Map<String, String> target, SolrParams params) throws ParseException {\r\n    int off = start;\r\n    if (!txt.startsWith(LOCALPARAM_START, off)) return start;\r\n    StrParser p = new StrParser(txt, start, txt.length());\r\n    p.pos += 2; // skip over \"{!\"\r\n\r\n    for (; ;) {\r\n      /*\r\n      if (p.pos>=txt.length()) {\r\n        throw new ParseException(\"Missing \'}\' parsing local params \'\" + txt + \'\"\');\r\n      }\r\n      */\r\n      char ch = p.peek();\r\n      if (ch == LOCALPARAM_END) {\r\n        return p.pos + 1;\r\n      }\r\n\r\n      String id = p.getId();\r\n      if (id.length() == 0) {\r\n        throw new ParseException(\"Expected identifier \'}\' parsing local params \'\" + txt + \'\"\');\r\n\r\n      }\r\n      String val = null;\r\n\r\n      ch = p.peek();\r\n      if (ch != \'=\') {\r\n        // single word... treat {!func} as type=func for easy lookup\r\n        val = id;\r\n        id = TYPE;\r\n      } else {\r\n        // saw equals, so read value\r\n        p.pos++;\r\n        ch = p.peek();\r\n        boolean deref = false;\r\n        if (ch == \'$\') {\r\n          p.pos++;\r\n          ch = p.peek();\r\n          deref = true;  // dereference whatever value is read by treating it as a variable name\r\n        }\r\n\r\n        if (ch == \'\\\"\' || ch == \'\\\'\') {\r\n          val = p.getQuotedString();\r\n        } else {\r\n          // read unquoted literal ended by whitespace or \'}\'\r\n          // there is no escaping.\r\n          int valStart = p.pos;\r\n          for (; ;) {\r\n            if (p.pos >= p.end) {\r\n              throw new ParseException(\"Missing end to unquoted value starting at \" + valStart + \" str=\'\" + txt + \"\'\");\r\n            }\r\n            char c = p.val.charAt(p.pos);\r\n            if (c == LOCALPARAM_END || Character.isWhitespace(c)) {\r\n              val = p.val.substring(valStart, p.pos);\r\n              break;\r\n            }\r\n            p.pos++;\r\n          }\r\n        }\r\n\r\n        if (deref) {  // dereference parameter\r\n          if (params != null) {\r\n            val = params.get(val);\r\n          }\r\n        }\r\n      }\r\n      if (target != null) target.put(id, val);\r\n    }\r\n  }\r\n\r\n  public static String encodeLocalParamVal(String val) {\r\n    int len = val.length();\r\n    int i = 0;\r\n    if (len > 0 && val.charAt(0) != \'$\') {\r\n      for (;i<len; i++) {\r\n        char ch = val.charAt(i);\r\n        if (Character.isWhitespace(ch) || ch==\'}\') break;\r\n      }\r\n    }\r\n\r\n    if (i>=len) return val;\r\n\r\n    // We need to enclose in quotes... but now we need to escape\r\n    StringBuilder sb = new StringBuilder(val.length() + 4);\r\n    sb.append(\'\\\'\');\r\n    for (i=0; i<len; i++) {\r\n      char ch = val.charAt(i);\r\n      if (ch==\'\\\'\') {\r\n        sb.append(\'\\\\\');\r\n      }\r\n      sb.append(ch);\r\n    }\r\n    sb.append(\'\\\'\');\r\n    return sb.toString();\r\n  }\r\n  \r\n\r\n  /**\r\n   * \"foo\" returns null\r\n   * \"{!prefix f=myfield}yes\" returns type=\"prefix\",f=\"myfield\",v=\"yes\"\r\n   * \"{!prefix f=myfield v=$p}\" returns type=\"prefix\",f=\"myfield\",v=params.get(\"p\")\r\n   */\r\n  public static SolrParams getLocalParams(String txt, SolrParams params) throws ParseException {\r\n    if (txt == null || !txt.startsWith(LOCALPARAM_START)) {\r\n      return null;\r\n    }\r\n    Map<String, String> localParams = new HashMap<String, String>();\r\n    int start = QueryParsing.parseLocalParams(txt, 0, localParams, params);\r\n\r\n    String val = localParams.get(V);\r\n    if (val == null) {\r\n      val = txt.substring(start);\r\n      localParams.put(V, val);\r\n    } else {\r\n      // localParams.put(VAL_EXPLICIT, \"true\");\r\n    }\r\n    return new MapSolrParams(localParams);\r\n  }\r\n\r\n\r\n  /**\r\n   * Returns null if the sortSpec is the standard sort desc.\r\n   * <p/>\r\n   * <p>\r\n   * The form of the sort specification string currently parsed is:\r\n   * </p>\r\n   * <pre>>\r\n   * SortSpec ::= SingleSort [, SingleSort]*\r\n   * SingleSort ::= <fieldname> SortDirection\r\n   * SortDirection ::= top | desc | bottom | asc\r\n   * </pre>\r\n   * Examples:\r\n   * <pre>\r\n   *   score desc               #normal sort by score (will return null)\r\n   *   weight bottom            #sort by weight ascending\r\n   *   weight desc              #sort by weight descending\r\n   *   height desc,weight desc  #sort by height descending, and use weight descending to break any ties\r\n   *   height desc,weight asc   #sort by height descending, using weight ascending as a tiebreaker\r\n   * </pre>\r\n   */\r\n  public static Sort parseSort(String sortSpec, SolrQueryRequest req) {\r\n    if (sortSpec == null || sortSpec.length() == 0) return null;\r\n    List<SortField> lst = new ArrayList<SortField>(4);\r\n\r\n    try {\r\n\r\n      StrParser sp = new StrParser(sortSpec);\r\n      while (sp.pos < sp.end) {\r\n        sp.eatws();\r\n\r\n        final int start = sp.pos;\r\n\r\n        // short circuit test for a really simple field name\r\n        String field = sp.getId(null);\r\n        Exception qParserException = null;\r\n\r\n        if (field == null || !Character.isWhitespace(sp.peekChar())) {\r\n          // let\'s try it as a function instead\r\n          field = null;\r\n          String funcStr = sp.val.substring(start);\r\n\r\n          QParser parser = QParser.getParser(funcStr, FunctionQParserPlugin.NAME, req);\r\n          Query q = null;\r\n          try {\r\n            if (parser instanceof FunctionQParser) {\r\n              FunctionQParser fparser = (FunctionQParser)parser;\r\n              fparser.setParseMultipleSources(false);\r\n              fparser.setParseToEnd(false);\r\n              \r\n              q = fparser.getQuery();\r\n              \r\n              if (fparser.localParams != null) {\r\n                if (fparser.valFollowedParams) {\r\n                  // need to find the end of the function query via the string parser\r\n                  int leftOver = fparser.sp.end - fparser.sp.pos;\r\n                  sp.pos = sp.end - leftOver;   // reset our parser to the same amount of leftover\r\n                } else {\r\n                  // the value was via the \"v\" param in localParams, so we need to find\r\n                  // the end of the local params themselves to pick up where we left off\r\n                  sp.pos = start + fparser.localParamsEnd;\r\n                }\r\n              } else {\r\n                // need to find the end of the function query via the string parser\r\n                int leftOver = fparser.sp.end - fparser.sp.pos;\r\n                sp.pos = sp.end - leftOver;   // reset our parser to the same amount of leftover\r\n              }\r\n            } else {\r\n              // A QParser that\'s not for function queries.\r\n              // It must have been specified via local params.\r\n              q = parser.getQuery();\r\n\r\n              assert parser.getLocalParams() != null;\r\n              sp.pos = start + parser.localParamsEnd;\r\n            }\r\n\r\n            Boolean top = sp.getSortDirection();\r\n            if (null != top) {\r\n              // we have a Query and a valid direction\r\n              if (q instanceof FunctionQuery) {\r\n                lst.add(((FunctionQuery)q).getValueSource().getSortField(top));\r\n              } else {\r\n                lst.add((new QueryValueSource(q, 0.0f)).getSortField(top));\r\n              }\r\n              continue;\r\n            }\r\n          } catch (IOException ioe) {\r\n            throw ioe;\r\n          } catch (Exception e) {\r\n            // hang onto this in case the string isn\'t a full field name either\r\n            qParserException = e;\r\n          }\r\n        }\r\n\r\n        // if we made it here, we either have a \"simple\" field name,\r\n        // or there was a problem parsing the string as a complex func/quer\r\n\r\n        if (field == null) {\r\n          // try again, simple rules for a field name with no whitespace\r\n          sp.pos = start;\r\n          field = sp.getSimpleString();\r\n        }\r\n        Boolean top = sp.getSortDirection();\r\n        if (null == top) {\r\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \r\n                                    \"Can\'t determine Sort Order: \" + sp);\r\n        }\r\n        \r\n        if (SCORE.equals(field)) {\r\n          if (top) {\r\n            lst.add(SortField.FIELD_SCORE);\r\n          } else {\r\n            lst.add(new SortField(null, SortField.SCORE, true));\r\n          }\r\n        } else if (DOCID.equals(field)) {\r\n          lst.add(new SortField(null, SortField.DOC, top));\r\n        } else {\r\n          // try to find the field\r\n          SchemaField sf = req.getSchema().getFieldOrNull(field);\r\n          if (null == sf) {\r\n            if (null != qParserException) {\r\n              throw new SolrException\r\n                (SolrException.ErrorCode.BAD_REQUEST,\r\n                 \"sort param could not be parsed as a query, and is not a \"+\r\n                 \"field that exists in the index: \" + field,\r\n                 qParserException);\r\n            }\r\n            throw new SolrException\r\n              (SolrException.ErrorCode.BAD_REQUEST,\r\n               \"sort param field can\'t be found: \" + field);\r\n          }\r\n          lst.add(sf.getSortField(top));\r\n        }\r\n      }\r\n\r\n    } catch (ParseException e) {\r\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"error in sort: \" + sortSpec, e);\r\n    } catch (IOException e) {\r\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"error in sort: \" + sortSpec, e);\r\n    }\r\n\r\n\r\n    // normalize a sort on score desc to null\r\n    if (lst.size()==1 && lst.get(0) == SortField.FIELD_SCORE) {\r\n      return null;\r\n    }\r\n\r\n    return new Sort(lst.toArray(new SortField[lst.size()]));\r\n  }\r\n\r\n\r\n\r\n  ///////////////////////////\r\n  ///////////////////////////\r\n  ///////////////////////////\r\n\r\n  static FieldType writeFieldName(String name, IndexSchema schema, Appendable out, int flags) throws IOException {\r\n    FieldType ft = null;\r\n    ft = schema.getFieldTypeNoEx(name);\r\n    out.append(name);\r\n    if (ft == null) {\r\n      out.append(\"(UNKNOWN FIELD \" + name + \')\');\r\n    }\r\n    out.append(\':\');\r\n    return ft;\r\n  }\r\n\r\n  static void writeFieldVal(String val, FieldType ft, Appendable out, int flags) throws IOException {\r\n    if (ft != null) {\r\n      try {\r\n        out.append(ft.indexedToReadable(val));\r\n      } catch (Exception e) {\r\n        out.append(\"EXCEPTION(val=\");\r\n        out.append(val);\r\n        out.append(\")\");\r\n      }\r\n    } else {\r\n      out.append(val);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * @see #toString(Query,IndexSchema)\r\n   */\r\n  public static void toString(Query query, IndexSchema schema, Appendable out, int flags) throws IOException {\r\n    boolean writeBoost = true;\r\n\r\n    if (query instanceof TermQuery) {\r\n      TermQuery q = (TermQuery) query;\r\n      Term t = q.getTerm();\r\n      FieldType ft = writeFieldName(t.field(), schema, out, flags);\r\n      writeFieldVal(t.text(), ft, out, flags);\r\n    } else if (query instanceof TermRangeQuery) {\r\n      TermRangeQuery q = (TermRangeQuery) query;\r\n      String fname = q.getField();\r\n      FieldType ft = writeFieldName(fname, schema, out, flags);\r\n      out.append(q.includesLower() ? \'[\' : \'{\');\r\n      String lt = q.getLowerTerm();\r\n      String ut = q.getUpperTerm();\r\n      if (lt == null) {\r\n        out.append(\'*\');\r\n      } else {\r\n        writeFieldVal(lt, ft, out, flags);\r\n      }\r\n\r\n      out.append(\" TO \");\r\n\r\n      if (ut == null) {\r\n        out.append(\'*\');\r\n      } else {\r\n        writeFieldVal(ut, ft, out, flags);\r\n      }\r\n\r\n      out.append(q.includesUpper() ? \']\' : \'}\');\r\n    } else if (query instanceof NumericRangeQuery) {\r\n      NumericRangeQuery q = (NumericRangeQuery) query;\r\n      String fname = q.getField();\r\n      FieldType ft = writeFieldName(fname, schema, out, flags);\r\n      out.append(q.includesMin() ? \'[\' : \'{\');\r\n      Number lt = q.getMin();\r\n      Number ut = q.getMax();\r\n      if (lt == null) {\r\n        out.append(\'*\');\r\n      } else {\r\n        out.append(lt.toString());\r\n      }\r\n\r\n      out.append(\" TO \");\r\n\r\n      if (ut == null) {\r\n        out.append(\'*\');\r\n      } else {\r\n        out.append(ut.toString());\r\n      }\r\n\r\n      out.append(q.includesMax() ? \']\' : \'}\');\r\n    } else if (query instanceof BooleanQuery) {\r\n      BooleanQuery q = (BooleanQuery) query;\r\n      boolean needParens = false;\r\n\r\n      if (q.getBoost() != 1.0 || q.getMinimumNumberShouldMatch() != 0) {\r\n        needParens = true;\r\n      }\r\n      if (needParens) {\r\n        out.append(\'(\');\r\n      }\r\n      boolean first = true;\r\n      for (BooleanClause c : q.clauses()) {\r\n        if (!first) {\r\n          out.append(\' \');\r\n        } else {\r\n          first = false;\r\n        }\r\n\r\n        if (c.isProhibited()) {\r\n          out.append(\'-\');\r\n        } else if (c.isRequired()) {\r\n          out.append(\'+\');\r\n        }\r\n        Query subQuery = c.getQuery();\r\n        boolean wrapQuery = false;\r\n\r\n        // TODO: may need to put parens around other types\r\n        // of queries too, depending on future syntax.\r\n        if (subQuery instanceof BooleanQuery) {\r\n          wrapQuery = true;\r\n        }\r\n\r\n        if (wrapQuery) {\r\n          out.append(\'(\');\r\n        }\r\n\r\n        toString(subQuery, schema, out, flags);\r\n\r\n        if (wrapQuery) {\r\n          out.append(\')\');\r\n        }\r\n      }\r\n\r\n      if (needParens) {\r\n        out.append(\')\');\r\n      }\r\n      if (q.getMinimumNumberShouldMatch() > 0) {\r\n        out.append(\'~\');\r\n        out.append(Integer.toString(q.getMinimumNumberShouldMatch()));\r\n      }\r\n\r\n    } else if (query instanceof PrefixQuery) {\r\n      PrefixQuery q = (PrefixQuery) query;\r\n      Term prefix = q.getPrefix();\r\n      FieldType ft = writeFieldName(prefix.field(), schema, out, flags);\r\n      out.append(prefix.text());\r\n      out.append(\'*\');\r\n    } else if (query instanceof ConstantScorePrefixQuery) {\r\n      ConstantScorePrefixQuery q = (ConstantScorePrefixQuery) query;\r\n      Term prefix = q.getPrefix();\r\n      FieldType ft = writeFieldName(prefix.field(), schema, out, flags);\r\n      out.append(prefix.text());\r\n      out.append(\'*\');\r\n    } else if (query instanceof WildcardQuery) {\r\n      out.append(query.toString());\r\n      writeBoost = false;\r\n    } else if (query instanceof FuzzyQuery) {\r\n      out.append(query.toString());\r\n      writeBoost = false;\r\n    } else if (query instanceof ConstantScoreQuery) {\r\n      out.append(query.toString());\r\n      writeBoost = false;\r\n    } else {\r\n      out.append(query.getClass().getSimpleName()\r\n              + \'(\' + query.toString() + \')\');\r\n      writeBoost = false;\r\n    }\r\n\r\n    if (writeBoost && query.getBoost() != 1.0f) {\r\n      out.append(\"^\");\r\n      out.append(Float.toString(query.getBoost()));\r\n    }\r\n\r\n  }\r\n\r\n  /**\r\n   * Formats a Query for debugging, using the IndexSchema to make\r\n   * complex field types readable.\r\n   * <p/>\r\n   * <p>\r\n   * The benefit of using this method instead of calling\r\n   * <code>Query.toString</code> directly is that it knows about the data\r\n   * types of each field, so any field which is encoded in a particularly\r\n   * complex way is still readable. The downside is that it only knows\r\n   * about built in Query types, and will not be able to format custom\r\n   * Query classes.\r\n   * </p>\r\n   */\r\n  public static String toString(Query query, IndexSchema schema) {\r\n    try {\r\n      StringBuilder sb = new StringBuilder();\r\n      toString(query, schema, sb, 0);\r\n      return sb.toString();\r\n    } catch (Exception e) {\r\n      throw new RuntimeException(e);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Simple class to help with parsing a string\r\n   * <b>Note: This API is experimental and may change in non backward-compatible ways in the future</b>\r\n   */\r\n  public static class StrParser {\r\n    String val;\r\n    int pos;\r\n    int end;\r\n\r\n    public StrParser(String val) {\r\n      this(val, 0, val.length());\r\n    }\r\n\r\n    public StrParser(String val, int start, int end) {\r\n      this.val = val;\r\n      this.pos = start;\r\n      this.end = end;\r\n    }\r\n\r\n    void eatws() {\r\n      while (pos < end && Character.isWhitespace(val.charAt(pos))) pos++;\r\n    }\r\n\r\n    char ch() {\r\n      return pos < end ? val.charAt(pos) : 0;\r\n    }\r\n\r\n    void skip(int nChars) {\r\n      pos = Math.max(pos + nChars, end);\r\n    }\r\n\r\n    boolean opt(String s) {\r\n      eatws();\r\n      int slen = s.length();\r\n      if (val.regionMatches(pos, s, 0, slen)) {\r\n        pos += slen;\r\n        return true;\r\n      }\r\n      return false;\r\n    }\r\n\r\n    boolean opt(char ch) {\r\n      eatws();\r\n      if (val.charAt(pos) == ch) {\r\n        pos++;\r\n        return true;\r\n      }\r\n      return false;\r\n    }\r\n\r\n\r\n    void expect(String s) throws ParseException {\r\n      eatws();\r\n      int slen = s.length();\r\n      if (val.regionMatches(pos, s, 0, slen)) {\r\n        pos += slen;\r\n      } else {\r\n        throw new ParseException(\"Expected \'\" + s + \"\' at position \" + pos + \" in \'\" + val + \"\'\");\r\n      }\r\n    }\r\n\r\n    float getFloat() throws ParseException {\r\n      eatws();\r\n      char[] arr = new char[end - pos];\r\n      int i;\r\n      for (i = 0; i < arr.length; i++) {\r\n        char ch = val.charAt(pos);\r\n        if ((ch >= \'0\' && ch <= \'9\')\r\n                || ch == \'+\' || ch == \'-\'\r\n                || ch == \'.\' || ch == \'e\' || ch == \'E\'\r\n                ) {\r\n          pos++;\r\n          arr[i] = ch;\r\n        } else {\r\n          break;\r\n        }\r\n      }\r\n\r\n      return Float.parseFloat(new String(arr, 0, i));\r\n    }\r\n\r\n    Number getNumber() throws ParseException {\r\n      eatws();\r\n      int start = pos;\r\n      boolean flt = false;\r\n\r\n      while (pos < end) {\r\n        char ch = val.charAt(pos);\r\n        if ((ch >= \'0\' && ch <= \'9\') || ch == \'+\' || ch == \'-\') {\r\n          pos++;\r\n        } else if (ch == \'.\' || ch ==\'e\' || ch==\'E\') {\r\n          flt = true;\r\n          pos++;\r\n        } else {\r\n          break;\r\n        }\r\n      }\r\n\r\n      String v = val.substring(start,pos);\r\n      return flt ? Double.parseDouble(v) : Long.parseLong(v);\r\n    }\r\n\r\n    double getDouble() throws ParseException {\r\n      eatws();\r\n      char[] arr = new char[end - pos];\r\n      int i;\r\n      for (i = 0; i < arr.length; i++) {\r\n        char ch = val.charAt(pos);\r\n        if ((ch >= \'0\' && ch <= \'9\')\r\n                || ch == \'+\' || ch == \'-\'\r\n                || ch == \'.\' || ch == \'e\' || ch == \'E\'\r\n                ) {\r\n          pos++;\r\n          arr[i] = ch;\r\n        } else {\r\n          break;\r\n        }\r\n      }\r\n\r\n      return Double.parseDouble(new String(arr, 0, i));\r\n    }\r\n\r\n    int getInt() throws ParseException {\r\n      eatws();\r\n      char[] arr = new char[end - pos];\r\n      int i;\r\n      for (i = 0; i < arr.length; i++) {\r\n        char ch = val.charAt(pos);\r\n        if ((ch >= \'0\' && ch <= \'9\')\r\n                || ch == \'+\' || ch == \'-\'\r\n                ) {\r\n          pos++;\r\n          arr[i] = ch;\r\n        } else {\r\n          break;\r\n        }\r\n      }\r\n\r\n      return Integer.parseInt(new String(arr, 0, i));\r\n    }\r\n\r\n\r\n    String getId() throws ParseException {\r\n      return getId(\"Expected identifier\");\r\n    }\r\n\r\n    String getId(String errMessage) throws ParseException {\r\n      eatws();\r\n      int id_start = pos;\r\n      char ch;\r\n      if (pos < end && (ch = val.charAt(pos)) != \'$\' && Character.isJavaIdentifierStart(ch)) {\r\n        pos++;\r\n        while (pos < end) {\r\n          ch = val.charAt(pos);\r\n          if (!Character.isJavaIdentifierPart(ch) && ch != \'.\') {\r\n            break;\r\n          }\r\n          pos++;\r\n        }\r\n        return val.substring(id_start, pos);\r\n      }\r\n\r\n      if (errMessage != null) {\r\n        throw new ParseException(errMessage + \" at pos \" + pos + \" str=\'\" + val + \"\'\");\r\n      }\r\n      return null;\r\n    }\r\n\r\n    /**\r\n     * Skips leading whitespace and returns whatever sequence of non \r\n     * whitespace it can find (or hte empty string)\r\n     */\r\n    String getSimpleString() {\r\n      eatws();\r\n      int startPos = pos;\r\n      char ch;\r\n      while (pos < end) {\r\n        ch = val.charAt(pos);\r\n        if (Character.isWhitespace(ch)) break;\r\n        pos++;\r\n      }\r\n      return val.substring(startPos, pos);\r\n    }\r\n\r\n    /**\r\n     * Sort direction or null if current position does not inidcate a \r\n     * sort direction. (True is desc, False is asc).  \r\n     * Position is advanced to after the comma (or end) when result is non null \r\n     */\r\n    Boolean getSortDirection() throws ParseException {\r\n      final int startPos = pos;\r\n      final String order = getId(null);\r\n\r\n      Boolean top = null;\r\n\r\n      if (null != order) {\r\n        if (\"desc\".equals(order) || \"top\".equals(order)) {\r\n          top = true;\r\n        } else if (\"asc\".equals(order) || \"bottom\".equals(order)) {\r\n          top = false;\r\n        }\r\n\r\n        // it\'s not a legal direction if more stuff comes after it\r\n        eatws();\r\n        final char c = ch();\r\n        if (0 == c) {\r\n          // :NOOP\r\n        } else if (\',\' == c) {\r\n          pos++;\r\n        } else {\r\n          top = null;\r\n        }\r\n      }\r\n\r\n      if (null == top) pos = startPos; // no direction, reset\r\n      return top;\r\n    }\r\n\r\n    // return null if not a string\r\n    String getQuotedString() throws ParseException {\r\n      eatws();\r\n      char delim = peekChar();\r\n      if (!(delim == \'\\\"\' || delim == \'\\\'\')) {\r\n        return null;\r\n      }\r\n      int val_start = ++pos;\r\n      StringBuilder sb = new StringBuilder(); // needed for escaping\r\n      for (; ;) {\r\n        if (pos >= end) {\r\n          throw new ParseException(\"Missing end quote for string at pos \" + (val_start - 1) + \" str=\'\" + val + \"\'\");\r\n        }\r\n        char ch = val.charAt(pos);\r\n        if (ch == \'\\\\\') {\r\n          pos++;\r\n          if (pos >= end) break;\r\n          ch = val.charAt(pos);\r\n          switch (ch) {\r\n            case \'n\':\r\n              ch = \'\\n\';\r\n              break;\r\n            case \'t\':\r\n              ch = \'\\t\';\r\n              break;\r\n            case \'r\':\r\n              ch = \'\\r\';\r\n              break;\r\n            case \'b\':\r\n              ch = \'\\b\';\r\n              break;\r\n            case \'f\':\r\n              ch = \'\\f\';\r\n              break;\r\n            case \'u\':\r\n              if (pos + 4 >= end) {\r\n                throw new ParseException(\"bad unicode escape \\\\uxxxx at pos\" + (val_start - 1) + \" str=\'\" + val + \"\'\");\r\n              }\r\n              ch = (char) Integer.parseInt(val.substring(pos + 1, pos + 5), 16);\r\n              pos += 4;\r\n              break;\r\n          }\r\n        } else if (ch == delim) {\r\n          pos++;  // skip over the quote\r\n          break;\r\n        }\r\n        sb.append(ch);\r\n        pos++;\r\n      }\r\n\r\n      return sb.toString();\r\n    }\r\n\r\n    // next non-whitespace char\r\n    char peek() {\r\n      eatws();\r\n      return pos < end ? val.charAt(pos) : 0;\r\n    }\r\n\r\n    // next char\r\n    char peekChar() {\r\n      return pos < end ? val.charAt(pos) : 0;\r\n    }\r\n\r\n    @Override\r\n    public String toString() {\r\n      return \"\'\" + val + \"\'\" + \", pos=\" + pos;\r\n    }\r\n\r\n  }\r\n\r\n  /**\r\n   * Builds a list of String which are stringified versions of a list of Queries\r\n   */\r\n  public static List<String> toString(List<Query> queries, IndexSchema schema) {\r\n    List<String> out = new ArrayList<String>(queries.size());\r\n    for (Query q : queries) {\r\n      out.add(QueryParsing.toString(q, schema));\r\n    }\r\n    return out;\r\n  }\r\n\r\n  /**\r\n   * Parse a function, returning a FunctionQuery\r\n   * <p/>\r\n   * <p>\r\n   * Syntax Examples....\r\n   * </p>\r\n   * <p/>\r\n   * <pre>\r\n   * // Numeric fields default to correct type\r\n   * // (ie: IntFieldSource or FloatFieldSource)\r\n   * // Others use explicit ord(...) to generate numeric field value\r\n   * myfield\r\n   * <p/>\r\n   * // OrdFieldSource\r\n   * ord(myfield)\r\n   * <p/>\r\n   * // ReverseOrdFieldSource\r\n   * rord(myfield)\r\n   * <p/>\r\n   * // LinearFloatFunction on numeric field value\r\n   * linear(myfield,1,2)\r\n   * <p/>\r\n   * // MaxFloatFunction of LinearFloatFunction on numeric field value or constant\r\n   * max(linear(myfield,1,2),100)\r\n   * <p/>\r\n   * // ReciprocalFloatFunction on numeric field value\r\n   * recip(myfield,1,2,3)\r\n   * <p/>\r\n   * // ReciprocalFloatFunction on ReverseOrdFieldSource\r\n   * recip(rord(myfield),1,2,3)\r\n   * <p/>\r\n   * // ReciprocalFloatFunction on LinearFloatFunction on ReverseOrdFieldSource\r\n   * recip(linear(rord(myfield),1,2),3,4,5)\r\n   * </pre>\r\n   */\r\n  public static FunctionQuery parseFunction(String func, IndexSchema schema) throws ParseException {\r\n    SolrCore core = SolrCore.getSolrCore();\r\n    return (FunctionQuery) (QParser.getParser(func, \"func\", new LocalSolrQueryRequest(core, new HashMap())).parse());\r\n    // return new FunctionQuery(parseValSource(new StrParser(func), schema));\r\n  }\r\n\r\n}','lucene','Public Class','org.apache.solr.search.QueryParsing',0,4,'cdsbp'),(3,'dt2.png','/* to you under the Apache License, Version 2.0 (the\r\n * \"License\"); you may not use this file except in compliance\r\n * with the License.  You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing,\r\n * software distributed under the License is distributed on an\r\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\n * KIND, either express or implied.  See the License for the\r\n * specific language governing permissions and limitations\r\n * under the License.\r\n *\r\n */\r\n\r\npackage org.apache.cassandra.metrics;\r\n\r\nimport com.yammer.metrics.Metrics;\r\nimport com.yammer.metrics.core.Counter;\r\n\r\npublic class ClientRequestMetrics\r\n{\r\n    public static final Counter readTimeouts = Metrics.newCounter(ClientRequestMetrics.class, \"ReadTimeouts\");\r\n    public static final Counter writeTimeouts = Metrics.newCounter(ClientRequestMetrics.class, \"WriteTimeouts\");\r\n    public static final Counter readUnavailables = Metrics.newCounter(ClientRequestMetrics.class, \"ReadUnavailables\");\r\n    public static final Counter writeUnavailables = Metrics.newCounter(ClientRequestMetrics.class, \"WriteUnavailables\");\r\n}','cassandra','Public Class','org.apache.cassandra.metrics.ClientRequestMetrics',0,7,'cdsbp'),(4,'dt3.png','/**\r\n * Licensed to the Apache Software Foundation (ASF) under one or more\r\n * contributor license agreements.  See the NOTICE file distributed with\r\n * this work for additional information regarding copyright ownership.\r\n * The ASF licenses this file to You under the Apache License, Version 2.0\r\n * (the \"License\"); you may not use this file except in compliance with\r\n * the License.  You may obtain a copy of the License at\r\n *\r\n *     http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n\r\npackage org.apache.nutch.crawl;\r\n\r\nimport java.io.*;\r\nimport java.text.SimpleDateFormat;\r\nimport java.util.*;\r\n\r\n// Commons Logging imports\r\nimport org.slf4j.Logger;\r\nimport org.slf4j.LoggerFactory;\r\n\r\nimport org.apache.hadoop.io.*;\r\nimport org.apache.hadoop.fs.*;\r\nimport org.apache.hadoop.conf.*;\r\nimport org.apache.hadoop.mapred.*;\r\nimport org.apache.hadoop.util.*;\r\n\r\nimport org.apache.nutch.util.HadoopFSUtil;\r\nimport org.apache.nutch.util.LockUtil;\r\nimport org.apache.nutch.util.NutchConfiguration;\r\nimport org.apache.nutch.util.NutchJob;\r\nimport org.apache.nutch.util.TimingUtil;\r\n\r\n/**\r\n * This class takes the output of the fetcher and updates the\r\n * crawldb accordingly.\r\n */\r\npublic class CrawlDb extends Configured implements Tool {\r\n  public static final Logger LOG = LoggerFactory.getLogger(CrawlDb.class);\r\n\r\n  public static final String CRAWLDB_ADDITIONS_ALLOWED = \"db.update.additions.allowed\";\r\n\r\n  public static final String CRAWLDB_PURGE_404 = \"db.update.purge.404\";\r\n\r\n  public static final String CURRENT_NAME = \"current\";\r\n  \r\n  public static final String LOCK_NAME = \".locked\";\r\n  \r\n  public CrawlDb() {}\r\n  \r\n  public CrawlDb(Configuration conf) {\r\n    setConf(conf);\r\n  }\r\n\r\n  public void update(Path crawlDb, Path[] segments, boolean normalize, boolean filter) throws IOException {\r\n    boolean additionsAllowed = getConf().getBoolean(CRAWLDB_ADDITIONS_ALLOWED, true);\r\n    update(crawlDb, segments, normalize, filter, additionsAllowed, false);\r\n  }\r\n  \r\n  public void update(Path crawlDb, Path[] segments, boolean normalize, boolean filter, boolean additionsAllowed, boolean force) throws IOException {\r\n    FileSystem fs = FileSystem.get(getConf());\r\n    Path lock = new Path(crawlDb, LOCK_NAME);\r\n    LockUtil.createLockFile(fs, lock, force);\r\n    SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\r\n    long start = System.currentTimeMillis();\r\n\r\n    JobConf job = CrawlDb.createJob(getConf(), crawlDb);\r\n    job.setBoolean(CRAWLDB_ADDITIONS_ALLOWED, additionsAllowed);\r\n    job.setBoolean(CrawlDbFilter.URL_FILTERING, filter);\r\n    job.setBoolean(CrawlDbFilter.URL_NORMALIZING, normalize);\r\n\r\n    boolean url404Purging = job.getBoolean(CRAWLDB_PURGE_404, false);\r\n\r\n    if (LOG.isInfoEnabled()) {\r\n      LOG.info(\"CrawlDb update: starting at \" + sdf.format(start));\r\n      LOG.info(\"CrawlDb update: db: \" + crawlDb);\r\n      LOG.info(\"CrawlDb update: segments: \" + Arrays.asList(segments));\r\n      LOG.info(\"CrawlDb update: additions allowed: \" + additionsAllowed);\r\n      LOG.info(\"CrawlDb update: URL normalizing: \" + normalize);\r\n      LOG.info(\"CrawlDb update: URL filtering: \" + filter);\r\n      LOG.info(\"CrawlDb update: 404 purging: \" + url404Purging);\r\n    }\r\n\r\n    for (int i = 0; i < segments.length; i++) {\r\n      Path fetch = new Path(segments[i], CrawlDatum.FETCH_DIR_NAME);\r\n      Path parse = new Path(segments[i], CrawlDatum.PARSE_DIR_NAME);\r\n      if (fs.exists(fetch) && fs.exists(parse)) {\r\n        FileInputFormat.addInputPath(job, fetch);\r\n        FileInputFormat.addInputPath(job, parse);\r\n      } else {\r\n        LOG.info(\" - skipping invalid segment \" + segments[i]);\r\n      }\r\n    }\r\n\r\n    if (LOG.isInfoEnabled()) {\r\n      LOG.info(\"CrawlDb update: Merging segment data into db.\");\r\n    }\r\n    try {\r\n      JobClient.runJob(job);\r\n    } catch (IOException e) {\r\n      LockUtil.removeLockFile(fs, lock);\r\n      Path outPath = FileOutputFormat.getOutputPath(job);\r\n      if (fs.exists(outPath) ) fs.delete(outPath, true);\r\n      throw e;\r\n    }\r\n\r\n    CrawlDb.install(job, crawlDb);\r\n    long end = System.currentTimeMillis();\r\n    LOG.info(\"CrawlDb update: finished at \" + sdf.format(end) + \", elapsed: \" + TimingUtil.elapsedTime(start, end));\r\n  }\r\n\r\n  public static JobConf createJob(Configuration config, Path crawlDb)\r\n    throws IOException {\r\n    Path newCrawlDb =\r\n      new Path(crawlDb,\r\n               Integer.toString(new Random().nextInt(Integer.MAX_VALUE)));\r\n\r\n    JobConf job = new NutchJob(config);\r\n    job.setJobName(\"crawldb \" + crawlDb);\r\n\r\n\r\n    Path current = new Path(crawlDb, CURRENT_NAME);\r\n    if (FileSystem.get(job).exists(current)) {\r\n      FileInputFormat.addInputPath(job, current);\r\n    }\r\n    job.setInputFormat(SequenceFileInputFormat.class);\r\n\r\n    job.setMapperClass(CrawlDbFilter.class);\r\n    job.setReducerClass(CrawlDbReducer.class);\r\n\r\n    FileOutputFormat.setOutputPath(job, newCrawlDb);\r\n    job.setOutputFormat(MapFileOutputFormat.class);\r\n    job.setOutputKeyClass(Text.class);\r\n    job.setOutputValueClass(CrawlDatum.class);\r\n\r\n    // https://issues.apache.org/jira/browse/NUTCH-1110\r\n    job.setBoolean(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\", false);\r\n\r\n    return job;\r\n  }\r\n\r\n  public static void install(JobConf job, Path crawlDb) throws IOException {\r\n    Path newCrawlDb = FileOutputFormat.getOutputPath(job);\r\n    FileSystem fs = new JobClient(job).getFs();\r\n    Path old = new Path(crawlDb, \"old\");\r\n    Path current = new Path(crawlDb, CURRENT_NAME);\r\n    if (fs.exists(current)) {\r\n      if (fs.exists(old)) fs.delete(old, true);\r\n      fs.rename(current, old);\r\n    }\r\n    fs.mkdirs(crawlDb);\r\n    fs.rename(newCrawlDb, current);\r\n    if (fs.exists(old)) fs.delete(old, true);\r\n    Path lock = new Path(crawlDb, LOCK_NAME);\r\n    LockUtil.removeLockFile(fs, lock);\r\n  }\r\n\r\n  public static void main(String[] args) throws Exception {\r\n    int res = ToolRunner.run(NutchConfiguration.create(), new CrawlDb(), args);\r\n    System.exit(res);\r\n  }\r\n\r\n  public int run(String[] args) throws Exception {\r\n    if (args.length < 2) {\r\n      System.err.println(\"Usage: CrawlDb <crawldb> (-dir <segments> | <seg1> <seg2> ...) [-force] [-normalize] [-filter] [-noAdditions]\");\r\n      System.err.println(\"\\tcrawldb\\tCrawlDb to update\");\r\n      System.err.println(\"\\t-dir segments\\tparent directory containing all segments to update from\");\r\n      System.err.println(\"\\tseg1 seg2 ...\\tlist of segment names to update from\");\r\n      System.err.println(\"\\t-force\\tforce update even if CrawlDb appears to be locked (CAUTION advised)\");\r\n      System.err.println(\"\\t-normalize\\tuse URLNormalizer on urls in CrawlDb and segment (usually not needed)\");\r\n      System.err.println(\"\\t-filter\\tuse URLFilters on urls in CrawlDb and segment\");\r\n      System.err.println(\"\\t-noAdditions\\tonly update already existing URLs, don\'t add any newly discovered URLs\");\r\n\r\n      return -1;\r\n    }\r\n    boolean normalize = false;\r\n    boolean filter = false;\r\n    boolean force = false;\r\n    boolean url404Purging = false;\r\n    final FileSystem fs = FileSystem.get(getConf());\r\n    boolean additionsAllowed = getConf().getBoolean(CRAWLDB_ADDITIONS_ALLOWED, true);\r\n    HashSet<Path> dirs = new HashSet<Path>();\r\n    for (int i = 1; i < args.length; i++) {\r\n      if (args[i].equals(\"-normalize\")) {\r\n        normalize = true;\r\n      } else if (args[i].equals(\"-filter\")) {\r\n        filter = true;\r\n      } else if (args[i].equals(\"-force\")) {\r\n        force = true;\r\n      } else if (args[i].equals(\"-noAdditions\")) {\r\n        additionsAllowed = false;\r\n      } else if (args[i].equals(\"-dir\")) {\r\n        FileStatus[] paths = fs.listStatus(new Path(args[++i]), HadoopFSUtil.getPassDirectoriesFilter(fs));\r\n        dirs.addAll(Arrays.asList(HadoopFSUtil.getPaths(paths)));\r\n      } else {\r\n        dirs.add(new Path(args[i]));\r\n      }\r\n    }\r\n    try {\r\n      update(new Path(args[0]), dirs.toArray(new Path[dirs.size()]), normalize, filter, additionsAllowed, force);\r\n      return 0;\r\n    } catch (Exception e) {\r\n      LOG.error(\"CrawlDb update: \" + StringUtils.stringifyException(e));\r\n      return -1;\r\n    }\r\n  }\r\n}','nutch','Public Class','org.apache.nutch.crawl.CrawlDb',0,10,'cdsbp'),(5,'dt4.png','/*\r\n *  Licensed to the Apache Software Foundation (ASF) under one or more\r\n *  contributor license agreements.  See the NOTICE file distributed with\r\n *  this work for additional information regarding copyright ownership.\r\n *  The ASF licenses this file to You under the Apache License, Version 2.0\r\n *  (the \"License\"); you may not use this file except in compliance with\r\n *  the License.  You may obtain a copy of the License at\r\n *\r\n *      http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n *  Unless required by applicable law or agreed to in writing, software\r\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\r\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n *  See the License for the specific language governing permissions and\r\n *  limitations under the License.\r\n *\r\n */\r\npackage org.apache.tools.ant;\r\n\r\nimport java.io.File;\r\nimport java.io.IOException;\r\nimport java.io.EOFException;\r\nimport java.io.InputStream;\r\nimport java.lang.reflect.Method;\r\nimport java.lang.reflect.Modifier;\r\nimport java.util.Collections;\r\nimport java.util.Enumeration;\r\nimport java.util.Hashtable;\r\nimport java.util.Properties;\r\nimport java.util.Stack;\r\nimport java.util.Vector;\r\nimport java.util.Set;\r\nimport java.util.HashSet;\r\nimport java.util.HashMap;\r\nimport java.util.Map;\r\nimport java.util.WeakHashMap;\r\nimport org.apache.tools.ant.input.DefaultInputHandler;\r\nimport org.apache.tools.ant.input.InputHandler;\r\nimport org.apache.tools.ant.helper.DefaultExecutor;\r\nimport org.apache.tools.ant.types.FilterSet;\r\nimport org.apache.tools.ant.types.FilterSetCollection;\r\nimport org.apache.tools.ant.types.Description;\r\nimport org.apache.tools.ant.types.Path;\r\nimport org.apache.tools.ant.types.Resource;\r\nimport org.apache.tools.ant.types.ResourceFactory;\r\nimport org.apache.tools.ant.types.resources.FileResource;\r\nimport org.apache.tools.ant.util.CollectionUtils;\r\nimport org.apache.tools.ant.util.FileUtils;\r\nimport org.apache.tools.ant.util.JavaEnvUtils;\r\nimport org.apache.tools.ant.util.StringUtils;\r\nimport org.apache.tools.ant.util.VectorSet;\r\n\r\n/**\r\n * Central representation of an Ant project. This class defines an\r\n * Ant project with all of its targets, tasks and various other\r\n * properties. It also provides the mechanism to kick off a build using\r\n * a particular target name.\r\n * <p>\r\n * This class also encapsulates methods which allow files to be referred\r\n * to using abstract path names which are translated to native system\r\n * file paths at runtime.\r\n *\r\n */\r\npublic class Project implements ResourceFactory {\r\n    /** Message priority of &quot;error&quot;. */\r\n    public static final int MSG_ERR = 0;\r\n    /** Message priority of &quot;warning&quot;. */\r\n    public static final int MSG_WARN = 1;\r\n    /** Message priority of &quot;information&quot;. */\r\n    public static final int MSG_INFO = 2;\r\n    /** Message priority of &quot;verbose&quot;. */\r\n    public static final int MSG_VERBOSE = 3;\r\n    /** Message priority of &quot;debug&quot;. */\r\n    public static final int MSG_DEBUG = 4;\r\n\r\n    /**\r\n     * Constant for the &quot;visiting&quot; state, used when\r\n     * traversing a DFS of target dependencies.\r\n     */\r\n    private static final String VISITING = \"VISITING\";\r\n    /**\r\n     * Constant for the &quot;visited&quot; state, used when\r\n     * traversing a DFS of target dependencies.\r\n     */\r\n    private static final String VISITED = \"VISITED\";\r\n\r\n    /**\r\n     * Version constant for Java 1.0 .\r\n     *\r\n     * @deprecated since 1.5.x.\r\n     *             Use {@link JavaEnvUtils#JAVA_1_0} instead.\r\n     */\r\n    public static final String JAVA_1_0 = JavaEnvUtils.JAVA_1_0;\r\n    /**\r\n     * Version constant for Java 1.1 .\r\n     *\r\n     * @deprecated since 1.5.x.\r\n     *             Use {@link JavaEnvUtils#JAVA_1_1} instead.\r\n     */\r\n    public static final String JAVA_1_1 = JavaEnvUtils.JAVA_1_1;\r\n    /**\r\n     * Version constant for Java 1.2 .\r\n     *\r\n     * @deprecated since 1.5.x.\r\n     *             Use {@link JavaEnvUtils#JAVA_1_2} instead.\r\n     */\r\n    public static final String JAVA_1_2 = JavaEnvUtils.JAVA_1_2;\r\n    /**\r\n     * Version constant for Java 1.3 .\r\n     *\r\n     * @deprecated since 1.5.x.\r\n     *             Use {@link JavaEnvUtils#JAVA_1_3} instead.\r\n     */\r\n    public static final String JAVA_1_3 = JavaEnvUtils.JAVA_1_3;\r\n    /**\r\n     * Version constant for Java 1.4 .\r\n     *\r\n     * @deprecated since 1.5.x.\r\n     *             Use {@link JavaEnvUtils#JAVA_1_4} instead.\r\n     */\r\n    public static final String JAVA_1_4 = JavaEnvUtils.JAVA_1_4;\r\n\r\n    /** Default filter start token. */\r\n    public static final String TOKEN_START = FilterSet.DEFAULT_TOKEN_START;\r\n    /** Default filter end token. */\r\n    public static final String TOKEN_END = FilterSet.DEFAULT_TOKEN_END;\r\n\r\n    /** Instance of a utility class to use for file operations. */\r\n    private static final FileUtils FILE_UTILS = FileUtils.getFileUtils();\r\n\r\n    /** Name of this project. */\r\n    private String name;\r\n    /** Description for this project (if any). */\r\n    private String description;\r\n\r\n\r\n    /** Map of references within the project (paths etc) (String to Object). */\r\n    private Hashtable references = new AntRefTable();\r\n\r\n    /** Map of id references - used for indicating broken build files */\r\n    private HashMap idReferences = new HashMap();\r\n\r\n    /** the parent project for old id resolution (if inheritreferences is set) */\r\n    private Project parentIdProject = null;\r\n\r\n    /** Name of the project\'s default target. */\r\n    private String defaultTarget;\r\n\r\n    /** Map from target names to targets (String to Target). */\r\n    private Hashtable targets = new Hashtable();\r\n    /** Set of global filters. */\r\n    private FilterSet globalFilterSet = new FilterSet();\r\n    {\r\n        // Initialize the globalFileSet\'s project\r\n        globalFilterSet.setProject(this);\r\n    }\r\n\r\n    /**\r\n     * Wrapper around globalFilterSet. This collection only ever\r\n     * contains one FilterSet, but the wrapper is needed in order to\r\n     * make it easier to use the FileUtils interface.\r\n     */\r\n    private FilterSetCollection globalFilters\r\n        = new FilterSetCollection(globalFilterSet);\r\n\r\n    /** Project base directory. */\r\n    private File baseDir;\r\n\r\n    /** lock object used when adding/removing listeners */\r\n    private final Object listenersLock = new Object();\r\n\r\n    /** List of listeners to notify of build events. */\r\n    private volatile BuildListener[] listeners = new BuildListener[0];\r\n\r\n    /** for each thread, record whether it is currently executing\r\n        messageLogged */\r\n    private final ThreadLocal isLoggingMessage = new ThreadLocal() {\r\n            protected Object initialValue() {\r\n                return Boolean.FALSE;\r\n            }\r\n        };\r\n\r\n    /**\r\n     * The Ant core classloader--may be <code>null</code> if using\r\n     * parent classloader.\r\n     */\r\n    private ClassLoader coreLoader = null;\r\n\r\n    /** Records the latest task to be executed on a thread. */\r\n    private final Map/*<Thread,Task>*/ threadTasks =\r\n        Collections.synchronizedMap(new WeakHashMap());\r\n\r\n    /** Records the latest task to be executed on a thread group. */\r\n    private final Map/*<ThreadGroup,Task>*/ threadGroupTasks\r\n        = Collections.synchronizedMap(new WeakHashMap());\r\n\r\n    /**\r\n     * Called to handle any input requests.\r\n     */\r\n    private InputHandler inputHandler = null;\r\n\r\n    /**\r\n     * The default input stream used to read any input.\r\n     */\r\n    private InputStream defaultInputStream = null;\r\n\r\n    /**\r\n     * Keep going flag.\r\n     */\r\n    private boolean keepGoingMode = false;\r\n\r\n    /**\r\n     * Set the input handler.\r\n     *\r\n     * @param handler the InputHandler instance to use for gathering input.\r\n     */\r\n    public void setInputHandler(InputHandler handler) {\r\n        inputHandler = handler;\r\n    }\r\n\r\n    /**\r\n     * Set the default System input stream. Normally this stream is set to\r\n     * System.in. This inputStream is used when no task input redirection is\r\n     * being performed.\r\n     *\r\n     * @param defaultInputStream the default input stream to use when input\r\n     *        is requested.\r\n     * @since Ant 1.6\r\n     */\r\n    public void setDefaultInputStream(InputStream defaultInputStream) {\r\n        this.defaultInputStream = defaultInputStream;\r\n    }\r\n\r\n    /**\r\n     * Get this project\'s input stream.\r\n     *\r\n     * @return the InputStream instance in use by this Project instance to\r\n     * read input.\r\n     */\r\n    public InputStream getDefaultInputStream() {\r\n        return defaultInputStream;\r\n    }\r\n\r\n    /**\r\n     * Retrieve the current input handler.\r\n     *\r\n     * @return the InputHandler instance currently in place for the project\r\n     *         instance.\r\n     */\r\n    public InputHandler getInputHandler() {\r\n        return inputHandler;\r\n    }\r\n\r\n    /**\r\n     * Create a new Ant project.\r\n     */\r\n    public Project() {\r\n        inputHandler = new DefaultInputHandler();\r\n    }\r\n\r\n    /**\r\n     * Create and initialize a subproject. By default the subproject will be of\r\n     * the same type as its parent. If a no-arg constructor is unavailable, the\r\n     * <code>Project</code> class will be used.\r\n     * @return a Project instance configured as a subproject of this Project.\r\n     * @since Ant 1.7\r\n     */\r\n    public Project createSubProject() {\r\n        Project subProject = null;\r\n        try {\r\n            subProject = (Project) (getClass().newInstance());\r\n        } catch (Exception e) {\r\n            subProject = new Project();\r\n        }\r\n        initSubProject(subProject);\r\n        return subProject;\r\n    }\r\n\r\n    /**\r\n     * Initialize a subproject.\r\n     * @param subProject the subproject to initialize.\r\n     */\r\n    public void initSubProject(Project subProject) {\r\n        ComponentHelper.getComponentHelper(subProject)\r\n            .initSubProject(ComponentHelper.getComponentHelper(this));\r\n        subProject.setDefaultInputStream(getDefaultInputStream());\r\n        subProject.setKeepGoingMode(this.isKeepGoingMode());\r\n        subProject.setExecutor(getExecutor().getSubProjectExecutor());\r\n    }\r\n\r\n    /**\r\n     * Initialise the project.\r\n     *\r\n     * This involves setting the default task definitions and loading the\r\n     * system properties.\r\n     *\r\n     * @exception BuildException if the default task list cannot be loaded.\r\n     */\r\n    public void init() throws BuildException {\r\n        initProperties();\r\n\r\n        ComponentHelper.getComponentHelper(this).initDefaultDefinitions();\r\n    }\r\n\r\n    /**\r\n     * Initializes the properties.\r\n     * @exception BuildException if an vital property could not be set.\r\n     * @since Ant 1.7\r\n     */\r\n    public void initProperties() throws BuildException {\r\n        setJavaVersionProperty();\r\n        setSystemProperties();\r\n        setPropertyInternal(MagicNames.ANT_VERSION, Main.getAntVersion());\r\n        setAntLib();\r\n    }\r\n\r\n    /**\r\n     * Set a property to the location of ant.jar.\r\n     * Use the locator to find the location of the Project.class, and\r\n     * if this is not null, set the property {@link MagicNames#ANT_LIB}\r\n     * to the result\r\n     */\r\n    private void setAntLib() {\r\n        File antlib = org.apache.tools.ant.launch.Locator.getClassSource(\r\n            Project.class);\r\n        if (antlib != null) {\r\n            setPropertyInternal(MagicNames.ANT_LIB, antlib.getAbsolutePath());\r\n        }\r\n    }\r\n    /**\r\n     * Factory method to create a class loader for loading classes from\r\n     * a given path.\r\n     *\r\n     * @param path the path from which classes are to be loaded.\r\n     *\r\n     * @return an appropriate classloader.\r\n     */\r\n    public AntClassLoader createClassLoader(Path path) {\r\n        return AntClassLoader\r\n            .newAntClassLoader(getClass().getClassLoader(), this, path, true);\r\n    }\r\n\r\n    /**\r\n     * Factory method to create a class loader for loading classes from\r\n     * a given path.\r\n     *\r\n     * @param parent the parent classloader for the new loader.\r\n     * @param path the path from which classes are to be loaded.\r\n     *\r\n     * @return an appropriate classloader.\r\n     */\r\n    public AntClassLoader createClassLoader(\r\n        ClassLoader parent, Path path) {\r\n        return AntClassLoader.newAntClassLoader(parent, this, path, true);\r\n    }\r\n\r\n    /**\r\n     * Set the core classloader for the project. If a <code>null</code>\r\n     * classloader is specified, the parent classloader should be used.\r\n     *\r\n     * @param coreLoader The classloader to use for the project.\r\n     *                   May be <code>null</code>.\r\n     */\r\n    public void setCoreLoader(ClassLoader coreLoader) {\r\n        this.coreLoader = coreLoader;\r\n    }\r\n\r\n    /**\r\n     * Return the core classloader to use for this project.\r\n     * This may be <code>null</code>, indicating that\r\n     * the parent classloader should be used.\r\n     *\r\n     * @return the core classloader to use for this project.\r\n     *\r\n     */\r\n    public ClassLoader getCoreLoader() {\r\n        return coreLoader;\r\n    }\r\n\r\n    /**\r\n     * Add a build listener to the list. This listener will\r\n     * be notified of build events for this project.\r\n     *\r\n     * @param listener The listener to add to the list.\r\n     *                 Must not be <code>null</code>.\r\n     */\r\n    public void addBuildListener(BuildListener listener) {\r\n        synchronized (listenersLock) {\r\n            // If the listeners already has this listener, do nothing\r\n            for (int i = 0; i < listeners.length; i++) {\r\n                if (listeners[i] == listener) {\r\n                    return;\r\n                }\r\n            }\r\n            // copy on write semantics\r\n            BuildListener[] newListeners =\r\n                new BuildListener[listeners.length + 1];\r\n            System.arraycopy(listeners, 0, newListeners, 0, listeners.length);\r\n            newListeners[listeners.length] = listener;\r\n            listeners = newListeners;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Remove a build listener from the list. This listener\r\n     * will no longer be notified of build events for this project.\r\n     *\r\n     * @param listener The listener to remove from the list.\r\n     *                 Should not be <code>null</code>.\r\n     */\r\n    public void removeBuildListener(BuildListener listener) {\r\n        synchronized (listenersLock) {\r\n            // copy on write semantics\r\n            for (int i = 0; i < listeners.length; i++) {\r\n                if (listeners[i] == listener) {\r\n                    BuildListener[] newListeners =\r\n                        new BuildListener[listeners.length - 1];\r\n                    System.arraycopy(listeners, 0, newListeners, 0, i);\r\n                    System.arraycopy(listeners, i + 1, newListeners, i,\r\n                                     listeners.length - i - 1);\r\n                    listeners = newListeners;\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Return a copy of the list of build listeners for the project.\r\n     * \r\n     * @return a list of build listeners for the project\r\n     */\r\n    public Vector getBuildListeners() {\r\n        synchronized (listenersLock) {\r\n            Vector r = new Vector(listeners.length);\r\n            for (int i = 0; i < listeners.length; i++) {\r\n                r.add(listeners[i]);\r\n            }\r\n            return r;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Write a message to the log with the default log level\r\n     * of MSG_INFO .\r\n     * @param message The text to log. Should not be <code>null</code>.\r\n     */\r\n\r\n    public void log(String message) {\r\n        log(message, MSG_INFO);\r\n    }\r\n\r\n    /**\r\n     * Write a project level message to the log with the given log level.\r\n     * @param message The text to log. Should not be <code>null</code>.\r\n     * @param msgLevel The log priority level to use.\r\n     */\r\n    public void log(String message, int msgLevel) {\r\n        log(message, null, msgLevel);\r\n    }\r\n\r\n    /**\r\n     * Write a project level message to the log with the given log level.\r\n     * @param message The text to log. Should not be <code>null</code>.\r\n     * @param throwable The exception causing this log, may be <code>null</code>.\r\n     * @param msgLevel The log priority level to use.\r\n     * @since 1.7\r\n     */\r\n    public void log(String message, Throwable throwable, int msgLevel) {\r\n        fireMessageLogged(this, message, throwable, msgLevel);\r\n    }\r\n\r\n    /**\r\n     * Write a task level message to the log with the given log level.\r\n     * @param task The task to use in the log. Must not be <code>null</code>.\r\n     * @param message The text to log. Should not be <code>null</code>.\r\n     * @param msgLevel The log priority level to use.\r\n     */\r\n    public void log(Task task, String message, int msgLevel) {\r\n        fireMessageLogged(task, message, null, msgLevel);\r\n    }\r\n\r\n    /**\r\n     * Write a task level message to the log with the given log level.\r\n     * @param task The task to use in the log. Must not be <code>null</code>.\r\n     * @param message The text to log. Should not be <code>null</code>.\r\n     * @param throwable The exception causing this log, may be <code>null</code>.\r\n     * @param msgLevel The log priority level to use.\r\n     * @since 1.7\r\n     */\r\n    public void log(Task task, String message, Throwable throwable, int msgLevel) {\r\n        fireMessageLogged(task, message, throwable, msgLevel);\r\n    }\r\n\r\n    /**\r\n     * Write a target level message to the log with the given log level.\r\n     * @param target The target to use in the log.\r\n     *               Must not be <code>null</code>.\r\n     * @param message The text to log. Should not be <code>null</code>.\r\n     * @param msgLevel The log priority level to use.\r\n     */\r\n    public void log(Target target, String message, int msgLevel) {\r\n        log(target, message, null, msgLevel);\r\n    }\r\n\r\n    /**\r\n     * Write a target level message to the log with the given log level.\r\n     * @param target The target to use in the log.\r\n     *               Must not be <code>null</code>.\r\n     * @param message The text to log. Should not be <code>null</code>.\r\n     * @param throwable The exception causing this log, may be <code>null</code>.\r\n     * @param msgLevel The log priority level to use.\r\n     * @since 1.7\r\n     */\r\n    public void log(Target target, String message, Throwable throwable,\r\n            int msgLevel) {\r\n        fireMessageLogged(target, message, throwable, msgLevel);\r\n    }\r\n\r\n    /**\r\n     * Return the set of global filters.\r\n     *\r\n     * @return the set of global filters.\r\n     */\r\n    public FilterSet getGlobalFilterSet() {\r\n        return globalFilterSet;\r\n    }\r\n\r\n    /**\r\n     * Set a property. Any existing property of the same name\r\n     * is overwritten, unless it is a user property.\r\n     * @param name The name of property to set.\r\n     *             Must not be <code>null</code>.\r\n     * @param value The new value of the property.\r\n     *              Must not be <code>null</code>.\r\n     */\r\n    public void setProperty(String name, String value) {\r\n        PropertyHelper.getPropertyHelper(this).setProperty(name, value, true);\r\n    }\r\n\r\n    /**\r\n     * Set a property if no value currently exists. If the property\r\n     * exists already, a message is logged and the method returns with\r\n     * no other effect.\r\n     *\r\n     * @param name The name of property to set.\r\n     *             Must not be <code>null</code>.\r\n     * @param value The new value of the property.\r\n     *              Must not be <code>null</code>.\r\n     * @since 1.5\r\n     */\r\n    public void setNewProperty(String name, String value) {\r\n        PropertyHelper.getPropertyHelper(this).setNewProperty(name, value);\r\n    }\r\n\r\n    /**\r\n     * Set a user property, which cannot be overwritten by\r\n     * set/unset property calls. Any previous value is overwritten.\r\n     * @param name The name of property to set.\r\n     *             Must not be <code>null</code>.\r\n     * @param value The new value of the property.\r\n     *              Must not be <code>null</code>.\r\n     * @see #setProperty(String,String)\r\n     */\r\n    public void setUserProperty(String name, String value) {\r\n        PropertyHelper.getPropertyHelper(this).setUserProperty(name, value);\r\n    }\r\n\r\n    /**\r\n     * Set a user property, which cannot be overwritten by set/unset\r\n     * property calls. Any previous value is overwritten. Also marks\r\n     * these properties as properties that have not come from the\r\n     * command line.\r\n     *\r\n     * @param name The name of property to set.\r\n     *             Must not be <code>null</code>.\r\n     * @param value The new value of the property.\r\n     *              Must not be <code>null</code>.\r\n     * @see #setProperty(String,String)\r\n     */\r\n    public void setInheritedProperty(String name, String value) {\r\n        PropertyHelper.getPropertyHelper(this).setInheritedProperty(name, value);\r\n    }\r\n\r\n    /**\r\n     * Set a property unless it is already defined as a user property\r\n     * (in which case the method returns silently).\r\n     *\r\n     * @param name The name of the property.\r\n     *             Must not be <code>null</code>.\r\n     * @param value The property value. Must not be <code>null</code>.\r\n     */\r\n    private void setPropertyInternal(String name, String value) {\r\n        PropertyHelper.getPropertyHelper(this).setProperty(name, value, false);\r\n    }\r\n\r\n    /**\r\n     * Return the value of a property, if it is set.\r\n     *\r\n     * @param propertyName The name of the property.\r\n     *             May be <code>null</code>, in which case\r\n     *             the return value is also <code>null</code>.\r\n     * @return the property value, or <code>null</code> for no match\r\n     *         or if a <code>null</code> name is provided.\r\n     */\r\n    public String getProperty(String propertyName) {\r\n        Object value = PropertyHelper.getPropertyHelper(this).getProperty(propertyName);\r\n        return value == null ? null : String.valueOf(value);\r\n    }\r\n\r\n    /**\r\n     * Replace ${} style constructions in the given value with the\r\n     * string value of the corresponding data types.\r\n     *\r\n     * @param value The string to be scanned for property references.\r\n     *              May be <code>null</code>.\r\n     *\r\n     * @return the given string with embedded property names replaced\r\n     *         by values, or <code>null</code> if the given string is\r\n     *         <code>null</code>.\r\n     *\r\n     * @exception BuildException if the given value has an unclosed\r\n     *                           property name, e.g. <code>${xxx</code>.\r\n     */\r\n    public String replaceProperties(String value) throws BuildException {\r\n        return PropertyHelper.getPropertyHelper(this).replaceProperties(null, value, null);\r\n    }\r\n\r\n    /**\r\n     * Return the value of a user property, if it is set.\r\n     *\r\n     * @param propertyName The name of the property.\r\n     *             May be <code>null</code>, in which case\r\n     *             the return value is also <code>null</code>.\r\n     * @return the property value, or <code>null</code> for no match\r\n     *         or if a <code>null</code> name is provided.\r\n     */\r\n     public String getUserProperty(String propertyName) {\r\n        return (String) PropertyHelper.getPropertyHelper(this).getUserProperty(propertyName);\r\n    }\r\n\r\n    /**\r\n     * Return a copy of the properties table.\r\n     * @return a hashtable containing all properties\r\n     *         (including user properties).\r\n     */\r\n    public Hashtable getProperties() {\r\n        return PropertyHelper.getPropertyHelper(this).getProperties();\r\n    }\r\n\r\n    /**\r\n     * Return a copy of the user property hashtable.\r\n     * @return a hashtable containing just the user properties.\r\n     */\r\n    public Hashtable getUserProperties() {\r\n        return PropertyHelper.getPropertyHelper(this).getUserProperties();\r\n    }\r\n\r\n    /**\r\n     * Return a copy of the inherited property hashtable.\r\n     * @return a hashtable containing just the inherited properties.\r\n     * @since Ant 1.8.0\r\n     */\r\n    public Hashtable getInheritedProperties() {\r\n        return PropertyHelper.getPropertyHelper(this).getInheritedProperties();\r\n    }\r\n\r\n    /**\r\n     * Copy all user properties that have been set on the command\r\n     * line or a GUI tool from this instance to the Project instance\r\n     * given as the argument.\r\n     *\r\n     * <p>To copy all &quot;user&quot; properties, you will also have to call\r\n     * {@link #copyInheritedProperties copyInheritedProperties}.</p>\r\n     *\r\n     * @param other the project to copy the properties to.  Must not be null.\r\n     *\r\n     * @since Ant 1.5\r\n     */\r\n    public void copyUserProperties(Project other) {\r\n        PropertyHelper.getPropertyHelper(this).copyUserProperties(other);\r\n    }\r\n\r\n    /**\r\n     * Copy all user properties that have not been set on the\r\n     * command line or a GUI tool from this instance to the Project\r\n     * instance given as the argument.\r\n     *\r\n     * <p>To copy all &quot;user&quot; properties, you will also have to call\r\n     * {@link #copyUserProperties copyUserProperties}.</p>\r\n     *\r\n     * @param other the project to copy the properties to.  Must not be null.\r\n     *\r\n     * @since Ant 1.5\r\n     */\r\n    public void copyInheritedProperties(Project other) {\r\n        PropertyHelper.getPropertyHelper(this).copyInheritedProperties(other);\r\n    }\r\n\r\n    /**\r\n     * Set the default target of the project.\r\n     *\r\n     * @param defaultTarget The name of the default target for this project.\r\n     *                      May be <code>null</code>, indicating that there is\r\n     *                      no default target.\r\n     *\r\n     * @deprecated since 1.5.x.\r\n     *             Use setDefault.\r\n     * @see #setDefault(String)\r\n     */\r\n    public void setDefaultTarget(String defaultTarget) {\r\n        setDefault(defaultTarget);\r\n    }\r\n\r\n    /**\r\n     * Return the name of the default target of the project.\r\n     * @return name of the default target or\r\n     *         <code>null</code> if no default has been set.\r\n     */\r\n    public String getDefaultTarget() {\r\n        return defaultTarget;\r\n    }\r\n\r\n    /**\r\n     * Set the default target of the project.\r\n     *\r\n     * @param defaultTarget The name of the default target for this project.\r\n     *                      May be <code>null</code>, indicating that there is\r\n     *                      no default target.\r\n     */\r\n    public void setDefault(String defaultTarget) {\r\n        if (defaultTarget != null) {\r\n            setUserProperty(MagicNames.PROJECT_DEFAULT_TARGET, defaultTarget);\r\n        }\r\n        this.defaultTarget = defaultTarget;\r\n    }\r\n\r\n    /**\r\n     * Set the name of the project, also setting the user\r\n     * property <code>ant.project.name</code>.\r\n     *\r\n     * @param name The name of the project.\r\n     *             Must not be <code>null</code>.\r\n     */\r\n    public void setName(String name) {\r\n        setUserProperty(MagicNames.PROJECT_NAME,  name);\r\n        this.name = name;\r\n    }\r\n\r\n    /**\r\n     * Return the project name, if one has been set.\r\n     *\r\n     * @return the project name, or <code>null</code> if it hasn\'t been set.\r\n     */\r\n    public String getName() {\r\n        return name;\r\n    }\r\n\r\n    /**\r\n     * Set the project description.\r\n     *\r\n     * @param description The description of the project.\r\n     *                    May be <code>null</code>.\r\n     */\r\n    public void setDescription(String description) {\r\n        this.description = description;\r\n    }\r\n\r\n    /**\r\n     * Return the project description, if one has been set.\r\n     *\r\n     * @return the project description, or <code>null</code> if it hasn\'t\r\n     *         been set.\r\n     */\r\n    public String getDescription() {\r\n        if (description == null) {\r\n            description = Description.getDescription(this);\r\n        }\r\n        return description;\r\n    }\r\n\r\n    /**\r\n     * Add a filter to the set of global filters.\r\n     *\r\n     * @param token The token to filter.\r\n     *              Must not be <code>null</code>.\r\n     * @param value The replacement value.\r\n     *              Must not be <code>null</code>.\r\n     * @deprecated since 1.4.x.\r\n     *             Use getGlobalFilterSet().addFilter(token,value)\r\n     *\r\n     * @see #getGlobalFilterSet()\r\n     * @see FilterSet#addFilter(String,String)\r\n     */\r\n    public void addFilter(String token, String value) {\r\n        if (token == null) {\r\n            return;\r\n        }\r\n        globalFilterSet.addFilter(new FilterSet.Filter(token, value));\r\n    }\r\n\r\n    /**\r\n     * Return a hashtable of global filters, mapping tokens to values.\r\n     *\r\n     * @return a hashtable of global filters, mapping tokens to values\r\n     *         (String to String).\r\n     *\r\n     * @deprecated since 1.4.x\r\n     *             Use getGlobalFilterSet().getFilterHash().\r\n     *\r\n     * @see #getGlobalFilterSet()\r\n     * @see FilterSet#getFilterHash()\r\n     */\r\n    public Hashtable getFilters() {\r\n        // we need to build the hashtable dynamically\r\n        return globalFilterSet.getFilterHash();\r\n    }\r\n\r\n    /**\r\n     * Set the base directory for the project, checking that\r\n     * the given filename exists and is a directory.\r\n     *\r\n     * @param baseD The project base directory.\r\n     *              Must not be <code>null</code>.\r\n     *\r\n     * @exception BuildException if the directory if invalid.\r\n     */\r\n    public void setBasedir(String baseD) throws BuildException {\r\n        setBaseDir(new File(baseD));\r\n    }\r\n\r\n    /**\r\n     * Set the base directory for the project, checking that\r\n     * the given file exists and is a directory.\r\n     *\r\n     * @param baseDir The project base directory.\r\n     *                Must not be <code>null</code>.\r\n     * @exception BuildException if the specified file doesn\'t exist or\r\n     *                           isn\'t a directory.\r\n     */\r\n    public void setBaseDir(File baseDir) throws BuildException {\r\n        baseDir = FILE_UTILS.normalize(baseDir.getAbsolutePath());\r\n        if (!baseDir.exists()) {\r\n            throw new BuildException(\"Basedir \" + baseDir.getAbsolutePath()\r\n                + \" does not exist\");\r\n        }\r\n        if (!baseDir.isDirectory()) {\r\n            throw new BuildException(\"Basedir \" + baseDir.getAbsolutePath()\r\n                + \" is not a directory\");\r\n        }\r\n        this.baseDir = baseDir;\r\n        setPropertyInternal(MagicNames.PROJECT_BASEDIR, this.baseDir.getPath());\r\n        String msg = \"Project base dir set to: \" + this.baseDir;\r\n        log(msg, MSG_VERBOSE);\r\n    }\r\n\r\n    /**\r\n     * Return the base directory of the project as a file object.\r\n     *\r\n     * @return the project base directory, or <code>null</code> if the\r\n     *         base directory has not been successfully set to a valid value.\r\n     */\r\n    public File getBaseDir() {\r\n        if (baseDir == null) {\r\n            try {\r\n                setBasedir(\".\");\r\n            } catch (BuildException ex) {\r\n                ex.printStackTrace();\r\n            }\r\n        }\r\n        return baseDir;\r\n    }\r\n\r\n    /**\r\n     * Set &quot;keep-going&quot; mode. In this mode Ant will try to execute\r\n     * as many targets as possible. All targets that do not depend\r\n     * on failed target(s) will be executed.  If the keepGoing settor/getter\r\n     * methods are used in conjunction with the <code>ant.executor.class</code>\r\n     * property, they will have no effect.\r\n     * @param keepGoingMode &quot;keep-going&quot; mode\r\n     * @since Ant 1.6\r\n     */\r\n    public void setKeepGoingMode(boolean keepGoingMode) {\r\n        this.keepGoingMode = keepGoingMode;\r\n    }\r\n\r\n    /**\r\n     * Return the keep-going mode.  If the keepGoing settor/getter\r\n     * methods are used in conjunction with the <code>ant.executor.class</code>\r\n     * property, they will have no effect.\r\n     * @return &quot;keep-going&quot; mode\r\n     * @since Ant 1.6\r\n     */\r\n    public boolean isKeepGoingMode() {\r\n        return this.keepGoingMode;\r\n    }\r\n\r\n    /**\r\n     * Return the version of Java this class is running under.\r\n     * @return the version of Java as a String, e.g. \"1.1\" .\r\n     * @see org.apache.tools.ant.util.JavaEnvUtils#getJavaVersion\r\n     * @deprecated since 1.5.x.\r\n     *             Use org.apache.tools.ant.util.JavaEnvUtils instead.\r\n     */\r\n    public static String getJavaVersion() {\r\n        return JavaEnvUtils.getJavaVersion();\r\n    }\r\n\r\n    /**\r\n     * Set the <code>ant.java.version</code> property and tests for\r\n     * unsupported JVM versions. If the version is supported,\r\n     * verbose log messages are generated to record the Java version\r\n     * and operating system name.\r\n     *\r\n     * @exception BuildException if this Java version is not supported.\r\n     *\r\n     * @see org.apache.tools.ant.util.JavaEnvUtils#getJavaVersion\r\n     */\r\n    public void setJavaVersionProperty() throws BuildException {\r\n        String javaVersion = JavaEnvUtils.getJavaVersion();\r\n        setPropertyInternal(MagicNames.ANT_JAVA_VERSION, javaVersion);\r\n\r\n        // sanity check\r\n        if (!JavaEnvUtils.isAtLeastJavaVersion(JavaEnvUtils.JAVA_1_4))  {\r\n            throw new BuildException(\"Ant cannot work on Java prior to 1.4\");\r\n        }\r\n        log(\"Detected Java version: \" + javaVersion + \" in: \"\r\n            + System.getProperty(\"java.home\"), MSG_VERBOSE);\r\n\r\n        log(\"Detected OS: \" + System.getProperty(\"os.name\"), MSG_VERBOSE);\r\n    }\r\n\r\n    /**\r\n     * Add all system properties which aren\'t already defined as\r\n     * user properties to the project properties.\r\n     */\r\n    public void setSystemProperties() {\r\n        Properties systemP = System.getProperties();\r\n        Enumeration e = systemP.propertyNames();\r\n        while (e.hasMoreElements()) {\r\n            String propertyName = (String) e.nextElement();\r\n            String value = systemP.getProperty(propertyName);\r\n            if (value != null) {\r\n                this.setPropertyInternal(propertyName, value);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Add a new task definition to the project.\r\n     * Attempting to override an existing definition with an\r\n     * equivalent one (i.e. with the same classname) results in\r\n     * a verbose log message. Attempting to override an existing definition\r\n     * with a different one results in a warning log message and\r\n     * invalidates any tasks which have already been created with the\r\n     * old definition.\r\n     *\r\n     * @param taskName The name of the task to add.\r\n     *                 Must not be <code>null</code>.\r\n     * @param taskClass The full name of the class implementing the task.\r\n     *                  Must not be <code>null</code>.\r\n     *\r\n     * @exception BuildException if the class is unsuitable for being an Ant\r\n     *                           task. An error level message is logged before\r\n     *                           this exception is thrown.\r\n     *\r\n     * @see #checkTaskClass(Class)\r\n     */\r\n    public void addTaskDefinition(String taskName, Class taskClass)\r\n         throws BuildException {\r\n        ComponentHelper.getComponentHelper(this).addTaskDefinition(taskName,\r\n                taskClass);\r\n    }\r\n\r\n    /**\r\n     * Check whether or not a class is suitable for serving as Ant task.\r\n     * Ant task implementation classes must be public, concrete, and have\r\n     * a no-arg constructor.\r\n     *\r\n     * @param taskClass The class to be checked.\r\n     *                  Must not be <code>null</code>.\r\n     *\r\n     * @exception BuildException if the class is unsuitable for being an Ant\r\n     *                           task. An error level message is logged before\r\n     *                           this exception is thrown.\r\n     */\r\n    public void checkTaskClass(final Class taskClass) throws BuildException {\r\n        ComponentHelper.getComponentHelper(this).checkTaskClass(taskClass);\r\n\r\n        if (!Modifier.isPublic(taskClass.getModifiers())) {\r\n            final String message = taskClass + \" is not public\";\r\n            log(message, Project.MSG_ERR);\r\n            throw new BuildException(message);\r\n        }\r\n        if (Modifier.isAbstract(taskClass.getModifiers())) {\r\n            final String message = taskClass + \" is abstract\";\r\n            log(message, Project.MSG_ERR);\r\n            throw new BuildException(message);\r\n        }\r\n        try {\r\n            taskClass.getConstructor((Class[]) null);\r\n            // don\'t have to check for public, since\r\n            // getConstructor finds public constructors only.\r\n        } catch (NoSuchMethodException e) {\r\n            final String message = \"No public no-arg constructor in \"\r\n                + taskClass;\r\n            log(message, Project.MSG_ERR);\r\n            throw new BuildException(message);\r\n        } catch (LinkageError e) {\r\n            String message = \"Could not load \" + taskClass + \": \" + e;\r\n            log(message, Project.MSG_ERR);\r\n            throw new BuildException(message, e);\r\n        }\r\n        if (!Task.class.isAssignableFrom(taskClass)) {\r\n            TaskAdapter.checkTaskClass(taskClass, this);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Return the current task definition hashtable. The returned hashtable is\r\n     * &quot;live&quot; and so should not be modified.\r\n     *\r\n     * @return a map of from task name to implementing class\r\n     *         (String to Class).\r\n     */\r\n    public Hashtable getTaskDefinitions() {\r\n        return ComponentHelper.getComponentHelper(this).getTaskDefinitions();\r\n    }\r\n\r\n    /**\r\n     * Return the current task definition map. The returned map is a\r\n     * copy of the &quot;live&quot; definitions.\r\n     *\r\n     * @return a map of from task name to implementing class\r\n     *         (String to Class).\r\n     *\r\n     * @since Ant 1.8.1\r\n     */\r\n    public Map getCopyOfTaskDefinitions() {\r\n        return new HashMap(getTaskDefinitions());\r\n    }\r\n\r\n    /**\r\n     * Add a new datatype definition.\r\n     * Attempting to override an existing definition with an\r\n     * equivalent one (i.e. with the same classname) results in\r\n     * a verbose log message. Attempting to override an existing definition\r\n     * with a different one results in a warning log message, but the\r\n     * definition is changed.\r\n     *\r\n     * @param typeName The name of the datatype.\r\n     *                 Must not be <code>null</code>.\r\n     * @param typeClass The full name of the class implementing the datatype.\r\n     *                  Must not be <code>null</code>.\r\n     */\r\n    public void addDataTypeDefinition(String typeName, Class typeClass) {\r\n        ComponentHelper.getComponentHelper(this).addDataTypeDefinition(typeName,\r\n                typeClass);\r\n    }\r\n\r\n    /**\r\n     * Return the current datatype definition hashtable. The returned\r\n     * hashtable is &quot;live&quot; and so should not be modified.\r\n     *\r\n     * @return a map of from datatype name to implementing class\r\n     *         (String to Class).\r\n     */\r\n    public Hashtable getDataTypeDefinitions() {\r\n        return ComponentHelper.getComponentHelper(this).getDataTypeDefinitions();\r\n    }\r\n\r\n    /**\r\n     * Return the current datatype definition map. The returned\r\n     * map is a copy pf the &quot;live&quot; definitions.\r\n     *\r\n     * @return a map of from datatype name to implementing class\r\n     *         (String to Class).\r\n     *\r\n     * @since Ant 1.8.1\r\n     */\r\n    public Map getCopyOfDataTypeDefinitions() {\r\n        return new HashMap(getDataTypeDefinitions());\r\n    }\r\n\r\n    /**\r\n     * Add a <em>new</em> target to the project.\r\n     *\r\n     * @param target The target to be added to the project.\r\n     *               Must not be <code>null</code>.\r\n     *\r\n     * @exception BuildException if the target already exists in the project\r\n     *\r\n     * @see Project#addOrReplaceTarget(Target)\r\n     */\r\n    public void addTarget(Target target) throws BuildException {\r\n        addTarget(target.getName(), target);\r\n    }\r\n\r\n    /**\r\n     * Add a <em>new</em> target to the project.\r\n     *\r\n     * @param targetName The name to use for the target.\r\n     *             Must not be <code>null</code>.\r\n     * @param target The target to be added to the project.\r\n     *               Must not be <code>null</code>.\r\n     *\r\n     * @exception BuildException if the target already exists in the project.\r\n     *\r\n     * @see Project#addOrReplaceTarget(String, Target)\r\n     */\r\n     public void addTarget(String targetName, Target target)\r\n         throws BuildException {\r\n         if (targets.get(targetName) != null) {\r\n             throw new BuildException(\"Duplicate target: `\" + targetName + \"\'\");\r\n         }\r\n         addOrReplaceTarget(targetName, target);\r\n     }\r\n\r\n    /**\r\n     * Add a target to the project, or replaces one with the same\r\n     * name.\r\n     *\r\n     * @param target The target to be added or replaced in the project.\r\n     *               Must not be <code>null</code>.\r\n     */\r\n    public void addOrReplaceTarget(Target target) {\r\n        addOrReplaceTarget(target.getName(), target);\r\n    }\r\n\r\n    /**\r\n     * Add a target to the project, or replaces one with the same\r\n     * name.\r\n     *\r\n     * @param targetName The name to use for the target.\r\n     *                   Must not be <code>null</code>.\r\n     * @param target The target to be added or replaced in the project.\r\n     *               Must not be <code>null</code>.\r\n     */\r\n    public void addOrReplaceTarget(String targetName, Target target) {\r\n        String msg = \" +Target: \" + targetName;\r\n        log(msg, MSG_DEBUG);\r\n        target.setProject(this);\r\n        targets.put(targetName, target);\r\n    }\r\n\r\n    /**\r\n     * Return the hashtable of targets. The returned hashtable\r\n     * is &quot;live&quot; and so should not be modified.\r\n     * @return a map from name to target (String to Target).\r\n     */\r\n    public Hashtable getTargets() {\r\n        return targets;\r\n    }\r\n\r\n    /**\r\n     * Return the map of targets. The returned map\r\n     * is a copy of the &quot;live&quot; targets.\r\n     * @return a map from name to target (String to Target).\r\n     * @since Ant 1.8.1\r\n     */\r\n    public Map getCopyOfTargets() {\r\n        return new HashMap(targets);\r\n    }\r\n\r\n    /**\r\n     * Create a new instance of a task, adding it to a list of\r\n     * created tasks for later invalidation. This causes all tasks\r\n     * to be remembered until the containing project is removed\r\n     * @param taskType The name of the task to create an instance of.\r\n     *                 Must not be <code>null</code>.\r\n     *\r\n     * @return an instance of the specified task, or <code>null</code> if\r\n     *         the task name is not recognised.\r\n     *\r\n     * @exception BuildException if the task name is recognised but task\r\n     *                           creation fails.\r\n     */\r\n    public Task createTask(String taskType) throws BuildException {\r\n        return ComponentHelper.getComponentHelper(this).createTask(taskType);\r\n    }\r\n\r\n    /**\r\n     * Create a new instance of a data type.\r\n     *\r\n     * @param typeName The name of the data type to create an instance of.\r\n     *                 Must not be <code>null</code>.\r\n     *\r\n     * @return an instance of the specified data type, or <code>null</code> if\r\n     *         the data type name is not recognised.\r\n     *\r\n     * @exception BuildException if the data type name is recognised but\r\n     *                           instance creation fails.\r\n     */\r\n    public Object createDataType(String typeName) throws BuildException {\r\n        return ComponentHelper.getComponentHelper(this).createDataType(typeName);\r\n    }\r\n\r\n    /**\r\n     * Set the Executor instance for this Project.\r\n     * @param e the Executor to use.\r\n     */\r\n    public void setExecutor(Executor e) {\r\n        addReference(MagicNames.ANT_EXECUTOR_REFERENCE, e);\r\n    }\r\n\r\n    /**\r\n     * Get this Project\'s Executor (setting it if necessary).\r\n     * @return an Executor instance.\r\n     */\r\n    public Executor getExecutor() {\r\n        Object o = getReference(MagicNames.ANT_EXECUTOR_REFERENCE);\r\n        if (o == null) {\r\n            String classname = getProperty(MagicNames.ANT_EXECUTOR_CLASSNAME);\r\n            if (classname == null) {\r\n                classname = DefaultExecutor.class.getName();\r\n            }\r\n            log(\"Attempting to create object of type \" + classname, MSG_DEBUG);\r\n            try {\r\n                o = Class.forName(classname, true, coreLoader).newInstance();\r\n            } catch (ClassNotFoundException seaEnEfEx) {\r\n                //try the current classloader\r\n                try {\r\n                    o = Class.forName(classname).newInstance();\r\n                } catch (Exception ex) {\r\n                    log(ex.toString(), MSG_ERR);\r\n                }\r\n            } catch (Exception ex) {\r\n                log(ex.toString(), MSG_ERR);\r\n            }\r\n            if (o == null) {\r\n                throw new BuildException(\r\n                    \"Unable to obtain a Target Executor instance.\");\r\n            }\r\n            setExecutor((Executor) o);\r\n        }\r\n        return (Executor) o;\r\n    }\r\n\r\n    /**\r\n     * Execute the specified sequence of targets, and the targets\r\n     * they depend on.\r\n     *\r\n     * @param names A vector of target name strings to execute.\r\n     *              Must not be <code>null</code>.\r\n     *\r\n     * @exception BuildException if the build failed.\r\n     */\r\n    public void executeTargets(Vector names) throws BuildException {\r\n        setUserProperty(MagicNames.PROJECT_INVOKED_TARGETS,\r\n                        CollectionUtils.flattenToString(names));\r\n        getExecutor().executeTargets(this,\r\n            (String[]) (names.toArray(new String[names.size()])));\r\n    }\r\n\r\n    /**\r\n     * Demultiplex output so that each task receives the appropriate\r\n     * messages. If the current thread is not currently executing a task,\r\n     * the message is logged directly.\r\n     *\r\n     * @param output Message to handle. Should not be <code>null</code>.\r\n     * @param isWarning Whether the text represents an warning (<code>true</code>)\r\n     *        or information (<code>false</code>).\r\n     */\r\n    public void demuxOutput(String output, boolean isWarning) {\r\n        Task task = getThreadTask(Thread.currentThread());\r\n        if (task == null) {\r\n            log(output, isWarning ? MSG_WARN : MSG_INFO);\r\n        } else {\r\n            if (isWarning) {\r\n                task.handleErrorOutput(output);\r\n            } else {\r\n                task.handleOutput(output);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Read data from the default input stream. If no default has been\r\n     * specified, System.in is used.\r\n     *\r\n     * @param buffer the buffer into which data is to be read.\r\n     * @param offset the offset into the buffer at which data is stored.\r\n     * @param length the amount of data to read.\r\n     *\r\n     * @return the number of bytes read.\r\n     *\r\n     * @exception IOException if the data cannot be read.\r\n     * @since Ant 1.6\r\n     */\r\n    public int defaultInput(byte[] buffer, int offset, int length)\r\n        throws IOException {\r\n        if (defaultInputStream != null) {\r\n            System.out.flush();\r\n            return defaultInputStream.read(buffer, offset, length);\r\n        } else {\r\n            throw new EOFException(\"No input provided for project\");\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Demux an input request to the correct task.\r\n     *\r\n     * @param buffer the buffer into which data is to be read.\r\n     * @param offset the offset into the buffer at which data is stored.\r\n     * @param length the amount of data to read.\r\n     *\r\n     * @return the number of bytes read.\r\n     *\r\n     * @exception IOException if the data cannot be read.\r\n     * @since Ant 1.6\r\n     */\r\n    public int demuxInput(byte[] buffer, int offset, int length)\r\n        throws IOException {\r\n        Task task = getThreadTask(Thread.currentThread());\r\n        if (task == null) {\r\n            return defaultInput(buffer, offset, length);\r\n        } else {\r\n            return task.handleInput(buffer, offset, length);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Demultiplex flush operations so that each task receives the appropriate\r\n     * messages. If the current thread is not currently executing a task,\r\n     * the message is logged directly.\r\n     *\r\n     * @since Ant 1.5.2\r\n     *\r\n     * @param output Message to handle. Should not be <code>null</code>.\r\n     * @param isError Whether the text represents an error (<code>true</code>)\r\n     *        or information (<code>false</code>).\r\n     */\r\n    public void demuxFlush(String output, boolean isError) {\r\n        Task task = getThreadTask(Thread.currentThread());\r\n        if (task == null) {\r\n            fireMessageLogged(this, output, isError ? MSG_ERR : MSG_INFO);\r\n        } else {\r\n            if (isError) {\r\n                task.handleErrorFlush(output);\r\n            } else {\r\n                task.handleFlush(output);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Execute the specified target and any targets it depends on.\r\n     *\r\n     * @param targetName The name of the target to execute.\r\n     *                   Must not be <code>null</code>.\r\n     *\r\n     * @exception BuildException if the build failed.\r\n     */\r\n    public void executeTarget(String targetName) throws BuildException {\r\n\r\n        // sanity check ourselves, if we\'ve been asked to build nothing\r\n        // then we should complain\r\n\r\n        if (targetName == null) {\r\n            String msg = \"No target specified\";\r\n            throw new BuildException(msg);\r\n        }\r\n\r\n        // Sort and run the dependency tree.\r\n        // Sorting checks if all the targets (and dependencies)\r\n        // exist, and if there is any cycle in the dependency\r\n        // graph.\r\n        executeSortedTargets(topoSort(targetName, targets, false));\r\n    }\r\n\r\n    /**\r\n     * Execute a <code>Vector</code> of sorted targets.\r\n     * @param sortedTargets   the aforementioned <code>Vector</code>.\r\n     * @throws BuildException on error.\r\n     */\r\n    public void executeSortedTargets(Vector sortedTargets)\r\n        throws BuildException {\r\n        Set succeededTargets = new HashSet();\r\n        BuildException buildException = null; // first build exception\r\n        for (Enumeration iter = sortedTargets.elements();\r\n             iter.hasMoreElements();) {\r\n            Target curtarget = (Target) iter.nextElement();\r\n            boolean canExecute = true;\r\n            for (Enumeration depIter = curtarget.getDependencies();\r\n                 depIter.hasMoreElements();) {\r\n                String dependencyName = ((String) depIter.nextElement());\r\n                if (!succeededTargets.contains(dependencyName)) {\r\n                    canExecute = false;\r\n                    log(curtarget,\r\n                        \"Cannot execute \'\" + curtarget.getName() + \"\' - \'\"\r\n                        + dependencyName + \"\' failed or was not executed.\",\r\n                        MSG_ERR);\r\n                    break;\r\n                }\r\n            }\r\n            if (canExecute) {\r\n                Throwable thrownException = null;\r\n                try {\r\n                    curtarget.performTasks();\r\n                    succeededTargets.add(curtarget.getName());\r\n                } catch (RuntimeException ex) {\r\n                    if (!(keepGoingMode)) {\r\n                        throw ex; // throw further\r\n                    }\r\n                    thrownException = ex;\r\n                } catch (Throwable ex) {\r\n                    if (!(keepGoingMode)) {\r\n                        throw new BuildException(ex);\r\n                    }\r\n                    thrownException = ex;\r\n                }\r\n                if (thrownException != null) {\r\n                    if (thrownException instanceof BuildException) {\r\n                        log(curtarget,\r\n                            \"Target \'\" + curtarget.getName()\r\n                            + \"\' failed with message \'\"\r\n                            + thrownException.getMessage() + \"\'.\", MSG_ERR);\r\n                        // only the first build exception is reported\r\n                        if (buildException == null) {\r\n                            buildException = (BuildException) thrownException;\r\n                        }\r\n                    } else {\r\n                        log(curtarget,\r\n                            \"Target \'\" + curtarget.getName()\r\n                            + \"\' failed with message \'\"\r\n                            + thrownException.getMessage() + \"\'.\", MSG_ERR);\r\n                        thrownException.printStackTrace(System.err);\r\n                        if (buildException == null) {\r\n                            buildException =\r\n                                new BuildException(thrownException);\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        if (buildException != null) {\r\n            throw buildException;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Return the canonical form of a filename.\r\n     * <p>\r\n     * If the specified file name is relative it is resolved\r\n     * with respect to the given root directory.\r\n     *\r\n     * @param fileName The name of the file to resolve.\r\n     *                 Must not be <code>null</code>.\r\n     *\r\n     * @param rootDir  The directory respective to which relative file names\r\n     *                 are resolved. May be <code>null</code>, in which case\r\n     *                 the current directory is used.\r\n     *\r\n     * @return the resolved File.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public File resolveFile(String fileName, File rootDir) {\r\n        return FILE_UTILS.resolveFile(rootDir, fileName);\r\n    }\r\n\r\n    /**\r\n     * Return the canonical form of a filename.\r\n     * <p>\r\n     * If the specified file name is relative it is resolved\r\n     * with respect to the project\'s base directory.\r\n     *\r\n     * @param fileName The name of the file to resolve.\r\n     *                 Must not be <code>null</code>.\r\n     *\r\n     * @return the resolved File.\r\n     *\r\n     */\r\n    public File resolveFile(String fileName) {\r\n        return FILE_UTILS.resolveFile(baseDir, fileName);\r\n    }\r\n\r\n    /**\r\n     * Translate a path into its native (platform specific) format.\r\n     * <p>\r\n     * This method uses PathTokenizer to separate the input path\r\n     * into its components. This handles DOS style paths in a relatively\r\n     * sensible way. The file separators are then converted to their platform\r\n     * specific versions.\r\n     *\r\n     * @param toProcess The path to be translated.\r\n     *                  May be <code>null</code>.\r\n     *\r\n     * @return the native version of the specified path or\r\n     *         an empty string if the path is <code>null</code> or empty.\r\n     *\r\n     * @deprecated since 1.7\r\n     *             Use FileUtils.translatePath instead.\r\n     *\r\n     * @see PathTokenizer\r\n     */\r\n    public static String translatePath(String toProcess) {\r\n        return FileUtils.translatePath(toProcess);\r\n    }\r\n\r\n    /**\r\n     * Convenience method to copy a file from a source to a destination.\r\n     * No filtering is performed.\r\n     *\r\n     * @param sourceFile Name of file to copy from.\r\n     *                   Must not be <code>null</code>.\r\n     * @param destFile Name of file to copy to.\r\n     *                 Must not be <code>null</code>.\r\n     *\r\n     * @exception IOException if the copying fails.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public void copyFile(String sourceFile, String destFile)\r\n          throws IOException {\r\n        FILE_UTILS.copyFile(sourceFile, destFile);\r\n    }\r\n\r\n    /**\r\n     * Convenience method to copy a file from a source to a destination\r\n     * specifying if token filtering should be used.\r\n     *\r\n     * @param sourceFile Name of file to copy from.\r\n     *                   Must not be <code>null</code>.\r\n     * @param destFile Name of file to copy to.\r\n     *                 Must not be <code>null</code>.\r\n     * @param filtering Whether or not token filtering should be used during\r\n     *                  the copy.\r\n     *\r\n     * @exception IOException if the copying fails.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public void copyFile(String sourceFile, String destFile, boolean filtering)\r\n        throws IOException {\r\n        FILE_UTILS.copyFile(sourceFile, destFile,\r\n            filtering ? globalFilters : null);\r\n    }\r\n\r\n    /**\r\n     * Convenience method to copy a file from a source to a\r\n     * destination specifying if token filtering should be used and if\r\n     * source files may overwrite newer destination files.\r\n     *\r\n     * @param sourceFile Name of file to copy from.\r\n     *                   Must not be <code>null</code>.\r\n     * @param destFile Name of file to copy to.\r\n     *                 Must not be <code>null</code>.\r\n     * @param filtering Whether or not token filtering should be used during\r\n     *                  the copy.\r\n     * @param overwrite Whether or not the destination file should be\r\n     *                  overwritten if it already exists.\r\n     *\r\n     * @exception IOException if the copying fails.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public void copyFile(String sourceFile, String destFile, boolean filtering,\r\n                         boolean overwrite) throws IOException {\r\n        FILE_UTILS.copyFile(sourceFile, destFile,\r\n            filtering ? globalFilters : null, overwrite);\r\n    }\r\n\r\n    /**\r\n     * Convenience method to copy a file from a source to a\r\n     * destination specifying if token filtering should be used, if\r\n     * source files may overwrite newer destination files, and if the\r\n     * last modified time of the resulting file should be set to\r\n     * that of the source file.\r\n     *\r\n     * @param sourceFile Name of file to copy from.\r\n     *                   Must not be <code>null</code>.\r\n     * @param destFile Name of file to copy to.\r\n     *                 Must not be <code>null</code>.\r\n     * @param filtering Whether or not token filtering should be used during\r\n     *                  the copy.\r\n     * @param overwrite Whether or not the destination file should be\r\n     *                  overwritten if it already exists.\r\n     * @param preserveLastModified Whether or not the last modified time of\r\n     *                             the resulting file should be set to that\r\n     *                             of the source file.\r\n     *\r\n     * @exception IOException if the copying fails.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public void copyFile(String sourceFile, String destFile, boolean filtering,\r\n                         boolean overwrite, boolean preserveLastModified)\r\n        throws IOException {\r\n        FILE_UTILS.copyFile(sourceFile, destFile,\r\n            filtering ? globalFilters : null, overwrite, preserveLastModified);\r\n    }\r\n\r\n    /**\r\n     * Convenience method to copy a file from a source to a destination.\r\n     * No filtering is performed.\r\n     *\r\n     * @param sourceFile File to copy from.\r\n     *                   Must not be <code>null</code>.\r\n     * @param destFile File to copy to.\r\n     *                 Must not be <code>null</code>.\r\n     *\r\n     * @exception IOException if the copying fails.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public void copyFile(File sourceFile, File destFile) throws IOException {\r\n        FILE_UTILS.copyFile(sourceFile, destFile);\r\n    }\r\n\r\n    /**\r\n     * Convenience method to copy a file from a source to a destination\r\n     * specifying if token filtering should be used.\r\n     *\r\n     * @param sourceFile File to copy from.\r\n     *                   Must not be <code>null</code>.\r\n     * @param destFile File to copy to.\r\n     *                 Must not be <code>null</code>.\r\n     * @param filtering Whether or not token filtering should be used during\r\n     *                  the copy.\r\n     *\r\n     * @exception IOException if the copying fails.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public void copyFile(File sourceFile, File destFile, boolean filtering)\r\n        throws IOException {\r\n        FILE_UTILS.copyFile(sourceFile, destFile,\r\n            filtering ? globalFilters : null);\r\n    }\r\n\r\n    /**\r\n     * Convenience method to copy a file from a source to a\r\n     * destination specifying if token filtering should be used and if\r\n     * source files may overwrite newer destination files.\r\n     *\r\n     * @param sourceFile File to copy from.\r\n     *                   Must not be <code>null</code>.\r\n     * @param destFile File to copy to.\r\n     *                 Must not be <code>null</code>.\r\n     * @param filtering Whether or not token filtering should be used during\r\n     *                  the copy.\r\n     * @param overwrite Whether or not the destination file should be\r\n     *                  overwritten if it already exists.\r\n     *\r\n     * @exception IOException if the file cannot be copied.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public void copyFile(File sourceFile, File destFile, boolean filtering,\r\n                         boolean overwrite) throws IOException {\r\n        FILE_UTILS.copyFile(sourceFile, destFile,\r\n            filtering ? globalFilters : null, overwrite);\r\n    }\r\n\r\n    /**\r\n     * Convenience method to copy a file from a source to a\r\n     * destination specifying if token filtering should be used, if\r\n     * source files may overwrite newer destination files, and if the\r\n     * last modified time of the resulting file should be set to\r\n     * that of the source file.\r\n     *\r\n     * @param sourceFile File to copy from.\r\n     *                   Must not be <code>null</code>.\r\n     * @param destFile File to copy to.\r\n     *                 Must not be <code>null</code>.\r\n     * @param filtering Whether or not token filtering should be used during\r\n     *                  the copy.\r\n     * @param overwrite Whether or not the destination file should be\r\n     *                  overwritten if it already exists.\r\n     * @param preserveLastModified Whether or not the last modified time of\r\n     *                             the resulting file should be set to that\r\n     *                             of the source file.\r\n     *\r\n     * @exception IOException if the file cannot be copied.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     */\r\n    public void copyFile(File sourceFile, File destFile, boolean filtering,\r\n                         boolean overwrite, boolean preserveLastModified)\r\n        throws IOException {\r\n        FILE_UTILS.copyFile(sourceFile, destFile,\r\n            filtering ? globalFilters : null, overwrite, preserveLastModified);\r\n    }\r\n\r\n    /**\r\n     * Call File.setLastModified(long time) on Java above 1.1, and logs\r\n     * a warning on Java 1.1.\r\n     *\r\n     * @param file The file to set the last modified time on.\r\n     *             Must not be <code>null</code>.\r\n     *\r\n     * @param time the required modification time.\r\n     *\r\n     * @deprecated since 1.4.x\r\n     *\r\n     * @exception BuildException if the last modified time cannot be set\r\n     *                           despite running on a platform with a version\r\n     *                           above 1.1.\r\n     */\r\n    public void setFileLastModified(File file, long time)\r\n         throws BuildException {\r\n        FILE_UTILS.setFileLastModified(file, time);\r\n        log(\"Setting modification time for \" + file, MSG_VERBOSE);\r\n    }\r\n\r\n    /**\r\n     * Return the boolean equivalent of a string, which is considered\r\n     * <code>true</code> if either <code>\"on\"</code>, <code>\"true\"</code>,\r\n     * or <code>\"yes\"</code> is found, ignoring case.\r\n     *\r\n     * @param s The string to convert to a boolean value.\r\n     *\r\n     * @return <code>true</code> if the given string is <code>\"on\"</code>,\r\n     *         <code>\"true\"</code> or <code>\"yes\"</code>, or\r\n     *         <code>false</code> otherwise.\r\n     */\r\n    public static boolean toBoolean(String s) {\r\n        return (\"on\".equalsIgnoreCase(s)\r\n                || \"true\".equalsIgnoreCase(s)\r\n                || \"yes\".equalsIgnoreCase(s));\r\n    }\r\n\r\n    /**\r\n     * Get the Project instance associated with the specified object.\r\n     * @param o the object to query.\r\n     * @return Project instance, if any.\r\n     * @since Ant 1.7.1\r\n     */\r\n    public static Project getProject(Object o) {\r\n        if (o instanceof ProjectComponent) {\r\n            return ((ProjectComponent) o).getProject();\r\n        }\r\n        try {\r\n            Method m = o.getClass().getMethod(\"getProject\", (Class[]) null);\r\n            if (Project.class == m.getReturnType()) {\r\n                return (Project) m.invoke(o, (Object[]) null);\r\n            }\r\n        } catch (Exception e) {\r\n            //too bad\r\n        }\r\n        return null;\r\n    }\r\n\r\n    /**\r\n     * Topologically sort a set of targets.  Equivalent to calling\r\n     * <code>topoSort(new String[] {root}, targets, true)</code>.\r\n     *\r\n     * @param root The name of the root target. The sort is created in such\r\n     *             a way that the sequence of Targets up to the root\r\n     *             target is the minimum possible such sequence.\r\n     *             Must not be <code>null</code>.\r\n     * @param targetTable A Hashtable mapping names to Targets.\r\n     *                Must not be <code>null</code>.\r\n     * @return a Vector of ALL Target objects in sorted order.\r\n     * @exception BuildException if there is a cyclic dependency among the\r\n     *                           targets, or if a named target does not exist.\r\n     */\r\n    public final Vector topoSort(String root, Hashtable targetTable)\r\n        throws BuildException {\r\n        return topoSort(new String[] {root}, targetTable, true);\r\n    }\r\n\r\n    /**\r\n     * Topologically sort a set of targets.  Equivalent to calling\r\n     * <code>topoSort(new String[] {root}, targets, returnAll)</code>.\r\n     *\r\n     * @param root The name of the root target. The sort is created in such\r\n     *             a way that the sequence of Targets up to the root\r\n     *             target is the minimum possible such sequence.\r\n     *             Must not be <code>null</code>.\r\n     * @param targetTable A Hashtable mapping names to Targets.\r\n     *                Must not be <code>null</code>.\r\n     * @param returnAll <code>boolean</code> indicating whether to return all\r\n     *                  targets, or the execution sequence only.\r\n     * @return a Vector of Target objects in sorted order.\r\n     * @exception BuildException if there is a cyclic dependency among the\r\n     *                           targets, or if a named target does not exist.\r\n     * @since Ant 1.6.3\r\n     */\r\n    public final Vector topoSort(String root, Hashtable targetTable,\r\n                                 boolean returnAll) throws BuildException {\r\n        return topoSort(new String[] {root}, targetTable, returnAll);\r\n    }\r\n\r\n    /**\r\n     * Topologically sort a set of targets.\r\n     *\r\n     * @param root <code>String[]</code> containing the names of the root targets.\r\n     *             The sort is created in such a way that the ordered sequence of\r\n     *             Targets is the minimum possible such sequence to the specified\r\n     *             root targets.\r\n     *             Must not be <code>null</code>.\r\n     * @param targetTable A map of names to targets (String to Target).\r\n     *                Must not be <code>null</code>.\r\n     * @param returnAll <code>boolean</code> indicating whether to return all\r\n     *                  targets, or the execution sequence only.\r\n     * @return a Vector of Target objects in sorted order.\r\n     * @exception BuildException if there is a cyclic dependency among the\r\n     *                           targets, or if a named target does not exist.\r\n     * @since Ant 1.6.3\r\n     */\r\n    public final Vector topoSort(String[] root, Hashtable targetTable,\r\n                                 boolean returnAll) throws BuildException {\r\n        Vector ret = new VectorSet();\r\n        Hashtable state = new Hashtable();\r\n        Stack visiting = new Stack();\r\n\r\n        // We first run a DFS based sort using each root as a starting node.\r\n        // This creates the minimum sequence of Targets to the root node(s).\r\n        // We then do a sort on any remaining unVISITED targets.\r\n        // This is unnecessary for doing our build, but it catches\r\n        // circular dependencies or missing Targets on the entire\r\n        // dependency tree, not just on the Targets that depend on the\r\n        // build Target.\r\n\r\n        for (int i = 0; i < root.length; i++) {\r\n            String st = (String) (state.get(root[i]));\r\n            if (st == null) {\r\n                tsort(root[i], targetTable, state, visiting, ret);\r\n            } else if (st == VISITING) {\r\n                throw new RuntimeException(\"Unexpected node in visiting state: \"\r\n                    + root[i]);\r\n            }\r\n        }\r\n        StringBuffer buf = new StringBuffer(\"Build sequence for target(s)\");\r\n\r\n        for (int j = 0; j < root.length; j++) {\r\n            buf.append((j == 0) ? \" `\" : \", `\").append(root[j]).append(\'\\\'\');\r\n        }\r\n        buf.append(\" is \" + ret);\r\n        log(buf.toString(), MSG_VERBOSE);\r\n\r\n        Vector complete = (returnAll) ? ret : new Vector(ret);\r\n        for (Enumeration en = targetTable.keys(); en.hasMoreElements();) {\r\n            String curTarget = (String) en.nextElement();\r\n            String st = (String) state.get(curTarget);\r\n            if (st == null) {\r\n                tsort(curTarget, targetTable, state, visiting, complete);\r\n            } else if (st == VISITING) {\r\n                throw new RuntimeException(\"Unexpected node in visiting state: \"\r\n                    + curTarget);\r\n            }\r\n        }\r\n        log(\"Complete build sequence is \" + complete, MSG_VERBOSE);\r\n        return ret;\r\n    }\r\n\r\n    /**\r\n     * Perform a single step in a recursive depth-first-search traversal of\r\n     * the target dependency tree.\r\n     * <p>\r\n     * The current target is first set to the &quot;visiting&quot; state, and\r\n     * pushed onto the &quot;visiting&quot; stack.\r\n     * <p>\r\n     * An exception is then thrown if any child of the current node is in the\r\n     * visiting state, as that implies a circular dependency. The exception\r\n     * contains details of the cycle, using elements of the &quot;visiting&quot;\r\n     * stack.\r\n     * <p>\r\n     * If any child has not already been &quot;visited&quot;, this method is\r\n     * called recursively on it.\r\n     * <p>\r\n     * The current target is then added to the ordered list of targets. Note\r\n     * that this is performed after the children have been visited in order\r\n     * to get the correct order. The current target is set to the\r\n     * &quot;visited&quot; state.\r\n     * <p>\r\n     * By the time this method returns, the ordered list contains the sequence\r\n     * of targets up to and including the current target.\r\n     *\r\n     * @param root The current target to inspect.\r\n     *             Must not be <code>null</code>.\r\n     * @param targetTable A mapping from names to targets (String to Target).\r\n     *                Must not be <code>null</code>.\r\n     * @param state   A mapping from target names to states (String to String).\r\n     *                The states in question are &quot;VISITING&quot; and\r\n     *                &quot;VISITED&quot;. Must not be <code>null</code>.\r\n     * @param visiting A stack of targets which are currently being visited.\r\n     *                 Must not be <code>null</code>.\r\n     * @param ret     The list to add target names to. This will end up\r\n     *                containing the complete list of dependencies in\r\n     *                dependency order.\r\n     *                Must not be <code>null</code>.\r\n     *\r\n     * @exception BuildException if a non-existent target is specified or if\r\n     *                           a circular dependency is detected.\r\n     */\r\n    private void tsort(String root, Hashtable targetTable,\r\n                             Hashtable state, Stack visiting,\r\n                             Vector ret)\r\n        throws BuildException {\r\n        state.put(root, VISITING);\r\n        visiting.push(root);\r\n\r\n        Target target = (Target) targetTable.get(root);\r\n\r\n        // Make sure we exist\r\n        if (target == null) {\r\n            StringBuffer sb = new StringBuffer(\"Target \\\"\");\r\n            sb.append(root);\r\n            sb.append(\"\\\" does not exist in the project \\\"\");\r\n            sb.append(name);\r\n            sb.append(\"\\\". \");\r\n            visiting.pop();\r\n            if (!visiting.empty()) {\r\n                String parent = (String) visiting.peek();\r\n                sb.append(\"It is used from target \\\"\");\r\n                sb.append(parent);\r\n                sb.append(\"\\\".\");\r\n            }\r\n            throw new BuildException(new String(sb));\r\n        }\r\n        for (Enumeration en = target.getDependencies(); en.hasMoreElements();) {\r\n            String cur = (String) en.nextElement();\r\n            String m = (String) state.get(cur);\r\n            if (m == null) {\r\n                // Not been visited\r\n                tsort(cur, targetTable, state, visiting, ret);\r\n            } else if (m == VISITING) {\r\n                // Currently visiting this node, so have a cycle\r\n                throw makeCircularException(cur, visiting);\r\n            }\r\n        }\r\n        String p = (String) visiting.pop();\r\n        if (root != p) {\r\n            throw new RuntimeException(\"Unexpected internal error: expected to \"\r\n                + \"pop \" + root + \" but got \" + p);\r\n        }\r\n        state.put(root, VISITED);\r\n        ret.addElement(target);\r\n    }\r\n\r\n    /**\r\n     * Build an appropriate exception detailing a specified circular\r\n     * dependency.\r\n     *\r\n     * @param end The dependency to stop at. Must not be <code>null</code>.\r\n     * @param stk A stack of dependencies. Must not be <code>null</code>.\r\n     *\r\n     * @return a BuildException detailing the specified circular dependency.\r\n     */\r\n    private static BuildException makeCircularException(String end, Stack stk) {\r\n        StringBuffer sb = new StringBuffer(\"Circular dependency: \");\r\n        sb.append(end);\r\n        String c;\r\n        do {\r\n            c = (String) stk.pop();\r\n            sb.append(\" <- \");\r\n            sb.append(c);\r\n        } while (!c.equals(end));\r\n        return new BuildException(new String(sb));\r\n    }\r\n\r\n    /**\r\n     * Inherit the id references.\r\n     * @param parent the parent project of this project.\r\n     */\r\n    public void inheritIDReferences(Project parent) {\r\n        parentIdProject = parent;\r\n    }\r\n\r\n    /**\r\n     * Add an id reference.\r\n     * Used for broken build files.\r\n     * @param id the id to set.\r\n     * @param value the value to set it to (Unknown element in this case.\r\n     */\r\n    public void addIdReference(String id, Object value) {\r\n        idReferences.put(id, value);\r\n    }\r\n\r\n    /**\r\n     * Add a reference to the project.\r\n     *\r\n     * @param referenceName The name of the reference. Must not be <code>null</code>.\r\n     * @param value The value of the reference.\r\n     */\r\n    public void addReference(String referenceName, Object value) {\r\n        Object old = ((AntRefTable) references).getReal(referenceName);\r\n        if (old == value) {\r\n            // no warning, this is not changing anything\r\n            return;\r\n        }\r\n        if (old != null && !(old instanceof UnknownElement)) {\r\n            log(\"Overriding previous definition of reference to \" + referenceName,\r\n                MSG_VERBOSE);\r\n        }\r\n        log(\"Adding reference: \" + referenceName, MSG_DEBUG);\r\n        references.put(referenceName, value);\r\n    }\r\n\r\n    /**\r\n     * Return a map of the references in the project (String to Object).\r\n     * The returned hashtable is &quot;live&quot; and so must not be modified.\r\n     *\r\n     * @return a map of the references in the project (String to Object).\r\n     */\r\n    public Hashtable getReferences() {\r\n        return references;\r\n    }\r\n\r\n    /**\r\n     * Does the project know this reference?\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    public boolean hasReference(String key) {\r\n        return references.containsKey(key);\r\n    }\r\n\r\n    /**\r\n     * Return a map of the references in the project (String to\r\n     * Object).  The returned hashtable is a copy of the\r\n     * &quot;live&quot; references.\r\n     *\r\n     * @return a map of the references in the project (String to Object).\r\n     *\r\n     * @since Ant 1.8.1\r\n     */\r\n    public Map getCopyOfReferences() {\r\n        return new HashMap(references);\r\n    }\r\n\r\n    /**\r\n     * Look up a reference by its key (ID).\r\n     *\r\n     * @param key The key for the desired reference.\r\n     *            Must not be <code>null</code>.\r\n     *\r\n     * @return the reference with the specified ID, or <code>null</code> if\r\n     *         there is no such reference in the project.\r\n     */\r\n    public Object getReference(String key) {\r\n        Object ret = references.get(key);\r\n        if (ret != null) {\r\n            return ret;\r\n        }\r\n        if (!key.equals(MagicNames.REFID_PROPERTY_HELPER)) {\r\n            try {\r\n                if (PropertyHelper.getPropertyHelper(this).containsProperties(key)) {\r\n                    log(\"Unresolvable reference \" + key\r\n                            + \" might be a misuse of property expansion syntax.\", MSG_WARN);\r\n                }\r\n            } catch (Exception e) {\r\n                //ignore\r\n            }\r\n        }\r\n        return ret;\r\n    }\r\n\r\n    /**\r\n     * Return a description of the type of the given element, with\r\n     * special handling for instances of tasks and data types.\r\n     * <p>\r\n     * This is useful for logging purposes.\r\n     *\r\n     * @param element The element to describe.\r\n     *                Must not be <code>null</code>.\r\n     *\r\n     * @return a description of the element type.\r\n     *\r\n     * @since 1.95, Ant 1.5\r\n     */\r\n    public String getElementName(Object element) {\r\n        return ComponentHelper.getComponentHelper(this).getElementName(element);\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;build started&quot; event\r\n     * to the build listeners for this project.\r\n     */\r\n    public void fireBuildStarted() {\r\n        BuildEvent event = new BuildEvent(this);\r\n        BuildListener[] currListeners = listeners;\r\n        for (int i = 0; i < currListeners.length; i++) {\r\n            currListeners[i].buildStarted(event);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;build finished&quot; event to the build listeners\r\n     * for this project.\r\n     * @param exception an exception indicating a reason for a build\r\n     *                  failure. May be <code>null</code>, indicating\r\n     *                  a successful build.\r\n     */\r\n    public void fireBuildFinished(Throwable exception) {\r\n        BuildEvent event = new BuildEvent(this);\r\n        event.setException(exception);\r\n        BuildListener[] currListeners = listeners;\r\n        for (int i = 0; i < currListeners.length; i++) {\r\n            currListeners[i].buildFinished(event);\r\n        }\r\n        // Inform IH to clear the cache\r\n        IntrospectionHelper.clearCache();\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;subbuild started&quot; event to the build listeners for\r\n     * this project.\r\n     *\r\n     * @since Ant 1.6.2\r\n     */\r\n    public void fireSubBuildStarted() {\r\n        BuildEvent event = new BuildEvent(this);\r\n        BuildListener[] currListeners = listeners;\r\n        for (int i = 0; i < currListeners.length; i++) {\r\n            if (currListeners[i] instanceof SubBuildListener) {\r\n                ((SubBuildListener) currListeners[i]).subBuildStarted(event);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;subbuild finished&quot; event to the build listeners for\r\n     * this project.\r\n     * @param exception an exception indicating a reason for a build\r\n     *                  failure. May be <code>null</code>, indicating\r\n     *                  a successful build.\r\n     *\r\n     * @since Ant 1.6.2\r\n     */\r\n    public void fireSubBuildFinished(Throwable exception) {\r\n        BuildEvent event = new BuildEvent(this);\r\n        event.setException(exception);\r\n        BuildListener[] currListeners = listeners;\r\n        for (int i = 0; i < currListeners.length; i++) {\r\n            if (currListeners[i] instanceof SubBuildListener) {\r\n                ((SubBuildListener) currListeners[i]).subBuildFinished(event);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;target started&quot; event to the build listeners\r\n     * for this project.\r\n     *\r\n     * @param target The target which is starting to build.\r\n     *               Must not be <code>null</code>.\r\n     */\r\n    protected void fireTargetStarted(Target target) {\r\n        BuildEvent event = new BuildEvent(target);\r\n        BuildListener[] currListeners = listeners;\r\n        for (int i = 0; i < currListeners.length; i++) {\r\n            currListeners[i].targetStarted(event);\r\n        }\r\n\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;target finished&quot; event to the build listeners\r\n     * for this project.\r\n     *\r\n     * @param target    The target which has finished building.\r\n     *                  Must not be <code>null</code>.\r\n     * @param exception an exception indicating a reason for a build\r\n     *                  failure. May be <code>null</code>, indicating\r\n     *                  a successful build.\r\n     */\r\n    protected void fireTargetFinished(Target target, Throwable exception) {\r\n        BuildEvent event = new BuildEvent(target);\r\n        event.setException(exception);\r\n        BuildListener[] currListeners = listeners;\r\n        for (int i = 0; i < currListeners.length; i++) {\r\n            currListeners[i].targetFinished(event);\r\n        }\r\n\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;task started&quot; event to the build listeners\r\n     * for this project.\r\n     *\r\n     * @param task The target which is starting to execute.\r\n     *               Must not be <code>null</code>.\r\n     */\r\n    protected void fireTaskStarted(Task task) {\r\n        // register this as the current task on the current thread.\r\n        registerThreadTask(Thread.currentThread(), task);\r\n        BuildEvent event = new BuildEvent(task);\r\n        BuildListener[] currListeners = listeners;\r\n        for (int i = 0; i < currListeners.length; i++) {\r\n            currListeners[i].taskStarted(event);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;task finished&quot; event to the build listeners for this\r\n     * project.\r\n     *\r\n     * @param task      The task which has finished executing.\r\n     *                  Must not be <code>null</code>.\r\n     * @param exception an exception indicating a reason for a build\r\n     *                  failure. May be <code>null</code>, indicating\r\n     *                  a successful build.\r\n     */\r\n    protected void fireTaskFinished(Task task, Throwable exception) {\r\n        registerThreadTask(Thread.currentThread(), null);\r\n        System.out.flush();\r\n        System.err.flush();\r\n        BuildEvent event = new BuildEvent(task);\r\n        event.setException(exception);\r\n        BuildListener[] currListeners = listeners;\r\n        for (int i = 0; i < currListeners.length; i++) {\r\n            currListeners[i].taskFinished(event);\r\n        }\r\n\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;message logged&quot; event to the build listeners\r\n     * for this project.\r\n     *\r\n     * @param event    The event to send. This should be built up with the\r\n     *                 appropriate task/target/project by the caller, so that\r\n     *                 this method can set the message and priority, then send\r\n     *                 the event. Must not be <code>null</code>.\r\n     * @param message  The message to send. Should not be <code>null</code>.\r\n     * @param priority The priority of the message.\r\n     */\r\n    private void fireMessageLoggedEvent(BuildEvent event, String message,\r\n                                        int priority) {\r\n\r\n        if (message == null) {\r\n            message = String.valueOf(message);\r\n        }\r\n        if (message.endsWith(StringUtils.LINE_SEP)) {\r\n            int endIndex = message.length() - StringUtils.LINE_SEP.length();\r\n            event.setMessage(message.substring(0, endIndex), priority);\r\n        } else {\r\n            event.setMessage(message, priority);\r\n        }\r\n        if (isLoggingMessage.get() != Boolean.FALSE) {\r\n            /*\r\n             * One of the Listeners has attempted to access\r\n             * System.err or System.out.\r\n             *\r\n             * We used to throw an exception in this case, but\r\n             * sometimes Listeners can\'t prevent it(like our own\r\n             * Log4jListener which invokes getLogger() which in\r\n             * turn wants to write to the console).\r\n             *\r\n             * @see http://marc.theaimsgroup.com/?t=110538624200006&r=1&w=2\r\n             *\r\n             * We now (Ant 1.6.3 and later) simply swallow the message.\r\n             */\r\n            return;\r\n        }\r\n        try {\r\n            isLoggingMessage.set(Boolean.TRUE);\r\n            BuildListener[] currListeners = listeners;\r\n            for (int i = 0; i < currListeners.length; i++) {\r\n                currListeners[i].messageLogged(event);\r\n            }\r\n        } finally {\r\n            isLoggingMessage.set(Boolean.FALSE);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;message logged&quot; project level event\r\n     * to the build listeners for this project.\r\n     *\r\n     * @param project  The project generating the event.\r\n     *                 Should not be <code>null</code>.\r\n     * @param message  The message to send. Should not be <code>null</code>.\r\n     * @param priority The priority of the message.\r\n     */\r\n    protected void fireMessageLogged(Project project, String message,\r\n                                     int priority) {\r\n        fireMessageLogged(project, message, null, priority);\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;message logged&quot; project level event\r\n     * to the build listeners for this project.\r\n     *\r\n     * @param project  The project generating the event.\r\n     *                 Should not be <code>null</code>.\r\n     * @param message  The message to send. Should not be <code>null</code>.\r\n     * @param throwable The exception that caused this message. May be <code>null</code>.\r\n     * @param priority The priority of the message.\r\n     * @since 1.7\r\n     */\r\n    protected void fireMessageLogged(Project project, String message,\r\n            Throwable throwable, int priority) {\r\n        BuildEvent event = new BuildEvent(project);\r\n        event.setException(throwable);\r\n        fireMessageLoggedEvent(event, message, priority);\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;message logged&quot; target level event\r\n     * to the build listeners for this project.\r\n     *\r\n     * @param target   The target generating the event.\r\n     *                 Must not be <code>null</code>.\r\n     * @param message  The message to send. Should not be <code>null</code>.\r\n     * @param priority The priority of the message.\r\n     */\r\n    protected void fireMessageLogged(Target target, String message,\r\n                                     int priority) {\r\n        fireMessageLogged(target, message, null, priority);\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;message logged&quot; target level event\r\n     * to the build listeners for this project.\r\n     *\r\n     * @param target   The target generating the event.\r\n     *                 Must not be <code>null</code>.\r\n     * @param message  The message to send. Should not be <code>null</code>.\r\n     * @param throwable The exception that caused this message. May be <code>null</code>.\r\n     * @param priority The priority of the message.\r\n     * @since 1.7\r\n     */\r\n    protected void fireMessageLogged(Target target, String message,\r\n            Throwable throwable, int priority) {\r\n        BuildEvent event = new BuildEvent(target);\r\n        event.setException(throwable);\r\n        fireMessageLoggedEvent(event, message, priority);\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;message logged&quot; task level event\r\n     * to the build listeners for this project.\r\n     *\r\n     * @param task     The task generating the event.\r\n     *                 Must not be <code>null</code>.\r\n     * @param message  The message to send. Should not be <code>null</code>.\r\n     * @param priority The priority of the message.\r\n     */\r\n    protected void fireMessageLogged(Task task, String message, int priority) {\r\n        fireMessageLogged(task, message, null, priority);\r\n    }\r\n\r\n    /**\r\n     * Send a &quot;message logged&quot; task level event\r\n     * to the build listeners for this project.\r\n     *\r\n     * @param task     The task generating the event.\r\n     *                 Must not be <code>null</code>.\r\n     * @param message  The message to send. Should not be <code>null</code>.\r\n     * @param throwable The exception that caused this message. May be <code>null</code>.\r\n     * @param priority The priority of the message.\r\n     * @since 1.7\r\n     */\r\n    protected void fireMessageLogged(Task task, String message,\r\n            Throwable throwable, int priority) {\r\n        BuildEvent event = new BuildEvent(task);\r\n        event.setException(throwable);\r\n        fireMessageLoggedEvent(event, message, priority);\r\n    }\r\n\r\n    /**\r\n     * Register a task as the current task for a thread.\r\n     * If the task is null, the thread\'s entry is removed.\r\n     *\r\n     * @param thread the thread on which the task is registered.\r\n     * @param task the task to be registered.\r\n     * @since Ant 1.5\r\n     */\r\n    public void registerThreadTask(Thread thread, Task task) {\r\n        synchronized(threadTasks) {\r\n            if (task != null) {\r\n                threadTasks.put(thread, task);\r\n                threadGroupTasks.put(thread.getThreadGroup(), task);\r\n            } else {\r\n                threadTasks.remove(thread);\r\n                threadGroupTasks.remove(thread.getThreadGroup());\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Get the current task associated with a thread, if any.\r\n     *\r\n     * @param thread the thread for which the task is required.\r\n     * @return the task which is currently registered for the given thread or\r\n     *         null if no task is registered.\r\n     */\r\n    public Task getThreadTask(Thread thread) {\r\n        synchronized(threadTasks) {\r\n            Task task = (Task) threadTasks.get(thread);\r\n            if (task == null) {\r\n                ThreadGroup group = thread.getThreadGroup();\r\n                while (task == null && group != null) {\r\n                    task = (Task) threadGroupTasks.get(group);\r\n                    group = group.getParent();\r\n                }\r\n            }\r\n            return task;\r\n        }\r\n    }\r\n\r\n\r\n    // Should move to a separate public class - and have API to add\r\n    // listeners, etc.\r\n    private static class AntRefTable extends Hashtable {\r\n\r\n        AntRefTable() {\r\n            super();\r\n        }\r\n\r\n        /** Returns the unmodified original object.\r\n         * This method should be called internally to\r\n         * get the &quot;real&quot; object.\r\n         * The normal get method will do the replacement\r\n         * of UnknownElement (this is similar with the JDNI\r\n         * refs behavior).\r\n         */\r\n        private Object getReal(Object key) {\r\n            return super.get(key);\r\n        }\r\n\r\n        /** Get method for the reference table.\r\n         *  It can be used to hook dynamic references and to modify\r\n         * some references on the fly--for example for delayed\r\n         * evaluation.\r\n         *\r\n         * It is important to make sure that the processing that is\r\n         * done inside is not calling get indirectly.\r\n         *\r\n         * @param key lookup key.\r\n         * @return mapped value.\r\n         */\r\n        public Object get(Object key) {\r\n            //System.out.println(\"AntRefTable.get \" + key);\r\n            Object o = getReal(key);\r\n            if (o instanceof UnknownElement) {\r\n                // Make sure that\r\n                UnknownElement ue = (UnknownElement) o;\r\n                ue.maybeConfigure();\r\n                o = ue.getRealThing();\r\n            }\r\n            return o;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Set a reference to this Project on the parameterized object.\r\n     * Need to set the project before other set/add elements\r\n     * are called.\r\n     * @param obj the object to invoke setProject(this) on.\r\n     */\r\n    public final void setProjectReference(final Object obj) {\r\n        if (obj instanceof ProjectComponent) {\r\n            ((ProjectComponent) obj).setProject(this);\r\n            return;\r\n        }\r\n        try {\r\n            Method method =\r\n                obj.getClass().getMethod(\r\n                    \"setProject\", new Class[] {Project.class});\r\n            if (method != null) {\r\n                method.invoke(obj, new Object[] {this});\r\n            }\r\n        } catch (Throwable e) {\r\n            // ignore this if the object does not have\r\n            // a set project method or the method\r\n            // is private/protected.\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Resolve the file relative to the project\'s basedir and return it as a\r\n     * FileResource.\r\n     * @param name the name of the file to resolve.\r\n     * @return the file resource.\r\n     * @since Ant 1.7\r\n     */\r\n    public Resource getResource(String name) {\r\n        return new FileResource(getBaseDir(), name);\r\n    }\r\n}','ant','Public Class','org.apache.tools.ant.Project',0,4,'gc'),(6,'dt5.png','/*\r\n *  Licensed to the Apache Software Foundation (ASF) under one or more\r\n *  contributor license agreements.  See the NOTICE file distributed with\r\n *  this work for additional information regarding copyright ownership.\r\n *  The ASF licenses this file to You under the Apache License, Version 2.0\r\n *  (the \"License\"); you may not use this file except in compliance with\r\n *  the License.  You may obtain a copy of the License at\r\n *\r\n *      http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n *  Unless required by applicable law or agreed to in writing, software\r\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\r\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n *  See the License for the specific language governing permissions and\r\n *  limitations under the License.\r\n *\r\n */\r\n\r\npackage org.apache.tools.ant;\r\n\r\nimport java.io.File;\r\nimport java.io.IOException;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.HashMap;\r\nimport java.util.HashSet;\r\nimport java.util.Iterator;\r\nimport java.util.LinkedList;\r\nimport java.util.Map;\r\nimport java.util.Set;\r\nimport java.util.Vector;\r\n\r\nimport org.apache.tools.ant.taskdefs.condition.Os;\r\nimport org.apache.tools.ant.types.Resource;\r\nimport org.apache.tools.ant.types.ResourceFactory;\r\nimport org.apache.tools.ant.types.resources.FileResource;\r\nimport org.apache.tools.ant.types.selectors.FileSelector;\r\nimport org.apache.tools.ant.types.selectors.SelectorScanner;\r\nimport org.apache.tools.ant.types.selectors.SelectorUtils;\r\nimport org.apache.tools.ant.types.selectors.TokenizedPath;\r\nimport org.apache.tools.ant.types.selectors.TokenizedPattern;\r\nimport org.apache.tools.ant.util.CollectionUtils;\r\nimport org.apache.tools.ant.util.FileUtils;\r\nimport org.apache.tools.ant.util.SymbolicLinkUtils;\r\nimport org.apache.tools.ant.util.VectorSet;\r\n\r\n/**\r\n * Class for scanning a directory for files/directories which match certain\r\n * criteria.\r\n * <p>\r\n * These criteria consist of selectors and patterns which have been specified.\r\n * With the selectors you can select which files you want to have included.\r\n * Files which are not selected are excluded. With patterns you can include\r\n * or exclude files based on their filename.\r\n * <p>\r\n * The idea is simple. A given directory is recursively scanned for all files\r\n * and directories. Each file/directory is matched against a set of selectors,\r\n * including special support for matching against filenames with include and\r\n * and exclude patterns. Only files/directories which match at least one\r\n * pattern of the include pattern list or other file selector, and don\'t match\r\n * any pattern of the exclude pattern list or fail to match against a required\r\n * selector will be placed in the list of files/directories found.\r\n * <p>\r\n * When no list of include patterns is supplied, \"**\" will be used, which\r\n * means that everything will be matched. When no list of exclude patterns is\r\n * supplied, an empty list is used, such that nothing will be excluded. When\r\n * no selectors are supplied, none are applied.\r\n * <p>\r\n * The filename pattern matching is done as follows:\r\n * The name to be matched is split up in path segments. A path segment is the\r\n * name of a directory or file, which is bounded by\r\n * <code>File.separator</code> (\'/\' under UNIX, \'\\\' under Windows).\r\n * For example, \"abc/def/ghi/xyz.java\" is split up in the segments \"abc\",\r\n * \"def\",\"ghi\" and \"xyz.java\".\r\n * The same is done for the pattern against which should be matched.\r\n * <p>\r\n * The segments of the name and the pattern are then matched against each\r\n * other. When \'**\' is used for a path segment in the pattern, it matches\r\n * zero or more path segments of the name.\r\n * <p>\r\n * There is a special case regarding the use of <code>File.separator</code>s\r\n * at the beginning of the pattern and the string to match:<br>\r\n * When a pattern starts with a <code>File.separator</code>, the string\r\n * to match must also start with a <code>File.separator</code>.\r\n * When a pattern does not start with a <code>File.separator</code>, the\r\n * string to match may not start with a <code>File.separator</code>.\r\n * When one of these rules is not obeyed, the string will not\r\n * match.\r\n * <p>\r\n * When a name path segment is matched against a pattern path segment, the\r\n * following special characters can be used:<br>\r\n * \'*\' matches zero or more characters<br>\r\n * \'?\' matches one character.\r\n * <p>\r\n * Examples:\r\n * <p>\r\n * \"**\\*.class\" matches all .class files/dirs in a directory tree.\r\n * <p>\r\n * \"test\\a??.java\" matches all files/dirs which start with an \'a\', then two\r\n * more characters and then \".java\", in a directory called test.\r\n * <p>\r\n * \"**\" matches everything in a directory tree.\r\n * <p>\r\n * \"**\\test\\**\\XYZ*\" matches all files/dirs which start with \"XYZ\" and where\r\n * there is a parent directory called test (e.g. \"abc\\test\\def\\ghi\\XYZ123\").\r\n * <p>\r\n * Case sensitivity may be turned off if necessary. By default, it is\r\n * turned on.\r\n * <p>\r\n * Example of usage:\r\n * <pre>\r\n *   String[] includes = {\"**\\\\*.class\"};\r\n *   String[] excludes = {\"modules\\\\*\\\\**\"};\r\n *   ds.setIncludes(includes);\r\n *   ds.setExcludes(excludes);\r\n *   ds.setBasedir(new File(\"test\"));\r\n *   ds.setCaseSensitive(true);\r\n *   ds.scan();\r\n *\r\n *   System.out.println(\"FILES:\");\r\n *   String[] files = ds.getIncludedFiles();\r\n *   for (int i = 0; i < files.length; i++) {\r\n *     System.out.println(files[i]);\r\n *   }\r\n * </pre>\r\n * This will scan a directory called test for .class files, but excludes all\r\n * files in all proper subdirectories of a directory called \"modules\"\r\n *\r\n */\r\npublic class DirectoryScanner\r\n       implements FileScanner, SelectorScanner, ResourceFactory {\r\n\r\n    /** Is OpenVMS the operating system we\'re running on? */\r\n    private static final boolean ON_VMS = Os.isFamily(\"openvms\");\r\n\r\n    /**\r\n     * Patterns which should be excluded by default.\r\n     *\r\n     * <p>Note that you can now add patterns to the list of default\r\n     * excludes.  Added patterns will not become part of this array\r\n     * that has only been kept around for backwards compatibility\r\n     * reasons.</p>\r\n     *\r\n     * @deprecated since 1.6.x.\r\n     *             Use the {@link #getDefaultExcludes getDefaultExcludes}\r\n     *             method instead.\r\n     */\r\n    protected static final String[] DEFAULTEXCLUDES = {\r\n        // Miscellaneous typical temporary files\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/*~\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/#*#\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.#*\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/%*%\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/._*\",\r\n\r\n        // CVS\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/CVS\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/CVS/\" + SelectorUtils.DEEP_TREE_MATCH,\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.cvsignore\",\r\n\r\n        // SCCS\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/SCCS\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/SCCS/\" + SelectorUtils.DEEP_TREE_MATCH,\r\n\r\n        // Visual SourceSafe\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/vssver.scc\",\r\n\r\n        // Subversion\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.svn\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.svn/\" + SelectorUtils.DEEP_TREE_MATCH,\r\n\r\n        // Git\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.git\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.git/\" + SelectorUtils.DEEP_TREE_MATCH,\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.gitattributes\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.gitignore\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.gitmodules\",\r\n\r\n        // Mercurial\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.hg\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.hg/\" + SelectorUtils.DEEP_TREE_MATCH,\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.hgignore\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.hgsub\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.hgsubstate\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.hgtags\",\r\n\r\n        // Bazaar\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.bzr\",\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.bzr/\" + SelectorUtils.DEEP_TREE_MATCH,\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.bzrignore\",\r\n\r\n        // Mac\r\n        SelectorUtils.DEEP_TREE_MATCH + \"/.DS_Store\"\r\n    };\r\n\r\n    /**\r\n     * default value for {@link #maxLevelsOfSymlinks maxLevelsOfSymlinks}\r\n     * @since Ant 1.8.0\r\n     */\r\n    public static final int MAX_LEVELS_OF_SYMLINKS = 5;\r\n    /**\r\n     * The end of the exception message if something that should be\r\n     * there doesn\'t exist.\r\n     */\r\n    public static final String DOES_NOT_EXIST_POSTFIX = \" does not exist.\";\r\n\r\n    /** Helper. */\r\n    private static final FileUtils FILE_UTILS = FileUtils.getFileUtils();\r\n\r\n    /** Helper. */\r\n    private static final SymbolicLinkUtils SYMLINK_UTILS =\r\n        SymbolicLinkUtils.getSymbolicLinkUtils();\r\n\r\n    /**\r\n     * Patterns which should be excluded by default.\r\n     *\r\n     * @see #addDefaultExcludes()\r\n     */\r\n    private static final Set defaultExcludes = new HashSet();\r\n    static {\r\n        resetDefaultExcludes();\r\n    }\r\n\r\n    // CheckStyle:VisibilityModifier OFF - bc\r\n\r\n    /** The base directory to be scanned. */\r\n    protected File basedir;\r\n\r\n    /** The patterns for the files to be included. */\r\n    protected String[] includes;\r\n\r\n    /** The patterns for the files to be excluded. */\r\n    protected String[] excludes;\r\n\r\n    /** Selectors that will filter which files are in our candidate list. */\r\n    protected FileSelector[] selectors = null;\r\n\r\n    /**\r\n     * The files which matched at least one include and no excludes\r\n     * and were selected.\r\n     */\r\n    protected Vector filesIncluded;\r\n\r\n    /** The files which did not match any includes or selectors. */\r\n    protected Vector filesNotIncluded;\r\n\r\n    /**\r\n     * The files which matched at least one include and at least\r\n     * one exclude.\r\n     */\r\n    protected Vector filesExcluded;\r\n\r\n    /**\r\n     * The directories which matched at least one include and no excludes\r\n     * and were selected.\r\n     */\r\n    protected Vector dirsIncluded;\r\n\r\n    /** The directories which were found and did not match any includes. */\r\n    protected Vector dirsNotIncluded;\r\n\r\n    /**\r\n     * The directories which matched at least one include and at least one\r\n     * exclude.\r\n     */\r\n    protected Vector dirsExcluded;\r\n\r\n    /**\r\n     * The files which matched at least one include and no excludes and\r\n     * which a selector discarded.\r\n     */\r\n    protected Vector filesDeselected;\r\n\r\n    /**\r\n     * The directories which matched at least one include and no excludes\r\n     * but which a selector discarded.\r\n     */\r\n    protected Vector dirsDeselected;\r\n\r\n    /** Whether or not our results were built by a slow scan. */\r\n    protected boolean haveSlowResults = false;\r\n\r\n    /**\r\n     * Whether or not the file system should be treated as a case sensitive\r\n     * one.\r\n     */\r\n    protected boolean isCaseSensitive = true;\r\n\r\n    /**\r\n     * Whether a missing base directory is an error.\r\n     * @since Ant 1.7.1\r\n     */\r\n    protected boolean errorOnMissingDir = true;\r\n\r\n    /**\r\n     * Whether or not symbolic links should be followed.\r\n     *\r\n     * @since Ant 1.5\r\n     */\r\n    private boolean followSymlinks = true;\r\n\r\n    /** Whether or not everything tested so far has been included. */\r\n    protected boolean everythingIncluded = true;\r\n\r\n    // CheckStyle:VisibilityModifier ON\r\n\r\n    /**\r\n     * List of all scanned directories.\r\n     *\r\n     * @since Ant 1.6\r\n     */\r\n    private Set scannedDirs = new HashSet();\r\n\r\n    /**\r\n     * Map of all include patterns that are full file names and don\'t\r\n     * contain any wildcards.\r\n     *\r\n     * <p>Maps pattern string to TokenizedPath.</p>\r\n     *\r\n     * <p>If this instance is not case sensitive, the file names get\r\n     * turned to upper case.</p>\r\n     *\r\n     * <p>Gets lazily initialized on the first invocation of\r\n     * isIncluded or isExcluded and cleared at the end of the scan\r\n     * method (cleared in clearCaches, actually).</p>\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    private Map includeNonPatterns = new HashMap();\r\n\r\n    /**\r\n     * Map of all exclude patterns that are full file names and don\'t\r\n     * contain any wildcards.\r\n     *\r\n     * <p>Maps pattern string to TokenizedPath.</p>\r\n     *\r\n     * <p>If this instance is not case sensitive, the file names get\r\n     * turned to upper case.</p>\r\n     *\r\n     * <p>Gets lazily initialized on the first invocation of\r\n     * isIncluded or isExcluded and cleared at the end of the scan\r\n     * method (cleared in clearCaches, actually).</p>\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    private Map excludeNonPatterns = new HashMap();\r\n\r\n    /**\r\n     * Array of all include patterns that contain wildcards.\r\n     *\r\n     * <p>Gets lazily initialized on the first invocation of\r\n     * isIncluded or isExcluded and cleared at the end of the scan\r\n     * method (cleared in clearCaches, actually).</p>\r\n     */\r\n    private TokenizedPattern[] includePatterns;\r\n\r\n    /**\r\n     * Array of all exclude patterns that contain wildcards.\r\n     *\r\n     * <p>Gets lazily initialized on the first invocation of\r\n     * isIncluded or isExcluded and cleared at the end of the scan\r\n     * method (cleared in clearCaches, actually).</p>\r\n     */\r\n    private TokenizedPattern[] excludePatterns;\r\n\r\n    /**\r\n     * Have the non-pattern sets and pattern arrays for in- and\r\n     * excludes been initialized?\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    private boolean areNonPatternSetsReady = false;\r\n\r\n    /**\r\n     * Scanning flag.\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    private boolean scanning = false;\r\n\r\n    /**\r\n     * Scanning lock.\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    private Object scanLock = new Object();\r\n\r\n    /**\r\n     * Slow scanning flag.\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    private boolean slowScanning = false;\r\n\r\n    /**\r\n     * Slow scanning lock.\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    private Object slowScanLock = new Object();\r\n\r\n    /**\r\n     * Exception thrown during scan.\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    private IllegalStateException illegal = null;\r\n\r\n    /**\r\n     * The maximum number of times a symbolic link may be followed\r\n     * during a scan.\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    private int maxLevelsOfSymlinks = MAX_LEVELS_OF_SYMLINKS;\r\n\r\n\r\n    /**\r\n     * Absolute paths of all symlinks that haven\'t been followed but\r\n     * would have been if followsymlinks had been true or\r\n     * maxLevelsOfSymlinks had been higher.\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    private Set/*<String>*/ notFollowedSymlinks = new HashSet();\r\n\r\n    /**\r\n     * Sole constructor.\r\n     */\r\n    public DirectoryScanner() {\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a given path matches the start of a given\r\n     * pattern up to the first \"**\".\r\n     * <p>\r\n     * This is not a general purpose test and should only be used if you\r\n     * can live with false positives. For example, <code>pattern=**\\a</code>\r\n     * and <code>str=b</code> will yield <code>true</code>.\r\n     *\r\n     * @param pattern The pattern to match against. Must not be\r\n     *                <code>null</code>.\r\n     * @param str     The path to match, as a String. Must not be\r\n     *                <code>null</code>.\r\n     *\r\n     * @return whether or not a given path matches the start of a given\r\n     * pattern up to the first \"**\".\r\n     */\r\n    protected static boolean matchPatternStart(String pattern, String str) {\r\n        return SelectorUtils.matchPatternStart(pattern, str);\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a given path matches the start of a given\r\n     * pattern up to the first \"**\".\r\n     * <p>\r\n     * This is not a general purpose test and should only be used if you\r\n     * can live with false positives. For example, <code>pattern=**\\a</code>\r\n     * and <code>str=b</code> will yield <code>true</code>.\r\n     *\r\n     * @param pattern The pattern to match against. Must not be\r\n     *                <code>null</code>.\r\n     * @param str     The path to match, as a String. Must not be\r\n     *                <code>null</code>.\r\n     * @param isCaseSensitive Whether or not matching should be performed\r\n     *                        case sensitively.\r\n     *\r\n     * @return whether or not a given path matches the start of a given\r\n     * pattern up to the first \"**\".\r\n     */\r\n    protected static boolean matchPatternStart(String pattern, String str,\r\n                                               boolean isCaseSensitive) {\r\n        return SelectorUtils.matchPatternStart(pattern, str, isCaseSensitive);\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a given path matches a given pattern.\r\n     *\r\n     * @param pattern The pattern to match against. Must not be\r\n     *                <code>null</code>.\r\n     * @param str     The path to match, as a String. Must not be\r\n     *                <code>null</code>.\r\n     *\r\n     * @return <code>true</code> if the pattern matches against the string,\r\n     *         or <code>false</code> otherwise.\r\n     */\r\n    protected static boolean matchPath(String pattern, String str) {\r\n        return SelectorUtils.matchPath(pattern, str);\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a given path matches a given pattern.\r\n     *\r\n     * @param pattern The pattern to match against. Must not be\r\n     *                <code>null</code>.\r\n     * @param str     The path to match, as a String. Must not be\r\n     *                <code>null</code>.\r\n     * @param isCaseSensitive Whether or not matching should be performed\r\n     *                        case sensitively.\r\n     *\r\n     * @return <code>true</code> if the pattern matches against the string,\r\n     *         or <code>false</code> otherwise.\r\n     */\r\n    protected static boolean matchPath(String pattern, String str,\r\n                                       boolean isCaseSensitive) {\r\n        return SelectorUtils.matchPath(pattern, str, isCaseSensitive);\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a string matches against a pattern.\r\n     * The pattern may contain two special characters:<br>\r\n     * \'*\' means zero or more characters<br>\r\n     * \'?\' means one and only one character\r\n     *\r\n     * @param pattern The pattern to match against.\r\n     *                Must not be <code>null</code>.\r\n     * @param str     The string which must be matched against the pattern.\r\n     *                Must not be <code>null</code>.\r\n     *\r\n     * @return <code>true</code> if the string matches against the pattern,\r\n     *         or <code>false</code> otherwise.\r\n     */\r\n    public static boolean match(String pattern, String str) {\r\n        return SelectorUtils.match(pattern, str);\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a string matches against a pattern.\r\n     * The pattern may contain two special characters:<br>\r\n     * \'*\' means zero or more characters<br>\r\n     * \'?\' means one and only one character\r\n     *\r\n     * @param pattern The pattern to match against.\r\n     *                Must not be <code>null</code>.\r\n     * @param str     The string which must be matched against the pattern.\r\n     *                Must not be <code>null</code>.\r\n     * @param isCaseSensitive Whether or not matching should be performed\r\n     *                        case sensitively.\r\n     *\r\n     *\r\n     * @return <code>true</code> if the string matches against the pattern,\r\n     *         or <code>false</code> otherwise.\r\n     */\r\n    protected static boolean match(String pattern, String str,\r\n                                   boolean isCaseSensitive) {\r\n        return SelectorUtils.match(pattern, str, isCaseSensitive);\r\n    }\r\n\r\n\r\n    /**\r\n     * Get the list of patterns that should be excluded by default.\r\n     *\r\n     * @return An array of <code>String</code> based on the current\r\n     *         contents of the <code>defaultExcludes</code>\r\n     *         <code>Set</code>.\r\n     *\r\n     * @since Ant 1.6\r\n     */\r\n    public static String[] getDefaultExcludes() {\r\n        synchronized (defaultExcludes) {\r\n            return (String[]) defaultExcludes.toArray(new String[defaultExcludes\r\n                                                                 .size()]);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Add a pattern to the default excludes unless it is already a\r\n     * default exclude.\r\n     *\r\n     * @param s   A string to add as an exclude pattern.\r\n     * @return    <code>true</code> if the string was added;\r\n     *            <code>false</code> if it already existed.\r\n     *\r\n     * @since Ant 1.6\r\n     */\r\n    public static boolean addDefaultExclude(String s) {\r\n        synchronized (defaultExcludes) {\r\n            return defaultExcludes.add(s);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Remove a string if it is a default exclude.\r\n     *\r\n     * @param s   The string to attempt to remove.\r\n     * @return    <code>true</code> if <code>s</code> was a default\r\n     *            exclude (and thus was removed);\r\n     *            <code>false</code> if <code>s</code> was not\r\n     *            in the default excludes list to begin with.\r\n     *\r\n     * @since Ant 1.6\r\n     */\r\n    public static boolean removeDefaultExclude(String s) {\r\n        synchronized (defaultExcludes) {\r\n            return defaultExcludes.remove(s);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Go back to the hardwired default exclude patterns.\r\n     *\r\n     * @since Ant 1.6\r\n     */\r\n    public static void resetDefaultExcludes() {\r\n        synchronized (defaultExcludes) {\r\n            defaultExcludes.clear();\r\n            for (int i = 0; i < DEFAULTEXCLUDES.length; i++) {\r\n                defaultExcludes.add(DEFAULTEXCLUDES[i]);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Set the base directory to be scanned. This is the directory which is\r\n     * scanned recursively. All \'/\' and \'\\\' characters are replaced by\r\n     * <code>File.separatorChar</code>, so the separator used need not match\r\n     * <code>File.separatorChar</code>.\r\n     *\r\n     * @param basedir The base directory to scan.\r\n     */\r\n    public void setBasedir(String basedir) {\r\n        setBasedir(basedir == null ? (File) null\r\n            : new File(basedir.replace(\'/\', File.separatorChar).replace(\r\n            \'\\\\\', File.separatorChar)));\r\n    }\r\n\r\n    /**\r\n     * Set the base directory to be scanned. This is the directory which is\r\n     * scanned recursively.\r\n     *\r\n     * @param basedir The base directory for scanning.\r\n     */\r\n    public synchronized void setBasedir(File basedir) {\r\n        this.basedir = basedir;\r\n    }\r\n\r\n    /**\r\n     * Return the base directory to be scanned.\r\n     * This is the directory which is scanned recursively.\r\n     *\r\n     * @return the base directory to be scanned.\r\n     */\r\n    public synchronized File getBasedir() {\r\n        return basedir;\r\n    }\r\n\r\n    /**\r\n     * Find out whether include exclude patterns are matched in a\r\n     * case sensitive way.\r\n     * @return whether or not the scanning is case sensitive.\r\n     * @since Ant 1.6\r\n     */\r\n    public synchronized boolean isCaseSensitive() {\r\n        return isCaseSensitive;\r\n    }\r\n\r\n    /**\r\n     * Set whether or not include and exclude patterns are matched\r\n     * in a case sensitive way.\r\n     *\r\n     * @param isCaseSensitive whether or not the file system should be\r\n     *                        regarded as a case sensitive one.\r\n     */\r\n    public synchronized void setCaseSensitive(boolean isCaseSensitive) {\r\n        this.isCaseSensitive = isCaseSensitive;\r\n    }\r\n\r\n    /**\r\n     * Sets whether or not a missing base directory is an error\r\n     *\r\n     * @param errorOnMissingDir whether or not a missing base directory\r\n     *                        is an error\r\n     * @since Ant 1.7.1\r\n     */\r\n    public void setErrorOnMissingDir(boolean errorOnMissingDir) {\r\n        this.errorOnMissingDir = errorOnMissingDir;\r\n    }\r\n\r\n    /**\r\n     * Get whether or not a DirectoryScanner follows symbolic links.\r\n     *\r\n     * @return flag indicating whether symbolic links should be followed.\r\n     *\r\n     * @since Ant 1.6\r\n     */\r\n    public synchronized boolean isFollowSymlinks() {\r\n        return followSymlinks;\r\n    }\r\n\r\n    /**\r\n     * Set whether or not symbolic links should be followed.\r\n     *\r\n     * @param followSymlinks whether or not symbolic links should be followed.\r\n     */\r\n    public synchronized void setFollowSymlinks(boolean followSymlinks) {\r\n        this.followSymlinks = followSymlinks;\r\n    }\r\n\r\n    /**\r\n     * The maximum number of times a symbolic link may be followed\r\n     * during a scan.\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    public void setMaxLevelsOfSymlinks(int max) {\r\n        maxLevelsOfSymlinks = max;\r\n    }\r\n\r\n    /**\r\n     * Set the list of include patterns to use. All \'/\' and \'\\\' characters\r\n     * are replaced by <code>File.separatorChar</code>, so the separator used\r\n     * need not match <code>File.separatorChar</code>.\r\n     * <p>\r\n     * When a pattern ends with a \'/\' or \'\\\', \"**\" is appended.\r\n     *\r\n     * @param includes A list of include patterns.\r\n     *                 May be <code>null</code>, indicating that all files\r\n     *                 should be included. If a non-<code>null</code>\r\n     *                 list is given, all elements must be\r\n     *                 non-<code>null</code>.\r\n     */\r\n    public synchronized void setIncludes(String[] includes) {\r\n        if (includes == null) {\r\n            this.includes = null;\r\n        } else {\r\n            this.includes = new String[includes.length];\r\n            for (int i = 0; i < includes.length; i++) {\r\n                this.includes[i] = normalizePattern(includes[i]);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Set the list of exclude patterns to use. All \'/\' and \'\\\' characters\r\n     * are replaced by <code>File.separatorChar</code>, so the separator used\r\n     * need not match <code>File.separatorChar</code>.\r\n     * <p>\r\n     * When a pattern ends with a \'/\' or \'\\\', \"**\" is appended.\r\n     *\r\n     * @param excludes A list of exclude patterns.\r\n     *                 May be <code>null</code>, indicating that no files\r\n     *                 should be excluded. If a non-<code>null</code> list is\r\n     *                 given, all elements must be non-<code>null</code>.\r\n     */\r\n    public synchronized void setExcludes(String[] excludes) {\r\n        if (excludes == null) {\r\n            this.excludes = null;\r\n        } else {\r\n            this.excludes = new String[excludes.length];\r\n            for (int i = 0; i < excludes.length; i++) {\r\n                this.excludes[i] = normalizePattern(excludes[i]);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Add to the list of exclude patterns to use. All \'/\' and \'\\\'\r\n     * characters are replaced by <code>File.separatorChar</code>, so\r\n     * the separator used need not match <code>File.separatorChar</code>.\r\n     * <p>\r\n     * When a pattern ends with a \'/\' or \'\\\', \"**\" is appended.\r\n     *\r\n     * @param excludes A list of exclude patterns.\r\n     *                 May be <code>null</code>, in which case the\r\n     *                 exclude patterns don\'t get changed at all.\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    public synchronized void addExcludes(String[] excludes) {\r\n        if (excludes != null && excludes.length > 0) {\r\n            if (this.excludes != null && this.excludes.length > 0) {\r\n                String[] tmp = new String[excludes.length\r\n                                          + this.excludes.length];\r\n                System.arraycopy(this.excludes, 0, tmp, 0,\r\n                                 this.excludes.length);\r\n                for (int i = 0; i < excludes.length; i++) {\r\n                    tmp[this.excludes.length + i] =\r\n                        normalizePattern(excludes[i]);\r\n                }\r\n                this.excludes = tmp;\r\n            } else {\r\n                setExcludes(excludes);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * All \'/\' and \'\\\' characters are replaced by\r\n     * <code>File.separatorChar</code>, so the separator used need not\r\n     * match <code>File.separatorChar</code>.\r\n     *\r\n     * <p> When a pattern ends with a \'/\' or \'\\\', \"**\" is appended.\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    private static String normalizePattern(String p) {\r\n        String pattern = p.replace(\'/\', File.separatorChar)\r\n            .replace(\'\\\\\', File.separatorChar);\r\n        if (pattern.endsWith(File.separator)) {\r\n            pattern += SelectorUtils.DEEP_TREE_MATCH;\r\n        }\r\n        return pattern;\r\n    }\r\n\r\n    /**\r\n     * Set the selectors that will select the filelist.\r\n     *\r\n     * @param selectors specifies the selectors to be invoked on a scan.\r\n     */\r\n    public synchronized void setSelectors(FileSelector[] selectors) {\r\n        this.selectors = selectors;\r\n    }\r\n\r\n    /**\r\n     * Return whether or not the scanner has included all the files or\r\n     * directories it has come across so far.\r\n     *\r\n     * @return <code>true</code> if all files and directories which have\r\n     *         been found so far have been included.\r\n     */\r\n    public synchronized boolean isEverythingIncluded() {\r\n        return everythingIncluded;\r\n    }\r\n\r\n    /**\r\n     * Scan for files which match at least one include pattern and don\'t match\r\n     * any exclude patterns. If there are selectors then the files must pass\r\n     * muster there, as well.  Scans under basedir, if set; otherwise the\r\n     * include patterns without leading wildcards specify the absolute paths of\r\n     * the files that may be included.\r\n     *\r\n     * @exception IllegalStateException if the base directory was set\r\n     *            incorrectly (i.e. if it doesn\'t exist or isn\'t a directory).\r\n     */\r\n    public void scan() throws IllegalStateException {\r\n        synchronized (scanLock) {\r\n            if (scanning) {\r\n                while (scanning) {\r\n                    try {\r\n                        scanLock.wait();\r\n                    } catch (InterruptedException e) {\r\n                        continue;\r\n                    }\r\n                }\r\n                if (illegal != null) {\r\n                    throw illegal;\r\n                }\r\n                return;\r\n            }\r\n            scanning = true;\r\n        }\r\n        File savedBase = basedir;\r\n        try {\r\n            synchronized (this) {\r\n                illegal = null;\r\n                clearResults();\r\n\r\n                // set in/excludes to reasonable defaults if needed:\r\n                boolean nullIncludes = (includes == null);\r\n                includes = nullIncludes\r\n                    ? new String[] {SelectorUtils.DEEP_TREE_MATCH} : includes;\r\n                boolean nullExcludes = (excludes == null);\r\n                excludes = nullExcludes ? new String[0] : excludes;\r\n\r\n                if (basedir != null && !followSymlinks\r\n                    && SYMLINK_UTILS.isSymbolicLink(basedir)) {\r\n                    notFollowedSymlinks.add(basedir.getAbsolutePath());\r\n                    basedir = null;\r\n                }\r\n\r\n                if (basedir == null) {\r\n                    // if no basedir and no includes, nothing to do:\r\n                    if (nullIncludes) {\r\n                        return;\r\n                    }\r\n                } else {\r\n                    if (!basedir.exists()) {\r\n                        if (errorOnMissingDir) {\r\n                            illegal = new IllegalStateException(\"basedir \"\r\n                                                                + basedir\r\n                                                                + DOES_NOT_EXIST_POSTFIX);\r\n                        } else {\r\n                            // Nothing to do - basedir does not exist\r\n                            return;\r\n                        }\r\n                    } else if (!basedir.isDirectory()) {\r\n                        illegal = new IllegalStateException(\"basedir \"\r\n                                                            + basedir\r\n                                                            + \" is not a\"\r\n                                                            + \" directory.\");\r\n                    }\r\n                    if (illegal != null) {\r\n                        throw illegal;\r\n                    }\r\n                }\r\n                if (isIncluded(TokenizedPath.EMPTY_PATH)) {\r\n                    if (!isExcluded(TokenizedPath.EMPTY_PATH)) {\r\n                        if (isSelected(\"\", basedir)) {\r\n                            dirsIncluded.addElement(\"\");\r\n                        } else {\r\n                            dirsDeselected.addElement(\"\");\r\n                        }\r\n                    } else {\r\n                        dirsExcluded.addElement(\"\");\r\n                    }\r\n                } else {\r\n                    dirsNotIncluded.addElement(\"\");\r\n                }\r\n                checkIncludePatterns();\r\n                clearCaches();\r\n                includes = nullIncludes ? null : includes;\r\n                excludes = nullExcludes ? null : excludes;\r\n            }\r\n        } catch (IOException ex) {\r\n            throw new BuildException(ex);\r\n        } finally {\r\n            basedir = savedBase;\r\n            synchronized (scanLock) {\r\n                scanning = false;\r\n                scanLock.notifyAll();\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * This routine is actually checking all the include patterns in\r\n     * order to avoid scanning everything under base dir.\r\n     * @since Ant 1.6\r\n     */\r\n    private void checkIncludePatterns() {\r\n        ensureNonPatternSetsReady();\r\n        Map newroots = new HashMap();\r\n\r\n        // put in the newroots map the include patterns without\r\n        // wildcard tokens\r\n        for (int i = 0; i < includePatterns.length; i++) {\r\n            String pattern = includePatterns[i].toString();\r\n            if (!shouldSkipPattern(pattern)) {\r\n                newroots.put(includePatterns[i].rtrimWildcardTokens(),\r\n                             pattern);\r\n            }\r\n        }\r\n        for (Iterator iter = includeNonPatterns.entrySet().iterator();\r\n             iter.hasNext(); ) {\r\n            Map.Entry entry = (Map.Entry) iter.next();\r\n            String pattern = (String) entry.getKey();\r\n            if (!shouldSkipPattern(pattern)) {\r\n                newroots.put((TokenizedPath) entry.getValue(), pattern);\r\n            }\r\n        }\r\n\r\n        if (newroots.containsKey(TokenizedPath.EMPTY_PATH)\r\n            && basedir != null) {\r\n            // we are going to scan everything anyway\r\n            scandir(basedir, \"\", true);\r\n        } else {\r\n            // only scan directories that can include matched files or\r\n            // directories\r\n            Iterator it = newroots.entrySet().iterator();\r\n\r\n            File canonBase = null;\r\n            if (basedir != null) {\r\n                try {\r\n                    canonBase = basedir.getCanonicalFile();\r\n                } catch (IOException ex) {\r\n                    throw new BuildException(ex);\r\n                }\r\n            }\r\n            while (it.hasNext()) {\r\n                Map.Entry entry = (Map.Entry) it.next();\r\n                TokenizedPath currentPath = (TokenizedPath) entry.getKey();\r\n                String currentelement = currentPath.toString();\r\n                if (basedir == null\r\n                    && !FileUtils.isAbsolutePath(currentelement)) {\r\n                    continue;\r\n                }\r\n                File myfile = new File(basedir, currentelement);\r\n\r\n                if (myfile.exists()) {\r\n                    // may be on a case insensitive file system.  We want\r\n                    // the results to show what\'s really on the disk, so\r\n                    // we need to double check.\r\n                    try {\r\n                        String path = (basedir == null)\r\n                            ? myfile.getCanonicalPath()\r\n                            : FILE_UTILS.removeLeadingPath(canonBase,\r\n                                         myfile.getCanonicalFile());\r\n                        if (!path.equals(currentelement) || ON_VMS) {\r\n                            myfile = currentPath.findFile(basedir, true);\r\n                            if (myfile != null && basedir != null) {\r\n                                currentelement = FILE_UTILS.removeLeadingPath(\r\n                                    basedir, myfile);\r\n                                if (!currentPath.toString()\r\n                                    .equals(currentelement)) {\r\n                                    currentPath =\r\n                                        new TokenizedPath(currentelement);\r\n                                }\r\n                            }\r\n                        }\r\n                    } catch (IOException ex) {\r\n                        throw new BuildException(ex);\r\n                    }\r\n                }\r\n\r\n                if ((myfile == null || !myfile.exists()) && !isCaseSensitive()) {\r\n                    File f = currentPath.findFile(basedir, false);\r\n                    if (f != null && f.exists()) {\r\n                        // adapt currentelement to the case we\'ve\r\n                        // actually found\r\n                        currentelement = (basedir == null)\r\n                            ? f.getAbsolutePath()\r\n                            : FILE_UTILS.removeLeadingPath(basedir, f);\r\n                        myfile = f;\r\n                        currentPath = new TokenizedPath(currentelement);\r\n                    }\r\n                }\r\n\r\n                if (myfile != null && myfile.exists()) {\r\n                    if (!followSymlinks && currentPath.isSymlink(basedir)) {\r\n                        if (!isExcluded(currentPath)) {\r\n                            notFollowedSymlinks.add(myfile.getAbsolutePath());\r\n                        }\r\n                        continue;\r\n                    }\r\n                    if (myfile.isDirectory()) {\r\n                        if (isIncluded(currentPath)\r\n                            && currentelement.length() > 0) {\r\n                            accountForIncludedDir(currentPath, myfile, true);\r\n                        }  else {\r\n                            scandir(myfile, currentPath, true);\r\n                        }\r\n                    } else {\r\n                        String originalpattern = (String) entry.getValue();\r\n                        boolean included = isCaseSensitive()\r\n                            ? originalpattern.equals(currentelement)\r\n                            : originalpattern.equalsIgnoreCase(currentelement);\r\n                        if (included) {\r\n                            accountForIncludedFile(currentPath, myfile);\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * true if the pattern specifies a relative path without basedir\r\n     * or an absolute path not inside basedir.\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    private boolean shouldSkipPattern(String pattern) {\r\n        if (FileUtils.isAbsolutePath(pattern)) {\r\n            //skip abs. paths not under basedir, if set:\r\n            if (basedir != null\r\n                && !SelectorUtils.matchPatternStart(pattern,\r\n                                                    basedir.getAbsolutePath(),\r\n                                                    isCaseSensitive())) {\r\n                return true;\r\n            }\r\n        } else if (basedir == null) {\r\n            //skip non-abs. paths if basedir == null:\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n\r\n    /**\r\n     * Clear the result caches for a scan.\r\n     */\r\n    protected synchronized void clearResults() {\r\n        filesIncluded    = new VectorSet();\r\n        filesNotIncluded = new VectorSet();\r\n        filesExcluded    = new VectorSet();\r\n        filesDeselected  = new VectorSet();\r\n        dirsIncluded     = new VectorSet();\r\n        dirsNotIncluded  = new VectorSet();\r\n        dirsExcluded     = new VectorSet();\r\n        dirsDeselected   = new VectorSet();\r\n        everythingIncluded = (basedir != null);\r\n        scannedDirs.clear();\r\n        notFollowedSymlinks.clear();\r\n    }\r\n\r\n    /**\r\n     * Top level invocation for a slow scan. A slow scan builds up a full\r\n     * list of excluded/included files/directories, whereas a fast scan\r\n     * will only have full results for included files, as it ignores\r\n     * directories which can\'t possibly hold any included files/directories.\r\n     * <p>\r\n     * Returns immediately if a slow scan has already been completed.\r\n     */\r\n    protected void slowScan() {\r\n        synchronized (slowScanLock) {\r\n            if (haveSlowResults) {\r\n                return;\r\n            }\r\n            if (slowScanning) {\r\n                while (slowScanning) {\r\n                    try {\r\n                        slowScanLock.wait();\r\n                    } catch (InterruptedException e) {\r\n                        // Empty\r\n                    }\r\n                }\r\n                return;\r\n            }\r\n            slowScanning = true;\r\n        }\r\n        try {\r\n            synchronized (this) {\r\n\r\n                // set in/excludes to reasonable defaults if needed:\r\n                boolean nullIncludes = (includes == null);\r\n                includes = nullIncludes\r\n                    ? new String[] {SelectorUtils.DEEP_TREE_MATCH} : includes;\r\n                boolean nullExcludes = (excludes == null);\r\n                excludes = nullExcludes ? new String[0] : excludes;\r\n\r\n                String[] excl = new String[dirsExcluded.size()];\r\n                dirsExcluded.copyInto(excl);\r\n\r\n                String[] notIncl = new String[dirsNotIncluded.size()];\r\n                dirsNotIncluded.copyInto(notIncl);\r\n\r\n                ensureNonPatternSetsReady();\r\n\r\n                processSlowScan(excl);\r\n                processSlowScan(notIncl);\r\n                clearCaches();\r\n                includes = nullIncludes ? null : includes;\r\n                excludes = nullExcludes ? null : excludes;\r\n            }\r\n        } finally {\r\n            synchronized (slowScanLock) {\r\n                haveSlowResults = true;\r\n                slowScanning = false;\r\n                slowScanLock.notifyAll();\r\n            }\r\n        }\r\n    }\r\n\r\n    private void processSlowScan(String[] arr) {\r\n        for (int i = 0; i < arr.length; i++) {\r\n            TokenizedPath path  = new TokenizedPath(arr[i]);\r\n            if (!couldHoldIncluded(path) || contentsExcluded(path)) {\r\n                scandir(new File(basedir, arr[i]), path, false);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Scan the given directory for files and directories. Found files and\r\n     * directories are placed in their respective collections, based on the\r\n     * matching of includes, excludes, and the selectors.  When a directory\r\n     * is found, it is scanned recursively.\r\n     *\r\n     * @param dir   The directory to scan. Must not be <code>null</code>.\r\n     * @param vpath The path relative to the base directory (needed to\r\n     *              prevent problems with an absolute path when using\r\n     *              dir). Must not be <code>null</code>.\r\n     * @param fast  Whether or not this call is part of a fast scan.\r\n     *\r\n     * @see #filesIncluded\r\n     * @see #filesNotIncluded\r\n     * @see #filesExcluded\r\n     * @see #dirsIncluded\r\n     * @see #dirsNotIncluded\r\n     * @see #dirsExcluded\r\n     * @see #slowScan\r\n     */\r\n    protected void scandir(File dir, String vpath, boolean fast) {\r\n        scandir(dir, new TokenizedPath(vpath), fast);\r\n    }\r\n\r\n    /**\r\n     * Scan the given directory for files and directories. Found files and\r\n     * directories are placed in their respective collections, based on the\r\n     * matching of includes, excludes, and the selectors.  When a directory\r\n     * is found, it is scanned recursively.\r\n     *\r\n     * @param dir   The directory to scan. Must not be <code>null</code>.\r\n     * @param path The path relative to the base directory (needed to\r\n     *              prevent problems with an absolute path when using\r\n     *              dir). Must not be <code>null</code>.\r\n     * @param fast  Whether or not this call is part of a fast scan.\r\n     *\r\n     * @see #filesIncluded\r\n     * @see #filesNotIncluded\r\n     * @see #filesExcluded\r\n     * @see #dirsIncluded\r\n     * @see #dirsNotIncluded\r\n     * @see #dirsExcluded\r\n     * @see #slowScan\r\n     */\r\n    private void scandir(File dir, TokenizedPath path, boolean fast) {\r\n        if (dir == null) {\r\n            throw new BuildException(\"dir must not be null.\");\r\n        }\r\n        String[] newfiles = dir.list();\r\n        if (newfiles == null) {\r\n            if (!dir.exists()) {\r\n                throw new BuildException(dir + DOES_NOT_EXIST_POSTFIX);\r\n            } else if (!dir.isDirectory()) {\r\n                throw new BuildException(dir + \" is not a directory.\");\r\n            } else {\r\n                throw new BuildException(\"IO error scanning directory \'\"\r\n                                         + dir.getAbsolutePath() + \"\'\");\r\n            }\r\n        }\r\n        scandir(dir, path, fast, newfiles, new LinkedList());\r\n    }\r\n\r\n    private void scandir(File dir, TokenizedPath path, boolean fast,\r\n                         String[] newfiles, LinkedList directoryNamesFollowed) {\r\n        String vpath = path.toString();\r\n        if (vpath.length() > 0 && !vpath.endsWith(File.separator)) {\r\n            vpath += File.separator;\r\n        }\r\n\r\n        // avoid double scanning of directories, can only happen in fast mode\r\n        if (fast && hasBeenScanned(vpath)) {\r\n            return;\r\n        }\r\n        if (!followSymlinks) {\r\n            ArrayList noLinks = new ArrayList();\r\n            for (int i = 0; i < newfiles.length; i++) {\r\n                try {\r\n                    if (SYMLINK_UTILS.isSymbolicLink(dir, newfiles[i])) {\r\n                        String name = vpath + newfiles[i];\r\n                        File file = new File(dir, newfiles[i]);\r\n                        (file.isDirectory()\r\n                            ? dirsExcluded : filesExcluded).addElement(name);\r\n                        if (!isExcluded(name)) {\r\n                            notFollowedSymlinks.add(file.getAbsolutePath());\r\n                        }\r\n                    } else {\r\n                        noLinks.add(newfiles[i]);\r\n                    }\r\n                } catch (IOException ioe) {\r\n                    String msg = \"IOException caught while checking \"\r\n                        + \"for links, couldn\'t get canonical path!\";\r\n                    // will be caught and redirected to Ant\'s logging system\r\n                    System.err.println(msg);\r\n                    noLinks.add(newfiles[i]);\r\n                }\r\n            }\r\n            newfiles = (String[]) (noLinks.toArray(new String[noLinks.size()]));\r\n        } else {\r\n            directoryNamesFollowed.addFirst(dir.getName());\r\n        }\r\n\r\n        for (int i = 0; i < newfiles.length; i++) {\r\n            String name = vpath + newfiles[i];\r\n            TokenizedPath newPath = new TokenizedPath(path, newfiles[i]);\r\n            File file = new File(dir, newfiles[i]);\r\n            String[] children = file.list();\r\n            if (children == null || (children.length == 0 && file.isFile())) {\r\n                if (isIncluded(newPath)) {\r\n                    accountForIncludedFile(newPath, file);\r\n                } else {\r\n                    everythingIncluded = false;\r\n                    filesNotIncluded.addElement(name);\r\n                }\r\n            } else { // dir\r\n\r\n                if (followSymlinks\r\n                    && causesIllegalSymlinkLoop(newfiles[i], dir,\r\n                                                directoryNamesFollowed)) {\r\n                    // will be caught and redirected to Ant\'s logging system\r\n                    System.err.println(\"skipping symbolic link \"\r\n                                       + file.getAbsolutePath()\r\n                                       + \" -- too many levels of symbolic\"\r\n                                       + \" links.\");\r\n                    notFollowedSymlinks.add(file.getAbsolutePath());\r\n                    continue;\r\n                }\r\n\r\n                if (isIncluded(newPath)) {\r\n                    accountForIncludedDir(newPath, file, fast, children,\r\n                                          directoryNamesFollowed);\r\n                } else {\r\n                    everythingIncluded = false;\r\n                    dirsNotIncluded.addElement(name);\r\n                    if (fast && couldHoldIncluded(newPath)\r\n                        && !contentsExcluded(newPath)) {\r\n                        scandir(file, newPath, fast, children,\r\n                                directoryNamesFollowed);\r\n                    }\r\n                }\r\n                if (!fast) {\r\n                    scandir(file, newPath, fast, children, directoryNamesFollowed);\r\n                }\r\n            }\r\n        }\r\n\r\n        if (followSymlinks) {\r\n            directoryNamesFollowed.removeFirst();\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Process included file.\r\n     * @param name  path of the file relative to the directory of the FileSet.\r\n     * @param file  included File.\r\n     */\r\n    private void accountForIncludedFile(TokenizedPath name, File file) {\r\n        processIncluded(name, file, filesIncluded, filesExcluded,\r\n                        filesDeselected);\r\n    }\r\n\r\n    /**\r\n     * Process included directory.\r\n     * @param name path of the directory relative to the directory of\r\n     *             the FileSet.\r\n     * @param file directory as File.\r\n     * @param fast whether to perform fast scans.\r\n     */\r\n    private void accountForIncludedDir(TokenizedPath name, File file,\r\n                                       boolean fast) {\r\n        processIncluded(name, file, dirsIncluded, dirsExcluded, dirsDeselected);\r\n        if (fast && couldHoldIncluded(name) && !contentsExcluded(name)) {\r\n            scandir(file, name, fast);\r\n        }\r\n    }\r\n\r\n    private void accountForIncludedDir(TokenizedPath name,\r\n                                       File file, boolean fast,\r\n                                       String[] children,\r\n                                       LinkedList directoryNamesFollowed) {\r\n        processIncluded(name, file, dirsIncluded, dirsExcluded, dirsDeselected);\r\n        if (fast && couldHoldIncluded(name) && !contentsExcluded(name)) {\r\n            scandir(file, name, fast, children, directoryNamesFollowed);\r\n        }\r\n    }\r\n\r\n    private void processIncluded(TokenizedPath path,\r\n                                 File file, Vector inc, Vector exc,\r\n                                 Vector des) {\r\n        String name = path.toString();\r\n        if (inc.contains(name) || exc.contains(name) || des.contains(name)) {\r\n            return;\r\n        }\r\n\r\n        boolean included = false;\r\n        if (isExcluded(path)) {\r\n            exc.add(name);\r\n        } else if (isSelected(name, file)) {\r\n            included = true;\r\n            inc.add(name);\r\n        } else {\r\n            des.add(name);\r\n        }\r\n        everythingIncluded &= included;\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a name matches against at least one include\r\n     * pattern.\r\n     *\r\n     * @param name The name to match. Must not be <code>null</code>.\r\n     * @return <code>true</code> when the name matches against at least one\r\n     *         include pattern, or <code>false</code> otherwise.\r\n     */\r\n    protected boolean isIncluded(String name) {\r\n        return isIncluded(new TokenizedPath(name));\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a name matches against at least one include\r\n     * pattern.\r\n     *\r\n     * @param name The name to match. Must not be <code>null</code>.\r\n     * @return <code>true</code> when the name matches against at least one\r\n     *         include pattern, or <code>false</code> otherwise.\r\n     */\r\n    private boolean isIncluded(TokenizedPath path) {\r\n        ensureNonPatternSetsReady();\r\n\r\n        if (isCaseSensitive()\r\n            ? includeNonPatterns.containsKey(path.toString())\r\n            : includeNonPatterns.containsKey(path.toString().toUpperCase())) {\r\n            return true;\r\n        }\r\n        for (int i = 0; i < includePatterns.length; i++) {\r\n            if (includePatterns[i].matchPath(path, isCaseSensitive())) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a name matches the start of at least one include\r\n     * pattern.\r\n     *\r\n     * @param name The name to match. Must not be <code>null</code>.\r\n     * @return <code>true</code> when the name matches against the start of at\r\n     *         least one include pattern, or <code>false</code> otherwise.\r\n     */\r\n    protected boolean couldHoldIncluded(String name) {\r\n        return couldHoldIncluded(new TokenizedPath(name));\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a name matches the start of at least one include\r\n     * pattern.\r\n     *\r\n     * @param tokenizedName The name to match. Must not be <code>null</code>.\r\n     * @return <code>true</code> when the name matches against the start of at\r\n     *         least one include pattern, or <code>false</code> otherwise.\r\n     */\r\n    private boolean couldHoldIncluded(TokenizedPath tokenizedName) {\r\n        for (int i = 0; i < includePatterns.length; i++) {\r\n            if (couldHoldIncluded(tokenizedName, includePatterns[i])) {\r\n                return true;\r\n            }\r\n        }\r\n        for (Iterator iter = includeNonPatterns.values().iterator();\r\n             iter.hasNext(); ) {\r\n            if (couldHoldIncluded(tokenizedName,\r\n                                  ((TokenizedPath) iter.next()).toPattern())) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a name matches the start of the given\r\n     * include pattern.\r\n     *\r\n     * @param tokenizedName The name to match. Must not be <code>null</code>.\r\n     * @return <code>true</code> when the name matches against the start of the\r\n     *         include pattern, or <code>false</code> otherwise.\r\n     */\r\n    private boolean couldHoldIncluded(TokenizedPath tokenizedName,\r\n                                      TokenizedPattern tokenizedInclude) {\r\n        return tokenizedInclude.matchStartOf(tokenizedName, isCaseSensitive())\r\n            && isMorePowerfulThanExcludes(tokenizedName.toString())\r\n            && isDeeper(tokenizedInclude, tokenizedName);\r\n    }\r\n\r\n    /**\r\n     * Verify that a pattern specifies files deeper\r\n     * than the level of the specified file.\r\n     * @param pattern the pattern to check.\r\n     * @param name the name to check.\r\n     * @return whether the pattern is deeper than the name.\r\n     * @since Ant 1.6.3\r\n     */\r\n    private boolean isDeeper(TokenizedPattern pattern, TokenizedPath name) {\r\n        return pattern.containsPattern(SelectorUtils.DEEP_TREE_MATCH)\r\n            || pattern.depth() > name.depth();\r\n    }\r\n\r\n    /**\r\n     *  Find out whether one particular include pattern is more powerful\r\n     *  than all the excludes.\r\n     *  Note:  the power comparison is based on the length of the include pattern\r\n     *  and of the exclude patterns without the wildcards.\r\n     *  Ideally the comparison should be done based on the depth\r\n     *  of the match; that is to say how many file separators have been matched\r\n     *  before the first ** or the end of the pattern.\r\n     *\r\n     *  IMPORTANT : this function should return false \"with care\".\r\n     *\r\n     *  @param name the relative path to test.\r\n     *  @return true if there is no exclude pattern more powerful than\r\n     *  this include pattern.\r\n     *  @since Ant 1.6\r\n     */\r\n    private boolean isMorePowerfulThanExcludes(String name) {\r\n        final String soughtexclude =\r\n            name + File.separatorChar + SelectorUtils.DEEP_TREE_MATCH;\r\n        for (int counter = 0; counter < excludePatterns.length; counter++) {\r\n            if (excludePatterns[counter].toString().equals(soughtexclude))  {\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n\r\n    /**\r\n     * Test whether all contents of the specified directory must be excluded.\r\n     * @param path the path to check.\r\n     * @return whether all the specified directory\'s contents are excluded.\r\n     */\r\n    /* package */ boolean contentsExcluded(TokenizedPath path) {\r\n        for (int i = 0; i < excludePatterns.length; i++) {\r\n            if (excludePatterns[i].endsWith(SelectorUtils.DEEP_TREE_MATCH)\r\n                && excludePatterns[i].withoutLastToken()\r\n                   .matchPath(path, isCaseSensitive())) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a name matches against at least one exclude\r\n     * pattern.\r\n     *\r\n     * @param name The name to match. Must not be <code>null</code>.\r\n     * @return <code>true</code> when the name matches against at least one\r\n     *         exclude pattern, or <code>false</code> otherwise.\r\n     */\r\n    protected boolean isExcluded(String name) {\r\n        return isExcluded(new TokenizedPath(name));\r\n    }\r\n\r\n    /**\r\n     * Test whether or not a name matches against at least one exclude\r\n     * pattern.\r\n     *\r\n     * @param name The name to match. Must not be <code>null</code>.\r\n     * @return <code>true</code> when the name matches against at least one\r\n     *         exclude pattern, or <code>false</code> otherwise.\r\n     */\r\n    private boolean isExcluded(TokenizedPath name) {\r\n        ensureNonPatternSetsReady();\r\n\r\n        if (isCaseSensitive()\r\n            ? excludeNonPatterns.containsKey(name.toString())\r\n            : excludeNonPatterns.containsKey(name.toString().toUpperCase())) {\r\n            return true;\r\n        }\r\n        for (int i = 0; i < excludePatterns.length; i++) {\r\n            if (excludePatterns[i].matchPath(name, isCaseSensitive())) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n\r\n    /**\r\n     * Test whether a file should be selected.\r\n     *\r\n     * @param name the filename to check for selecting.\r\n     * @param file the java.io.File object for this filename.\r\n     * @return <code>false</code> when the selectors says that the file\r\n     *         should not be selected, <code>true</code> otherwise.\r\n     */\r\n    protected boolean isSelected(String name, File file) {\r\n        if (selectors != null) {\r\n            for (int i = 0; i < selectors.length; i++) {\r\n                if (!selectors[i].isSelected(basedir, name, file)) {\r\n                    return false;\r\n                }\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n\r\n    /**\r\n     * Return the names of the files which matched at least one of the\r\n     * include patterns and none of the exclude patterns.\r\n     * The names are relative to the base directory.\r\n     *\r\n     * @return the names of the files which matched at least one of the\r\n     *         include patterns and none of the exclude patterns.\r\n     */\r\n    public String[] getIncludedFiles() {\r\n        String[] files;\r\n        synchronized (this) {\r\n            if (filesIncluded == null) {\r\n                throw new IllegalStateException(\"Must call scan() first\");\r\n            }\r\n            files = new String[filesIncluded.size()];\r\n            filesIncluded.copyInto(files);\r\n        }\r\n        Arrays.sort(files);\r\n        return files;\r\n    }\r\n\r\n    /**\r\n     * Return the count of included files.\r\n     * @return <code>int</code>.\r\n     * @since Ant 1.6.3\r\n     */\r\n    public synchronized int getIncludedFilesCount() {\r\n        if (filesIncluded == null) {\r\n            throw new IllegalStateException(\"Must call scan() first\");\r\n        }\r\n        return filesIncluded.size();\r\n    }\r\n\r\n    /**\r\n     * Return the names of the files which matched none of the include\r\n     * patterns. The names are relative to the base directory. This involves\r\n     * performing a slow scan if one has not already been completed.\r\n     *\r\n     * @return the names of the files which matched none of the include\r\n     *         patterns.\r\n     *\r\n     * @see #slowScan\r\n     */\r\n    public synchronized String[] getNotIncludedFiles() {\r\n        slowScan();\r\n        String[] files = new String[filesNotIncluded.size()];\r\n        filesNotIncluded.copyInto(files);\r\n        return files;\r\n    }\r\n\r\n    /**\r\n     * Return the names of the files which matched at least one of the\r\n     * include patterns and at least one of the exclude patterns.\r\n     * The names are relative to the base directory. This involves\r\n     * performing a slow scan if one has not already been completed.\r\n     *\r\n     * @return the names of the files which matched at least one of the\r\n     *         include patterns and at least one of the exclude patterns.\r\n     *\r\n     * @see #slowScan\r\n     */\r\n    public synchronized String[] getExcludedFiles() {\r\n        slowScan();\r\n        String[] files = new String[filesExcluded.size()];\r\n        filesExcluded.copyInto(files);\r\n        return files;\r\n    }\r\n\r\n    /**\r\n     * <p>Return the names of the files which were selected out and\r\n     * therefore not ultimately included.</p>\r\n     *\r\n     * <p>The names are relative to the base directory. This involves\r\n     * performing a slow scan if one has not already been completed.</p>\r\n     *\r\n     * @return the names of the files which were deselected.\r\n     *\r\n     * @see #slowScan\r\n     */\r\n    public synchronized String[] getDeselectedFiles() {\r\n        slowScan();\r\n        String[] files = new String[filesDeselected.size()];\r\n        filesDeselected.copyInto(files);\r\n        return files;\r\n    }\r\n\r\n    /**\r\n     * Return the names of the directories which matched at least one of the\r\n     * include patterns and none of the exclude patterns.\r\n     * The names are relative to the base directory.\r\n     *\r\n     * @return the names of the directories which matched at least one of the\r\n     * include patterns and none of the exclude patterns.\r\n     */\r\n    public String[] getIncludedDirectories() {\r\n        String[] directories;\r\n        synchronized (this) {\r\n            if (dirsIncluded == null) {\r\n                throw new IllegalStateException(\"Must call scan() first\");\r\n            }\r\n            directories = new String[dirsIncluded.size()];\r\n            dirsIncluded.copyInto(directories);\r\n        }\r\n        Arrays.sort(directories);\r\n        return directories;\r\n    }\r\n\r\n    /**\r\n     * Return the count of included directories.\r\n     * @return <code>int</code>.\r\n     * @since Ant 1.6.3\r\n     */\r\n    public synchronized int getIncludedDirsCount() {\r\n        if (dirsIncluded == null) {\r\n            throw new IllegalStateException(\"Must call scan() first\");\r\n        }\r\n        return dirsIncluded.size();\r\n    }\r\n\r\n    /**\r\n     * Return the names of the directories which matched none of the include\r\n     * patterns. The names are relative to the base directory. This involves\r\n     * performing a slow scan if one has not already been completed.\r\n     *\r\n     * @return the names of the directories which matched none of the include\r\n     * patterns.\r\n     *\r\n     * @see #slowScan\r\n     */\r\n    public synchronized String[] getNotIncludedDirectories() {\r\n        slowScan();\r\n        String[] directories = new String[dirsNotIncluded.size()];\r\n        dirsNotIncluded.copyInto(directories);\r\n        return directories;\r\n    }\r\n\r\n    /**\r\n     * Return the names of the directories which matched at least one of the\r\n     * include patterns and at least one of the exclude patterns.\r\n     * The names are relative to the base directory. This involves\r\n     * performing a slow scan if one has not already been completed.\r\n     *\r\n     * @return the names of the directories which matched at least one of the\r\n     * include patterns and at least one of the exclude patterns.\r\n     *\r\n     * @see #slowScan\r\n     */\r\n    public synchronized String[] getExcludedDirectories() {\r\n        slowScan();\r\n        String[] directories = new String[dirsExcluded.size()];\r\n        dirsExcluded.copyInto(directories);\r\n        return directories;\r\n    }\r\n\r\n    /**\r\n     * <p>Return the names of the directories which were selected out and\r\n     * therefore not ultimately included.</p>\r\n     *\r\n     * <p>The names are relative to the base directory. This involves\r\n     * performing a slow scan if one has not already been completed.</p>\r\n     *\r\n     * @return the names of the directories which were deselected.\r\n     *\r\n     * @see #slowScan\r\n     */\r\n    public synchronized String[] getDeselectedDirectories() {\r\n        slowScan();\r\n        String[] directories = new String[dirsDeselected.size()];\r\n        dirsDeselected.copyInto(directories);\r\n        return directories;\r\n    }\r\n\r\n    /**\r\n     * Absolute paths of all symbolic links that haven\'t been followed\r\n     * but would have been followed had followsymlinks been true or\r\n     * maxLevelsOfSymlinks been bigger.\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    public synchronized String[] getNotFollowedSymlinks() {\r\n        String[] links;\r\n        synchronized (this) {\r\n            links = (String[]) notFollowedSymlinks\r\n                .toArray(new String[notFollowedSymlinks.size()]);\r\n        }\r\n        Arrays.sort(links);\r\n        return links;\r\n    }\r\n\r\n    /**\r\n     * Add default exclusions to the current exclusions set.\r\n     */\r\n    public synchronized void addDefaultExcludes() {\r\n        int excludesLength = excludes == null ? 0 : excludes.length;\r\n        String[] newExcludes;\r\n        String[] defaultExcludesTemp = getDefaultExcludes();\r\n        newExcludes = new String[excludesLength + defaultExcludesTemp.length];\r\n        if (excludesLength > 0) {\r\n            System.arraycopy(excludes, 0, newExcludes, 0, excludesLength);\r\n        }\r\n        for (int i = 0; i < defaultExcludesTemp.length; i++) {\r\n            newExcludes[i + excludesLength] =\r\n                defaultExcludesTemp[i].replace(\'/\', File.separatorChar)\r\n                .replace(\'\\\\\', File.separatorChar);\r\n        }\r\n        excludes = newExcludes;\r\n    }\r\n\r\n    /**\r\n     * Get the named resource.\r\n     * @param name path name of the file relative to the dir attribute.\r\n     *\r\n     * @return the resource with the given name.\r\n     * @since Ant 1.5.2\r\n     */\r\n    public synchronized Resource getResource(String name) {\r\n        return new FileResource(basedir, name);\r\n    }\r\n\r\n    /**\r\n     * Has the directory with the given path relative to the base\r\n     * directory already been scanned?\r\n     *\r\n     * <p>Registers the given directory as scanned as a side effect.</p>\r\n     *\r\n     * @since Ant 1.6\r\n     */\r\n    private boolean hasBeenScanned(String vpath) {\r\n        return !scannedDirs.add(vpath);\r\n    }\r\n\r\n    /**\r\n     * This method is of interest for testing purposes.  The returned\r\n     * Set is live and should not be modified.\r\n     * @return the Set of relative directory names that have been scanned.\r\n     */\r\n    /* package-private */ Set getScannedDirs() {\r\n        return scannedDirs;\r\n    }\r\n\r\n    /**\r\n     * Clear internal caches.\r\n     *\r\n     * @since Ant 1.6\r\n     */\r\n    private synchronized void clearCaches() {\r\n        includeNonPatterns.clear();\r\n        excludeNonPatterns.clear();\r\n        includePatterns = null;\r\n        excludePatterns = null;\r\n        areNonPatternSetsReady = false;\r\n    }\r\n\r\n    /**\r\n     * Ensure that the in|exclude &quot;patterns&quot;\r\n     * have been properly divided up.\r\n     *\r\n     * @since Ant 1.6.3\r\n     */\r\n    /* package */ synchronized void ensureNonPatternSetsReady() {\r\n        if (!areNonPatternSetsReady) {\r\n            includePatterns = fillNonPatternSet(includeNonPatterns, includes);\r\n            excludePatterns = fillNonPatternSet(excludeNonPatterns, excludes);\r\n            areNonPatternSetsReady = true;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Add all patterns that are not real patterns (do not contain\r\n     * wildcards) to the set and returns the real patterns.\r\n     *\r\n     * @param map Map to populate.\r\n     * @param patterns String[] of patterns.\r\n     * @since Ant 1.8.0\r\n     */\r\n    private TokenizedPattern[] fillNonPatternSet(Map map, String[] patterns) {\r\n        ArrayList al = new ArrayList(patterns.length);\r\n        for (int i = 0; i < patterns.length; i++) {\r\n            if (!SelectorUtils.hasWildcards(patterns[i])) {\r\n                String s = isCaseSensitive()\r\n                    ? patterns[i] : patterns[i].toUpperCase();\r\n                map.put(s, new TokenizedPath(s));\r\n            } else {\r\n                al.add(new TokenizedPattern(patterns[i]));\r\n            }\r\n        }\r\n        return (TokenizedPattern[]) al.toArray(new TokenizedPattern[al.size()]);\r\n    }\r\n\r\n    /**\r\n     * Would following the given directory cause a loop of symbolic\r\n     * links deeper than allowed?\r\n     *\r\n     * <p>Can only happen if the given directory has been seen at\r\n     * least more often than allowed during the current scan and it is\r\n     * a symbolic link and enough other occurences of the same name\r\n     * higher up are symbolic links that point to the same place.</p>\r\n     *\r\n     * @since Ant 1.8.0\r\n     */\r\n    private boolean causesIllegalSymlinkLoop(String dirName, File parent,\r\n                                             LinkedList directoryNamesFollowed) {\r\n        try {\r\n            if (directoryNamesFollowed.size() >= maxLevelsOfSymlinks\r\n                && CollectionUtils.frequency(directoryNamesFollowed, dirName)\r\n                   >= maxLevelsOfSymlinks\r\n                && SYMLINK_UTILS.isSymbolicLink(parent, dirName)) {\r\n\r\n                ArrayList files = new ArrayList();\r\n                File f = FILE_UTILS.resolveFile(parent, dirName);\r\n                String target = f.getCanonicalPath();\r\n                files.add(target);\r\n\r\n                String relPath = \"\";\r\n                for (Iterator i = directoryNamesFollowed.iterator();\r\n                     i.hasNext(); ) {\r\n                    relPath += \"../\";\r\n                    String dir = (String) i.next();\r\n                    if (dirName.equals(dir)) {\r\n                        f = FILE_UTILS.resolveFile(parent, relPath + dir);\r\n                        files.add(f.getCanonicalPath());\r\n                        if (files.size() > maxLevelsOfSymlinks\r\n                            && CollectionUtils.frequency(files, target)\r\n                                 > maxLevelsOfSymlinks) {\r\n                            return true;\r\n                        }\r\n                    }\r\n                }\r\n\r\n            }\r\n            return false;\r\n        } catch (IOException ex) {\r\n            throw new BuildException(\"Caught error while checking for\"\r\n                                     + \" symbolic links\", ex);\r\n        }\r\n    }\r\n\r\n}','ant','Public Class','org.apache.tools.ant.DirectoryScanner',0,7,'gc'),(7,'dt6.png','/**\r\n * Licensed to the Apache Software Foundation (ASF) under one\r\n * or more contributor license agreements.  See the NOTICE file\r\n * distributed with this work for additional information\r\n * regarding copyright ownership.  The ASF licenses this file\r\n * to you under the Apache License, Version 2.0 (the\r\n * \"License\"); you may not use this file except in compliance\r\n * with the License.  You may obtain a copy of the License at\r\n *\r\n *     http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\r\n\r\npackage org.apache.cassandra.service;\r\n\r\nimport java.io.File;\r\nimport java.io.IOError;\r\nimport java.io.IOException;\r\nimport java.lang.management.ManagementFactory;\r\nimport java.net.InetAddress;\r\nimport java.net.UnknownHostException;\r\nimport java.nio.ByteBuffer;\r\nimport java.util.*;\r\nimport java.util.Map.Entry;\r\nimport java.util.concurrent.*;\r\nimport java.util.concurrent.atomic.AtomicInteger;\r\nimport java.util.concurrent.atomic.AtomicLong;\r\nimport javax.management.MBeanServer;\r\nimport javax.management.Notification;\r\nimport javax.management.NotificationBroadcasterSupport;\r\nimport javax.management.ObjectName;\r\n\r\nimport com.google.common.base.Supplier;\r\nimport com.google.common.collect.*;\r\n\r\nimport org.apache.cassandra.metrics.ClientRequestMetrics;\r\n\r\nimport org.apache.log4j.Level;\r\nimport org.apache.commons.lang.StringUtils;\r\nimport org.slf4j.Logger;\r\nimport org.slf4j.LoggerFactory;\r\n\r\nimport org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor;\r\nimport org.apache.cassandra.concurrent.Stage;\r\nimport org.apache.cassandra.concurrent.StageManager;\r\nimport org.apache.cassandra.config.*;\r\nimport org.apache.cassandra.db.*;\r\nimport org.apache.cassandra.db.Table;\r\nimport org.apache.cassandra.db.commitlog.CommitLog;\r\nimport org.apache.cassandra.dht.*;\r\nimport org.apache.cassandra.dht.Range;\r\nimport org.apache.cassandra.gms.*;\r\nimport org.apache.cassandra.io.sstable.SSTableDeletingTask;\r\nimport org.apache.cassandra.io.sstable.SSTableLoader;\r\nimport org.apache.cassandra.io.util.FileUtils;\r\nimport org.apache.cassandra.locator.AbstractReplicationStrategy;\r\nimport org.apache.cassandra.locator.DynamicEndpointSnitch;\r\nimport org.apache.cassandra.locator.IEndpointSnitch;\r\nimport org.apache.cassandra.locator.TokenMetadata;\r\nimport org.apache.cassandra.net.IAsyncResult;\r\nimport org.apache.cassandra.net.Message;\r\nimport org.apache.cassandra.net.MessagingService;\r\nimport org.apache.cassandra.net.ResponseVerbHandler;\r\nimport org.apache.cassandra.service.AntiEntropyService.TreeRequestVerbHandler;\r\nimport org.apache.cassandra.streaming.*;\r\nimport org.apache.cassandra.thrift.*;\r\nimport org.apache.cassandra.utils.FBUtilities;\r\nimport org.apache.cassandra.utils.NodeId;\r\nimport org.apache.cassandra.utils.Pair;\r\nimport org.apache.cassandra.utils.OutputHandler;\r\nimport org.apache.cassandra.utils.WrappedRunnable;\r\n\r\n/**\r\n * This abstraction contains the token/identifier of this node\r\n * on the identifier space. This token gets gossiped around.\r\n * This class will also maintain histograms of the load information\r\n * of other nodes in the cluster.\r\n */\r\npublic class StorageService extends NotificationBroadcasterSupport implements IEndpointStateChangeSubscriber, StorageServiceMBean\r\n{\r\n    private static Logger logger_ = LoggerFactory.getLogger(StorageService.class);\r\n\r\n    public static final int RING_DELAY = getRingDelay(); // delay after which we assume ring has stablized\r\n\r\n    /* JMX notification serial number counter */\r\n    private final AtomicLong notificationSerialNumber = new AtomicLong();\r\n\r\n    /* All verb handler identifiers */\r\n    public enum Verb\r\n    {\r\n        MUTATION,\r\n        BINARY, // Deprecated\r\n        READ_REPAIR,\r\n        READ,\r\n        REQUEST_RESPONSE, // client-initiated reads and writes\r\n        STREAM_INITIATE, // Deprecated\r\n        STREAM_INITIATE_DONE, // Deprecated\r\n        STREAM_REPLY,\r\n        STREAM_REQUEST,\r\n        RANGE_SLICE,\r\n        BOOTSTRAP_TOKEN,\r\n        TREE_REQUEST,\r\n        TREE_RESPONSE,\r\n        JOIN, // Deprecated\r\n        GOSSIP_DIGEST_SYN,\r\n        GOSSIP_DIGEST_ACK,\r\n        GOSSIP_DIGEST_ACK2,\r\n        DEFINITIONS_ANNOUNCE, // Deprecated\r\n        DEFINITIONS_UPDATE,\r\n        TRUNCATE,\r\n        SCHEMA_CHECK,\r\n        INDEX_SCAN, // Deprecated\r\n        REPLICATION_FINISHED,\r\n        INTERNAL_RESPONSE, // responses to internal calls\r\n        COUNTER_MUTATION,\r\n        STREAMING_REPAIR_REQUEST,\r\n        STREAMING_REPAIR_RESPONSE,\r\n        SNAPSHOT, // Similar to nt snapshot\r\n        MIGRATION_REQUEST,\r\n        GOSSIP_SHUTDOWN,\r\n        // use as padding for backwards compatability where a previous version needs to validate a verb from the future.\r\n        UNUSED_1,\r\n        UNUSED_2,\r\n        UNUSED_3,\r\n        ;\r\n        // remember to add new verbs at the end, since we serialize by ordinal\r\n    }\r\n    public static final Verb[] VERBS = Verb.values();\r\n\r\n    public static final EnumMap<StorageService.Verb, Stage> verbStages = new EnumMap<StorageService.Verb, Stage>(StorageService.Verb.class)\r\n    {{\r\n        put(Verb.MUTATION, Stage.MUTATION);\r\n        put(Verb.BINARY, Stage.MUTATION);\r\n        put(Verb.READ_REPAIR, Stage.MUTATION);\r\n        put(Verb.TRUNCATE, Stage.MUTATION);\r\n        put(Verb.READ, Stage.READ);\r\n        put(Verb.REQUEST_RESPONSE, Stage.REQUEST_RESPONSE);\r\n        put(Verb.STREAM_REPLY, Stage.MISC); // TODO does this really belong on misc? I\'ve just copied old behavior here\r\n        put(Verb.STREAM_REQUEST, Stage.STREAM);\r\n        put(Verb.RANGE_SLICE, Stage.READ);\r\n        put(Verb.BOOTSTRAP_TOKEN, Stage.MISC);\r\n        put(Verb.TREE_REQUEST, Stage.ANTI_ENTROPY);\r\n        put(Verb.TREE_RESPONSE, Stage.ANTI_ENTROPY);\r\n        put(Verb.STREAMING_REPAIR_REQUEST, Stage.ANTI_ENTROPY);\r\n        put(Verb.STREAMING_REPAIR_RESPONSE, Stage.ANTI_ENTROPY);\r\n        put(Verb.GOSSIP_DIGEST_ACK, Stage.GOSSIP);\r\n        put(Verb.GOSSIP_DIGEST_ACK2, Stage.GOSSIP);\r\n        put(Verb.GOSSIP_DIGEST_SYN, Stage.GOSSIP);\r\n        put(Verb.GOSSIP_SHUTDOWN, Stage.GOSSIP);\r\n        put(Verb.DEFINITIONS_UPDATE, Stage.MIGRATION);\r\n        put(Verb.SCHEMA_CHECK, Stage.MIGRATION);\r\n        put(Verb.MIGRATION_REQUEST, Stage.MIGRATION);\r\n        put(Verb.INDEX_SCAN, Stage.READ);\r\n        put(Verb.REPLICATION_FINISHED, Stage.MISC);\r\n        put(Verb.INTERNAL_RESPONSE, Stage.INTERNAL_RESPONSE);\r\n        put(Verb.COUNTER_MUTATION, Stage.MUTATION);\r\n        put(Verb.SNAPSHOT, Stage.MISC);\r\n        put(Verb.UNUSED_1, Stage.INTERNAL_RESPONSE);\r\n        put(Verb.UNUSED_2, Stage.INTERNAL_RESPONSE);\r\n        put(Verb.UNUSED_3, Stage.INTERNAL_RESPONSE);\r\n    }};\r\n\r\n    private static int getRingDelay()\r\n    {\r\n        String newdelay = System.getProperty(\"cassandra.ring_delay_ms\");\r\n        if (newdelay != null)\r\n        {\r\n            logger_.info(\"Overriding RING_DELAY to {}ms\", newdelay);\r\n            return Integer.parseInt(newdelay);\r\n        }\r\n        else\r\n            return 30 * 1000;\r\n    }\r\n\r\n    /**\r\n     * This pool is used for periodic short (sub-second) tasks.\r\n     */\r\n     public static final DebuggableScheduledThreadPoolExecutor scheduledTasks = new DebuggableScheduledThreadPoolExecutor(\"ScheduledTasks\");\r\n\r\n    /**\r\n     * This pool is used by tasks that can have longer execution times, and usually are non periodic.\r\n     */\r\n    public static final DebuggableScheduledThreadPoolExecutor tasks = new DebuggableScheduledThreadPoolExecutor(\"NonPeriodicTasks\");\r\n\r\n    /**\r\n     * tasks that do not need to be waited for on shutdown/drain\r\n     */\r\n    public static final DebuggableScheduledThreadPoolExecutor optionalTasks = new DebuggableScheduledThreadPoolExecutor(\"OptionalTasks\");\r\n    static\r\n    {\r\n        tasks.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\r\n    }\r\n\r\n    /* This abstraction maintains the token/endpoint metadata information */\r\n    private TokenMetadata tokenMetadata_ = new TokenMetadata();\r\n\r\n    public VersionedValue.VersionedValueFactory valueFactory = new VersionedValue.VersionedValueFactory(getPartitioner());\r\n\r\n    public static final StorageService instance = new StorageService();\r\n\r\n    public static IPartitioner getPartitioner()\r\n    {\r\n        return DatabaseDescriptor.getPartitioner();\r\n    }\r\n\r\n    public Collection<Range<Token>> getLocalRanges(String table)\r\n    {\r\n        return getRangesForEndpoint(table, FBUtilities.getBroadcastAddress());\r\n    }\r\n\r\n    public Range<Token> getLocalPrimaryRange()\r\n    {\r\n        return getPrimaryRangeForEndpoint(FBUtilities.getBroadcastAddress());\r\n    }\r\n\r\n    // For JMX\'s sake. Use getLocalPrimaryRange for internal uses\r\n    public List<String> getPrimaryRange()\r\n    {\r\n        return getLocalPrimaryRange().asList();\r\n    }\r\n\r\n    private final Set<InetAddress> replicatingNodes = Collections.synchronizedSet(new HashSet<InetAddress>());\r\n    private CassandraDaemon daemon;\r\n\r\n    private InetAddress removingNode;\r\n\r\n    /* Are we starting this node in bootstrap mode? */\r\n    private boolean isBootstrapMode;\r\n\r\n    /* we bootstrap but do NOT join the ring unless told to do so */\r\n    private boolean isSurveyMode= Boolean.parseBoolean(System.getProperty(\"cassandra.write_survey\", \"false\"));\r\n\r\n    /* when intialized as a client, we shouldn\'t write to the system table. */\r\n    private boolean isClientMode;\r\n    private boolean initialized;\r\n    private volatile boolean joined = false;\r\n\r\n    private static enum Mode { NORMAL, CLIENT, JOINING, LEAVING, DECOMMISSIONED, MOVING, DRAINING, DRAINED }\r\n    private Mode operationMode;\r\n\r\n    private final MigrationManager migrationManager = new MigrationManager();\r\n\r\n    /* Used for tracking drain progress */\r\n    private volatile int totalCFs, remainingCFs;\r\n\r\n    private static final AtomicInteger nextRepairCommand = new AtomicInteger();\r\n\r\n    private final ObjectName jmxObjectName;\r\n\r\n    public void finishBootstrapping()\r\n    {\r\n        isBootstrapMode = false;\r\n    }\r\n\r\n    /** This method updates the local token on disk  */\r\n    public void setToken(Token token)\r\n    {\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Setting token to {}\", token);\r\n        SystemTable.updateToken(token);\r\n        tokenMetadata_.updateNormalToken(token, FBUtilities.getBroadcastAddress());\r\n        Gossiper.instance.addLocalApplicationState(ApplicationState.STATUS, valueFactory.normal(getLocalToken()));\r\n        setMode(Mode.NORMAL, false);\r\n    }\r\n\r\n    public StorageService()\r\n    {\r\n        MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();\r\n        try\r\n        {\r\n            jmxObjectName = new ObjectName(\"org.apache.cassandra.db:type=StorageService\");\r\n            mbs.registerMBean(this, jmxObjectName);\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            throw new RuntimeException(e);\r\n        }\r\n\r\n        /* register the verb handlers */\r\n        MessagingService.instance().registerVerbHandlers(Verb.MUTATION, new RowMutationVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.READ_REPAIR, new ReadRepairVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.READ, new ReadVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.RANGE_SLICE, new RangeSliceVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.INDEX_SCAN, new IndexScanVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.COUNTER_MUTATION, new CounterMutationVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.TRUNCATE, new TruncateVerbHandler());\r\n\r\n        // see BootStrapper for a summary of how the bootstrap verbs interact\r\n        MessagingService.instance().registerVerbHandlers(Verb.BOOTSTRAP_TOKEN, new BootStrapper.BootstrapTokenVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.STREAM_REQUEST, new StreamRequestVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.STREAM_REPLY, new StreamReplyVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.REPLICATION_FINISHED, new ReplicationFinishedVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.REQUEST_RESPONSE, new ResponseVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.INTERNAL_RESPONSE, new ResponseVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.TREE_REQUEST, new TreeRequestVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.TREE_RESPONSE, new AntiEntropyService.TreeResponseVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.STREAMING_REPAIR_REQUEST, new StreamingRepairTask.StreamingRepairRequest());\r\n        MessagingService.instance().registerVerbHandlers(Verb.STREAMING_REPAIR_RESPONSE, new StreamingRepairTask.StreamingRepairResponse());\r\n\r\n        MessagingService.instance().registerVerbHandlers(Verb.GOSSIP_DIGEST_SYN, new GossipDigestSynVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.GOSSIP_DIGEST_ACK, new GossipDigestAckVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.GOSSIP_DIGEST_ACK2, new GossipDigestAck2VerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.GOSSIP_SHUTDOWN, new GossipShutdownVerbHandler());\r\n\r\n        MessagingService.instance().registerVerbHandlers(Verb.DEFINITIONS_UPDATE, new DefinitionsUpdateVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.SCHEMA_CHECK, new SchemaCheckVerbHandler());\r\n        MessagingService.instance().registerVerbHandlers(Verb.MIGRATION_REQUEST, new MigrationRequestVerbHandler());\r\n\r\n        MessagingService.instance().registerVerbHandlers(Verb.SNAPSHOT, new SnapshotVerbHandler());\r\n\r\n        // spin up the streaming service so it is available for jmx tools.\r\n        if (StreamingService.instance == null)\r\n            throw new RuntimeException(\"Streaming service is unavailable.\");\r\n    }\r\n\r\n    public void registerDaemon(CassandraDaemon daemon)\r\n    {\r\n        this.daemon = daemon;\r\n    }\r\n\r\n    // should only be called via JMX\r\n    public void stopGossiping()\r\n    {\r\n        if (initialized)\r\n        {\r\n            logger_.warn(\"Stopping gossip by operator request\");\r\n            Gossiper.instance.stop();\r\n            initialized = false;\r\n        }\r\n    }\r\n\r\n    // should only be called via JMX\r\n    public void startGossiping()\r\n    {\r\n        if (!initialized)\r\n        {\r\n            logger_.warn(\"Starting gossip by operator request\");\r\n            Gossiper.instance.start((int)(System.currentTimeMillis() / 1000));\r\n            initialized = true;\r\n        }\r\n    }\r\n\r\n    // should only be called via JMX\r\n    public void startRPCServer()\r\n    {\r\n        if (daemon == null)\r\n        {\r\n            throw new IllegalStateException(\"No configured RPC daemon\");\r\n        }\r\n        daemon.startRPCServer();\r\n    }\r\n\r\n    public void stopRPCServer()\r\n    {\r\n        if (daemon == null)\r\n        {\r\n            throw new IllegalStateException(\"No configured RPC daemon\");\r\n        }\r\n        daemon.stopRPCServer();\r\n    }\r\n\r\n    public boolean isRPCServerRunning()\r\n    {\r\n        if (daemon == null)\r\n        {\r\n            return false;\r\n        }\r\n        return daemon.isRPCServerRunning();\r\n    }\r\n\r\n    public void stopClient()\r\n    {\r\n        Gossiper.instance.unregister(migrationManager);\r\n        Gossiper.instance.unregister(this);\r\n        Gossiper.instance.stop();\r\n        MessagingService.instance().shutdown();\r\n        // give it a second so that task accepted before the MessagingService shutdown gets submitted to the stage (to avoid RejectedExecutionException)\r\n        try { Thread.sleep(1000L); } catch (InterruptedException e) {}\r\n        StageManager.shutdownNow();\r\n    }\r\n\r\n    public boolean isInitialized()\r\n    {\r\n        return initialized;\r\n    }\r\n\r\n    public synchronized void initClient() throws IOException, ConfigurationException\r\n    {\r\n        initClient(RING_DELAY);\r\n    }\r\n\r\n    public synchronized void initClient(int delay) throws IOException, ConfigurationException\r\n    {\r\n        if (initialized)\r\n        {\r\n            if (!isClientMode)\r\n                throw new UnsupportedOperationException(\"StorageService does not support switching modes.\");\r\n            return;\r\n        }\r\n        initialized = true;\r\n        isClientMode = true;\r\n        logger_.info(\"Starting up client gossip\");\r\n        setMode(Mode.CLIENT, false);\r\n        Gossiper.instance.register(this);\r\n        Gossiper.instance.start((int)(System.currentTimeMillis() / 1000)); // needed for node-ring gathering.\r\n        MessagingService.instance().listen(FBUtilities.getLocalAddress());\r\n\r\n        // sleep a while to allow gossip to warm up (the other nodes need to know about this one before they can reply).\r\n        try\r\n        {\r\n            Thread.sleep(delay);\r\n        }\r\n        catch (Exception ex)\r\n        {\r\n            throw new IOError(ex);\r\n        }\r\n\r\n        Schema.instance.updateVersionAndAnnounce();\r\n    }\r\n\r\n    public synchronized void initServer() throws IOException, ConfigurationException\r\n    {\r\n        initServer(RING_DELAY);\r\n    }\r\n\r\n    public synchronized void initServer(int delay) throws IOException, ConfigurationException\r\n    {\r\n        logger_.info(\"Cassandra version: \" + FBUtilities.getReleaseVersionString());\r\n        logger_.info(\"Thrift API version: \" + Constants.VERSION);\r\n        logger_.info(\"CQL supported versions: \" + StringUtils.join(ClientState.getCQLSupportedVersion(), \",\") + \" (default: \" + ClientState.DEFAULT_CQL_VERSION + \")\");\r\n\r\n        if (initialized)\r\n        {\r\n            if (isClientMode)\r\n                throw new UnsupportedOperationException(\"StorageService does not support switching modes.\");\r\n            return;\r\n        }\r\n        initialized = true;\r\n        isClientMode = false;\r\n\r\n        // Ensure StorageProxy is initialized on start-up; see CASSANDRA-3797.\r\n        try\r\n        {\r\n            Class.forName(\"org.apache.cassandra.service.StorageProxy\");\r\n        }\r\n        catch (ClassNotFoundException e)\r\n        {\r\n            throw new AssertionError(e);\r\n        }\r\n\r\n        if (!isClientMode)\r\n        {\r\n            // \"Touch\" metrics classes to trigger static initialization, such that all metrics become available\r\n            // on start-up even if they have not yet been used.\r\n            new ClientRequestMetrics();\r\n        }\r\n\r\n        if (Boolean.parseBoolean(System.getProperty(\"cassandra.load_ring_state\", \"true\")))\r\n        {\r\n            logger_.info(\"Loading persisted ring state\");\r\n            for (Map.Entry<Token, InetAddress> entry : SystemTable.loadTokens().entrySet())\r\n            {\r\n                if (entry.getValue() == FBUtilities.getLocalAddress())\r\n                {\r\n                    // entry has been mistakenly added, delete it\r\n                    SystemTable.removeToken(entry.getKey());\r\n                }\r\n                else\r\n                {\r\n                    tokenMetadata_.updateNormalToken(entry.getKey(), entry.getValue());\r\n                    Gossiper.instance.addSavedEndpoint(entry.getValue());\r\n                }\r\n            }\r\n        }\r\n\r\n        if (Boolean.parseBoolean(System.getProperty(\"cassandra.renew_counter_id\", \"false\")))\r\n        {\r\n            logger_.info(\"Renewing local node id (as requested)\");\r\n            NodeId.renewLocalId();\r\n        }\r\n\r\n        // daemon threads, like our executors\', continue to run while shutdown hooks are invoked\r\n        Thread drainOnShutdown = new Thread(new WrappedRunnable()\r\n        {\r\n            @Override\r\n            public void runMayThrow() throws ExecutionException, InterruptedException, IOException\r\n            {\r\n                ThreadPoolExecutor mutationStage = StageManager.getStage(Stage.MUTATION);\r\n                if (mutationStage.isShutdown())\r\n                    return; // drained already\r\n\r\n                stopRPCServer();\r\n                optionalTasks.shutdown();\r\n                Gossiper.instance.stop();\r\n\r\n                // In-progress writes originating here could generate hints to be written, so shut down MessagingService\r\n                // before mutation stage, so we can get all the hints saved before shutting down\r\n                MessagingService.instance().shutdown();\r\n                mutationStage.shutdown();\r\n                mutationStage.awaitTermination(3600, TimeUnit.SECONDS);\r\n                StorageProxy.instance.verifyNoHintsInProgress();\r\n\r\n                List<Future<?>> flushes = new ArrayList<Future<?>>();\r\n                for (Table table : Table.all())\r\n                {\r\n                    KSMetaData ksm = Schema.instance.getKSMetaData(table.name);\r\n                    if (!ksm.durableWrites)\r\n                    {\r\n                        for (ColumnFamilyStore cfs : table.getColumnFamilyStores())\r\n                        {\r\n                            Future<?> future = cfs.forceFlush();\r\n                            if (future != null)\r\n                                flushes.add(future);\r\n                        }\r\n                    }\r\n                }\r\n                FBUtilities.waitOnFutures(flushes);\r\n\r\n                CommitLog.instance.shutdownBlocking();\r\n\r\n                // wait for miscellaneous tasks like sstable and commitlog segment deletion\r\n                tasks.shutdown();\r\n                if (!tasks.awaitTermination(1, TimeUnit.MINUTES))\r\n                    logger_.warn(\"Miscellaneous task executor still busy after one minute; proceeding with shutdown\");\r\n            }\r\n        }, \"StorageServiceShutdownHook\");\r\n        Runtime.getRuntime().addShutdownHook(drainOnShutdown);\r\n\r\n        if (Boolean.parseBoolean(System.getProperty(\"cassandra.join_ring\", \"true\")))\r\n        {\r\n            joinTokenRing(delay);\r\n        }\r\n        else\r\n        {\r\n            logger_.info(\"Not joining ring as requested. Use JMX (StorageService->joinRing()) to initiate ring joining\");\r\n        }\r\n    }\r\n\r\n    private void joinTokenRing(int delay) throws IOException, org.apache.cassandra.config.ConfigurationException\r\n    {\r\n        logger_.info(\"Starting up server gossip\");\r\n        joined = true;\r\n\r\n\r\n        // have to start the gossip service before we can see any info on other nodes.  this is necessary\r\n        // for bootstrap to get the load info it needs.\r\n        // (we won\'t be part of the storage ring though until we add a nodeId to our state, below.)\r\n        Gossiper.instance.register(this);\r\n        Gossiper.instance.register(migrationManager);\r\n        Gossiper.instance.start(SystemTable.incrementAndGetGeneration()); // needed for node-ring gathering.\r\n\r\n        // gossip Schema.emptyVersion forcing immediate check for schema updates (see MigrationManager#maybeScheduleSchemaPull)\r\n        Schema.instance.updateVersionAndAnnounce(); // Ensure we know our own actual Schema UUID in preparation for updates\r\n\r\n        // add rpc listening info\r\n        Gossiper.instance.addLocalApplicationState(ApplicationState.RPC_ADDRESS, valueFactory.rpcaddress(DatabaseDescriptor.getRpcAddress()));\r\n        if (null != DatabaseDescriptor.getReplaceToken())\r\n            Gossiper.instance.addLocalApplicationState(ApplicationState.STATUS, valueFactory.hibernate(true));\r\n\r\n        MessagingService.instance().listen(FBUtilities.getLocalAddress());\r\n        LoadBroadcaster.instance.startBroadcasting();\r\n        Gossiper.instance.addLocalApplicationState(ApplicationState.RELEASE_VERSION, valueFactory.releaseVersion());\r\n\r\n        HintedHandOffManager.instance.start();\r\n\r\n        // We bootstrap if we haven\'t successfully bootstrapped before, as long as we are not a seed.\r\n        // If we are a seed, or if the user manually sets auto_bootstrap to false,\r\n        // we\'ll skip streaming data from other nodes and jump directly into the ring.\r\n        //\r\n        // The seed check allows us to skip the RING_DELAY sleep for the single-node cluster case,\r\n        // which is useful for both new users and testing.\r\n        //\r\n        // We attempted to replace this with a schema-presence check, but you need a meaningful sleep\r\n        // to get schema info from gossip which defeats the purpose.  See CASSANDRA-4427 for the gory details.\r\n        Token<?> token;\r\n        InetAddress current = null;\r\n        logger_.debug(\"Bootstrap variables: {} {} {} {}\",\r\n                      new Object[]{ DatabaseDescriptor.isAutoBootstrap(),\r\n                                    SystemTable.bootstrapInProgress(),\r\n                                    SystemTable.bootstrapComplete(),\r\n                                    DatabaseDescriptor.getSeeds().contains(FBUtilities.getBroadcastAddress())});\r\n        if (DatabaseDescriptor.isAutoBootstrap()\r\n            && !SystemTable.bootstrapComplete()\r\n            && !DatabaseDescriptor.getSeeds().contains(FBUtilities.getBroadcastAddress()))\r\n        {\r\n            if (SystemTable.bootstrapInProgress())\r\n                logger_.warn(\"Detected previous bootstrap failure; retrying\");\r\n            else\r\n                SystemTable.setBootstrapState(SystemTable.BootstrapState.IN_PROGRESS);\r\n            setMode(Mode.JOINING, \"waiting for ring information\", true);\r\n            // first sleep the delay to make sure we see all our peers\r\n            for (int i = 0; i < delay; i += 1000)\r\n            {\r\n                // if we see schema, we can proceed to the next check directly\r\n                if (!Schema.instance.getVersion().equals(Schema.emptyVersion))\r\n                {\r\n                    logger_.debug(\"got schema: {}\", Schema.instance.getVersion());\r\n                    break;\r\n                }\r\n                try\r\n                {\r\n                    Thread.sleep(1000);\r\n                }\r\n                catch (InterruptedException e)\r\n                {\r\n                    throw new AssertionError(e);\r\n                }\r\n            }\r\n            // if our schema hasn\'t matched yet, keep sleeping until it does\r\n            // (post CASSANDRA-1391 we don\'t expect this to be necessary very often, but it doesn\'t hurt to be careful)\r\n            while (!MigrationManager.isReadyForBootstrap())\r\n            {\r\n                setMode(Mode.JOINING, \"waiting for schema information to complete\", true);\r\n                try\r\n                {\r\n                    Thread.sleep(1000);\r\n                }\r\n                catch (InterruptedException e)\r\n                {\r\n                    throw new AssertionError(e);\r\n                }\r\n            }\r\n            setMode(Mode.JOINING, \"schema complete\", true);\r\n            setMode(Mode.JOINING, \"waiting for pending range calculation\", true);\r\n            PendingRangeCalculatorService.instance.blockUntilFinished();\r\n            setMode(Mode.JOINING, \"calculation complete, ready to bootstrap\", true);\r\n\r\n\r\n            if (logger_.isDebugEnabled())\r\n                logger_.debug(\"... got ring + schema info\");\r\n\r\n            if (DatabaseDescriptor.getReplaceToken() == null)\r\n            {\r\n                if (tokenMetadata_.isMember(FBUtilities.getBroadcastAddress()))\r\n                {\r\n                    String s = \"This node is already a member of the token ring; bootstrap aborted. (If replacing a dead node, remove the old one from the ring first.)\";\r\n                    throw new UnsupportedOperationException(s);\r\n                }\r\n                setMode(Mode.JOINING, \"getting bootstrap token\", true);\r\n                token = BootStrapper.getBootstrapToken(tokenMetadata_, LoadBroadcaster.instance.getLoadInfo());\r\n            }\r\n            else\r\n            {\r\n                try\r\n                {\r\n                    // Sleeping additionally to make sure that the server actually is not alive\r\n                    // and giving it more time to gossip if alive.\r\n                    Thread.sleep(LoadBroadcaster.BROADCAST_INTERVAL);\r\n                }\r\n                catch (InterruptedException e)\r\n                {\r\n                    throw new AssertionError(e);\r\n                }\r\n                token = StorageService.getPartitioner().getTokenFactory().fromString(DatabaseDescriptor.getReplaceToken());\r\n                // check for operator errors...\r\n                current = tokenMetadata_.getEndpoint(token);\r\n                if (null != current && Gossiper.instance.getEndpointStateForEndpoint(current).getUpdateTimestamp() > (System.currentTimeMillis() - delay))\r\n                    throw new UnsupportedOperationException(\"Cannnot replace a token for a Live node... \");\r\n                setMode(Mode.JOINING, \"Replacing a node with token: \" + token, true);\r\n            }\r\n\r\n            bootstrap(token);\r\n            assert !isBootstrapMode; // bootstrap will block until finished\r\n        }\r\n        else\r\n        {\r\n            token = SystemTable.getSavedToken();\r\n            if (token == null)\r\n            {\r\n                String initialToken = DatabaseDescriptor.getInitialToken();\r\n                if (initialToken == null)\r\n                {\r\n                    token = getPartitioner().getRandomToken();\r\n                    logger_.warn(\"Generated random token \" + token + \". Random tokens will result in an unbalanced ring; see http://wiki.apache.org/cassandra/Operations\");\r\n                }\r\n                else\r\n                {\r\n                    token = getPartitioner().getTokenFactory().fromString(initialToken);\r\n                    logger_.info(\"Saved token not found. Using \" + token + \" from configuration\");\r\n                }\r\n            }\r\n            else\r\n            {\r\n                logger_.info(\"Using saved token \" + token);\r\n            }\r\n        }\r\n\r\n        if (!isSurveyMode)\r\n        {\r\n            // start participating in the ring.\r\n            SystemTable.setBootstrapState(SystemTable.BootstrapState.COMPLETED);\r\n            setToken(token);\r\n            // remove the existing info about the replaced node.\r\n            if (current != null)\r\n                Gossiper.instance.replacedEndpoint(current);\r\n            logger_.info(\"Bootstrap/Replace/Move completed! Now serving reads.\");\r\n            assert tokenMetadata_.sortedTokens().size() > 0;\r\n        }\r\n        else\r\n        {\r\n            logger_.info(\"Bootstrap complete, but write survey mode is active, not becoming an active ring member. Use JMX (StorageService->joinRing()) to finalize ring joining.\");\r\n        }\r\n    }\r\n\r\n    public synchronized void joinRing() throws IOException, org.apache.cassandra.config.ConfigurationException\r\n    {\r\n        if (!joined)\r\n        {\r\n            logger_.info(\"Joining ring by operator request\");\r\n            joinTokenRing(0);\r\n        }\r\n        else if (isSurveyMode)\r\n        {\r\n            setToken(SystemTable.getSavedToken());\r\n            SystemTable.setBootstrapState(SystemTable.BootstrapState.COMPLETED);\r\n            isSurveyMode = false;\r\n            logger_.info(\"Leaving write survey mode and joining ring at operator request\");\r\n            assert tokenMetadata_.sortedTokens().size() > 0;\r\n        }\r\n    }\r\n\r\n    public boolean isJoined()\r\n    {\r\n        return joined;\r\n    }\r\n\r\n    public void rebuild(String sourceDc)\r\n    {\r\n        logger_.info(\"rebuild from dc: {}\", sourceDc == null ? \"(any dc)\" : sourceDc);\r\n\r\n        RangeStreamer streamer = new RangeStreamer(tokenMetadata_, FBUtilities.getBroadcastAddress(), OperationType.REBUILD);\r\n        streamer.addSourceFilter(new RangeStreamer.FailureDetectorSourceFilter(FailureDetector.instance));\r\n        if (sourceDc != null)\r\n            streamer.addSourceFilter(new RangeStreamer.SingleDatacenterFilter(DatabaseDescriptor.getEndpointSnitch(), sourceDc));\r\n\r\n        for (String table : Schema.instance.getNonSystemTables())\r\n            streamer.addRanges(table, getLocalRanges(table));\r\n\r\n        streamer.fetch();\r\n    }\r\n\r\n    public void setStreamThroughputMbPerSec(int value)\r\n    {\r\n        DatabaseDescriptor.setStreamThroughputOutboundMegabitsPerSec(value);\r\n        logger_.info(\"setstreamthroughput: throttle set to {}\", value);\r\n    }\r\n\r\n    public int getStreamThroughputMbPerSec()\r\n    {\r\n        return DatabaseDescriptor.getStreamThroughputOutboundMegabitsPerSec();\r\n    }\r\n\r\n    public int getCompactionThroughputMbPerSec()\r\n    {\r\n        return DatabaseDescriptor.getCompactionThroughputMbPerSec();\r\n    }\r\n\r\n    public void setCompactionThroughputMbPerSec(int value)\r\n    {\r\n        DatabaseDescriptor.setCompactionThroughputMbPerSec(value);\r\n    }\r\n\r\n    public boolean isIncrementalBackupsEnabled()\r\n    {\r\n        return DatabaseDescriptor.isIncrementalBackupsEnabled();\r\n    }\r\n\r\n    public void setIncrementalBackupsEnabled(boolean value)\r\n    {\r\n        DatabaseDescriptor.setIncrementalBackupsEnabled(value);\r\n    }\r\n\r\n    private void setMode(Mode m, boolean log)\r\n    {\r\n        setMode(m, null, log);\r\n    }\r\n\r\n    private void setMode(Mode m, String msg, boolean log)\r\n    {\r\n        operationMode = m;\r\n        String logMsg = msg == null ? m.toString() : String.format(\"%s: %s\", m, msg);\r\n        if (log)\r\n            logger_.info(logMsg);\r\n        else\r\n            logger_.debug(logMsg);\r\n    }\r\n\r\n    private void bootstrap(Token token) throws IOException\r\n    {\r\n        isBootstrapMode = true;\r\n        SystemTable.updateToken(token); // DON\'T use setToken, that makes us part of the ring locally which is incorrect until we are done bootstrapping\r\n        if (null == DatabaseDescriptor.getReplaceToken())\r\n        {\r\n            // if not an existing token then bootstrap\r\n            Gossiper.instance.addLocalApplicationState(ApplicationState.STATUS, valueFactory.bootstrapping(token));\r\n            setMode(Mode.JOINING, \"sleeping \" + RING_DELAY + \" ms for pending range setup\", true);\r\n            try\r\n            {\r\n                Thread.sleep(RING_DELAY);\r\n            }\r\n            catch (InterruptedException e)\r\n            {\r\n                throw new AssertionError(e);\r\n            }\r\n        }\r\n        else\r\n        {\r\n            // Dont set any state for the node which is bootstrapping the existing token...\r\n            tokenMetadata_.updateNormalToken(token, FBUtilities.getBroadcastAddress());\r\n        }\r\n        setMode(Mode.JOINING, \"Starting to bootstrap...\", true);\r\n        new BootStrapper(FBUtilities.getBroadcastAddress(), token, tokenMetadata_).bootstrap(); // handles token update\r\n    }\r\n\r\n    public boolean isBootstrapMode()\r\n    {\r\n        return isBootstrapMode;\r\n    }\r\n\r\n    public TokenMetadata getTokenMetadata()\r\n    {\r\n        return tokenMetadata_;\r\n    }\r\n\r\n    /**\r\n     * for a keyspace, return the ranges and corresponding listen addresses.\r\n     * @param keyspace\r\n     * @return\r\n     */\r\n    public Map<List<String>, List<String>> getRangeToEndpointMap(String keyspace)\r\n    {\r\n        /* All the ranges for the tokens */\r\n        Map<List<String>, List<String>> map = new HashMap<List<String>, List<String>>();\r\n        for (Map.Entry<Range<Token>,List<InetAddress>> entry : getRangeToAddressMap(keyspace).entrySet())\r\n        {\r\n            map.put(entry.getKey().asList(), stringify(entry.getValue()));\r\n        }\r\n        return map;\r\n    }\r\n\r\n    /**\r\n     * Return the rpc address associated with an endpoint as a string.\r\n     * @param endpoint The endpoint to get rpc address for\r\n     * @return\r\n     */\r\n    public String getRpcaddress(InetAddress endpoint)\r\n    {\r\n        if (endpoint.equals(FBUtilities.getBroadcastAddress()))\r\n            return DatabaseDescriptor.getRpcAddress().getHostAddress();\r\n        else if (Gossiper.instance.getEndpointStateForEndpoint(endpoint).getApplicationState(ApplicationState.RPC_ADDRESS) == null)\r\n            return endpoint.getHostAddress();\r\n        else\r\n            return Gossiper.instance.getEndpointStateForEndpoint(endpoint).getApplicationState(ApplicationState.RPC_ADDRESS).value;\r\n    }\r\n\r\n    /**\r\n     * for a keyspace, return the ranges and corresponding RPC addresses for a given keyspace.\r\n     * @param keyspace\r\n     * @return\r\n     */\r\n    public Map<List<String>, List<String>> getRangeToRpcaddressMap(String keyspace)\r\n    {\r\n        /* All the ranges for the tokens */\r\n        Map<List<String>, List<String>> map = new HashMap<List<String>, List<String>>();\r\n        for (Map.Entry<Range<Token>, List<InetAddress>> entry : getRangeToAddressMap(keyspace).entrySet())\r\n        {\r\n            List<String> rpcaddrs = new ArrayList<String>(entry.getValue().size());\r\n            for (InetAddress endpoint: entry.getValue())\r\n            {\r\n                rpcaddrs.add(getRpcaddress(endpoint));\r\n            }\r\n            map.put(entry.getKey().asList(), rpcaddrs);\r\n        }\r\n        return map;\r\n    }\r\n\r\n    public Map<List<String>, List<String>> getPendingRangeToEndpointMap(String keyspace)\r\n    {\r\n        // some people just want to get a visual representation of things. Allow null and set it to the first\r\n        // non-system table.\r\n        if (keyspace == null)\r\n            keyspace = Schema.instance.getNonSystemTables().get(0);\r\n\r\n        Map<List<String>, List<String>> map = new HashMap<List<String>, List<String>>();\r\n        for (Map.Entry<Range<Token>, Collection<InetAddress>> entry : tokenMetadata_.getPendingRanges(keyspace).entrySet())\r\n        {\r\n            List<InetAddress> l = new ArrayList<InetAddress>(entry.getValue());\r\n            map.put(entry.getKey().asList(), stringify(l));\r\n        }\r\n        return map;\r\n    }\r\n\r\n    public Map<Range<Token>, List<InetAddress>> getRangeToAddressMap(String keyspace)\r\n    {\r\n        // some people just want to get a visual representation of things. Allow null and set it to the first\r\n        // non-system table.\r\n        if (keyspace == null)\r\n            keyspace = Schema.instance.getNonSystemTables().get(0);\r\n\r\n        List<Range<Token>> ranges = getAllRanges(tokenMetadata_.sortedTokens());\r\n        return constructRangeToEndpointMap(keyspace, ranges);\r\n    }\r\n\r\n    /**\r\n     * The same as {@code describeRing(String)} but converts TokenRange to the String for JMX compatibility\r\n     *\r\n     * @param keyspace The keyspace to fetch information about\r\n     *\r\n     * @return a List of TokenRange(s) converted to String for the given keyspace\r\n     *\r\n     * @throws InvalidRequestException if there is no ring information available about keyspace\r\n     */\r\n    public List<String> describeRingJMX(String keyspace) throws InvalidRequestException\r\n    {\r\n        List<TokenRange> tokenRanges = describeRing(keyspace);\r\n        List<String> result = new ArrayList<String>(tokenRanges.size());\r\n\r\n        for (TokenRange tokenRange : tokenRanges)\r\n            result.add(tokenRange.toString());\r\n\r\n        return result;\r\n    }\r\n\r\n    /**\r\n     * The TokenRange for a given keyspace.\r\n     *\r\n     * @param keyspace The keyspace to fetch information about\r\n     *\r\n     * @return a List of TokenRange(s) for the given keyspace\r\n     *\r\n     * @throws InvalidRequestException if there is no ring information available about keyspace\r\n     */\r\n    public List<TokenRange> describeRing(String keyspace) throws InvalidRequestException\r\n    {\r\n        if (keyspace == null || !Schema.instance.getNonSystemTables().contains(keyspace))\r\n            throw new InvalidRequestException(\"There is no ring for the keyspace: \" + keyspace);\r\n\r\n        List<TokenRange> ranges = new ArrayList<TokenRange>();\r\n        Token.TokenFactory tf = getPartitioner().getTokenFactory();\r\n\r\n        for (Map.Entry<Range<Token>, List<InetAddress>> entry : getRangeToAddressMap(keyspace).entrySet())\r\n        {\r\n            Range range = entry.getKey();\r\n            List<InetAddress> addresses = entry.getValue();\r\n            List<String> endpoints = new ArrayList<String>(addresses.size());\r\n            List<String> rpc_endpoints = new ArrayList<String>(addresses.size());\r\n            List<EndpointDetails> epDetails = new ArrayList<EndpointDetails>(addresses.size());\r\n\r\n            for (InetAddress endpoint : addresses)\r\n            {\r\n                EndpointDetails details = new EndpointDetails();\r\n                details.host = endpoint.getHostAddress();\r\n                details.datacenter = DatabaseDescriptor.getEndpointSnitch().getDatacenter(endpoint);\r\n                details.rack = DatabaseDescriptor.getEndpointSnitch().getRack(endpoint);\r\n\r\n                endpoints.add(details.host);\r\n                rpc_endpoints.add(getRpcaddress(endpoint));\r\n\r\n                epDetails.add(details);\r\n            }\r\n\r\n            TokenRange tr = new TokenRange(tf.toString(range.left.getToken()), tf.toString(range.right.getToken()), endpoints)\r\n                                    .setEndpoint_details(epDetails)\r\n                                    .setRpc_endpoints(rpc_endpoints);\r\n\r\n            ranges.add(tr);\r\n        }\r\n\r\n        return ranges;\r\n    }\r\n\r\n    public Map<String, String> getTokenToEndpointMap()\r\n    {\r\n        Map<Token, InetAddress> mapInetAddress = tokenMetadata_.getNormalAndBootstrappingTokenToEndpointMap();\r\n        // in order to preserve tokens in ascending order, we use LinkedHashMap here\r\n        Map<String, String> mapString = new LinkedHashMap<String, String>(mapInetAddress.size());\r\n        List<Token> tokens = new ArrayList<Token>(mapInetAddress.keySet());\r\n        Collections.sort(tokens);\r\n        for (Token token : tokens)\r\n        {\r\n            mapString.put(token.toString(), mapInetAddress.get(token).getHostAddress());\r\n        }\r\n        return mapString;\r\n    }\r\n\r\n    /**\r\n     * Construct the range to endpoint mapping based on the true view\r\n     * of the world.\r\n     * @param ranges\r\n     * @return mapping of ranges to the replicas responsible for them.\r\n    */\r\n    private Map<Range<Token>, List<InetAddress>> constructRangeToEndpointMap(String keyspace, List<Range<Token>> ranges)\r\n    {\r\n        Map<Range<Token>, List<InetAddress>> rangeToEndpointMap = new HashMap<Range<Token>, List<InetAddress>>();\r\n        for (Range<Token> range : ranges)\r\n        {\r\n            rangeToEndpointMap.put(range, Table.open(keyspace).getReplicationStrategy().getNaturalEndpoints(range.right));\r\n        }\r\n        return rangeToEndpointMap;\r\n    }\r\n\r\n    private Map<InetAddress, Collection<Range<Token>>> constructEndpointToRangeMap(String keyspace)\r\n    {\r\n        Multimap<InetAddress, Range<Token>> endpointToRangeMap = Multimaps.newListMultimap(new HashMap<InetAddress, Collection<Range<Token>>>(), new Supplier<List<Range<Token>>>()\r\n        {\r\n            public List<Range<Token>> get()\r\n            {\r\n                return Lists.newArrayList();\r\n            }\r\n        });\r\n\r\n        List<Range<Token>> ranges = getAllRanges(tokenMetadata_.sortedTokens());\r\n        for (Range<Token> range : ranges)\r\n        {\r\n            for (InetAddress endpoint : Table.open(keyspace).getReplicationStrategy().getNaturalEndpoints(range.left))\r\n                endpointToRangeMap.put(endpoint, range);\r\n        }\r\n        return endpointToRangeMap.asMap();\r\n    }\r\n\r\n    /*\r\n     * Handle the reception of a new particular ApplicationState for a particular endpoint. Note that the value of the\r\n     * ApplicationState has not necessarily \"changed\" since the last known value, if we already received the same update\r\n     * from somewhere else.\r\n     *\r\n     * onChange only ever sees one ApplicationState piece change at a time (even if many ApplicationState updates were\r\n     * received at the same time), so we perform a kind of state machine here. We are concerned with two events: knowing\r\n     * the token associated with an endpoint, and knowing its operation mode. Nodes can start in either bootstrap or\r\n     * normal mode, and from bootstrap mode can change mode to normal. A node in bootstrap mode needs to have\r\n     * pendingranges set in TokenMetadata; a node in normal mode should instead be part of the token ring.\r\n     *\r\n     * Normal progression of ApplicationState.STATUS values for a node should be like this:\r\n     * STATUS_BOOTSTRAPPING,token\r\n     *   if bootstrapping. stays this way until all files are received.\r\n     * STATUS_NORMAL,token\r\n     *   ready to serve reads and writes.\r\n     * STATUS_LEAVING,token\r\n     *   get ready to leave the cluster as part of a decommission\r\n     * STATUS_LEFT,token\r\n     *   set after decommission is completed.\r\n     *\r\n     * Other STATUS values that may be seen (possibly anywhere in the normal progression):\r\n     * STATUS_MOVING,newtoken\r\n     *   set if node is currently moving to a new token in the ring\r\n     * REMOVING_TOKEN,deadtoken\r\n     *   set if the node is dead and is being removed by its REMOVAL_COORDINATOR\r\n     * REMOVED_TOKEN,deadtoken\r\n     *   set if the node is dead and has been removed by its REMOVAL_COORDINATOR\r\n     *\r\n     * Note: Any time a node state changes from STATUS_NORMAL, it will not be visible to new nodes. So it follows that\r\n     * you should never bootstrap a new node during a removetoken, decommission or move.\r\n     */\r\n    public void onChange(InetAddress endpoint, ApplicationState state, VersionedValue value)\r\n    {\r\n        switch (state)\r\n        {\r\n            case STATUS:\r\n                String apStateValue = value.value;\r\n                String[] pieces = apStateValue.split(VersionedValue.DELIMITER_STR, -1);\r\n                assert (pieces.length > 0);\r\n\r\n                String moveName = pieces[0];\r\n\r\n                if (moveName.equals(VersionedValue.STATUS_BOOTSTRAPPING))\r\n                    handleStateBootstrap(endpoint, pieces);\r\n                else if (moveName.equals(VersionedValue.STATUS_NORMAL))\r\n                    handleStateNormal(endpoint, pieces);\r\n                else if (moveName.equals(VersionedValue.REMOVING_TOKEN) || moveName.equals(VersionedValue.REMOVED_TOKEN))\r\n                    handleStateRemoving(endpoint, pieces);\r\n                else if (moveName.equals(VersionedValue.STATUS_LEAVING))\r\n                    handleStateLeaving(endpoint, pieces);\r\n                else if (moveName.equals(VersionedValue.STATUS_LEFT))\r\n                    handleStateLeft(endpoint, pieces);\r\n                else if (moveName.equals(VersionedValue.STATUS_MOVING))\r\n                    handleStateMoving(endpoint, pieces);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Handle node bootstrap\r\n     *\r\n     * @param endpoint bootstrapping node\r\n     * @param pieces STATE_BOOTSTRAPPING,bootstrap token as string\r\n     */\r\n    private void handleStateBootstrap(InetAddress endpoint, String[] pieces)\r\n    {\r\n        assert pieces.length >= 2;\r\n        Token token = getPartitioner().getTokenFactory().fromString(pieces[1]);\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Node \" + endpoint + \" state bootstrapping, token \" + token);\r\n\r\n        // if this node is present in token metadata, either we have missed intermediate states\r\n        // or the node had crashed. Print warning if needed, clear obsolete stuff and\r\n        // continue.\r\n        if (tokenMetadata_.isMember(endpoint))\r\n        {\r\n            // If isLeaving is false, we have missed both LEAVING and LEFT. However, if\r\n            // isLeaving is true, we have only missed LEFT. Waiting time between completing\r\n            // leave operation and rebootstrapping is relatively short, so the latter is quite\r\n            // common (not enough time for gossip to spread). Therefore we report only the\r\n            // former in the log.\r\n            if (!tokenMetadata_.isLeaving(endpoint))\r\n                logger_.info(\"Node \" + endpoint + \" state jump to bootstrap\");\r\n            tokenMetadata_.removeEndpoint(endpoint);\r\n        }\r\n\r\n        tokenMetadata_.addBootstrapToken(token, endpoint);\r\n        PendingRangeCalculatorService.instance.update();\r\n    }\r\n\r\n    /**\r\n     * Handle node move to normal state. That is, node is entering token ring and participating\r\n     * in reads.\r\n     *\r\n     * @param endpoint node\r\n     * @param pieces STATE_NORMAL,token\r\n     */\r\n    private void handleStateNormal(InetAddress endpoint, String[] pieces)\r\n    {\r\n        assert pieces.length >= 2;\r\n        Token token = getPartitioner().getTokenFactory().fromString(pieces[1]);\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Node \" + endpoint + \" state normal, token \" + token);\r\n\r\n        if (tokenMetadata_.isMember(endpoint))\r\n            logger_.info(\"Node \" + endpoint + \" state jump to normal\");\r\n\r\n        // we don\'t want to update if this node is responsible for the token and it has a later startup time than endpoint.\r\n        InetAddress currentOwner = tokenMetadata_.getEndpoint(token);\r\n        if (currentOwner == null)\r\n        {\r\n            logger_.debug(\"New node \" + endpoint + \" at token \" + token);\r\n            tokenMetadata_.updateNormalToken(token, endpoint);\r\n            if (!isClientMode)\r\n                SystemTable.updateToken(endpoint, token);\r\n        }\r\n        else if (endpoint.equals(currentOwner))\r\n        {\r\n            // set state back to normal, since the node may have tried to leave, but failed and is now back up\r\n            // no need to persist, token/ip did not change\r\n            tokenMetadata_.updateNormalToken(token, endpoint);\r\n        }\r\n        else if (Gossiper.instance.compareEndpointStartup(endpoint, currentOwner) > 0)\r\n        {\r\n            logger_.info(String.format(\"Nodes %s and %s have the same token %s.  %s is the new owner\",\r\n                                       endpoint, currentOwner, token, endpoint));\r\n            tokenMetadata_.updateNormalToken(token, endpoint);\r\n            Gossiper.instance.removeEndpoint(currentOwner);\r\n            if (!isClientMode)\r\n                SystemTable.updateToken(endpoint, token);\r\n        }\r\n        else\r\n        {\r\n            logger_.info(String.format(\"Nodes %s and %s have the same token %s.  Ignoring %s\",\r\n                                       endpoint, currentOwner, token, endpoint));\r\n        }\r\n\r\n        if (tokenMetadata_.isMoving(endpoint)) // if endpoint was moving to a new token\r\n            tokenMetadata_.removeFromMoving(endpoint);\r\n\r\n        PendingRangeCalculatorService.instance.update();\r\n    }\r\n\r\n    /**\r\n     * Handle node preparing to leave the ring\r\n     *\r\n     * @param endpoint node\r\n     * @param pieces STATE_LEAVING,token\r\n     */\r\n    private void handleStateLeaving(InetAddress endpoint, String[] pieces)\r\n    {\r\n        assert pieces.length >= 2;\r\n        String moveValue = pieces[1];\r\n        Token token = getPartitioner().getTokenFactory().fromString(moveValue);\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Node \" + endpoint + \" state leaving, token \" + token);\r\n\r\n        // If the node is previously unknown or tokens do not match, update tokenmetadata to\r\n        // have this node as \'normal\' (it must have been using this token before the\r\n        // leave). This way we\'ll get pending ranges right.\r\n        if (!tokenMetadata_.isMember(endpoint))\r\n        {\r\n            logger_.info(\"Node \" + endpoint + \" state jump to leaving\");\r\n            tokenMetadata_.updateNormalToken(token, endpoint);\r\n        }\r\n        else if (!tokenMetadata_.getToken(endpoint).equals(token))\r\n        {\r\n            logger_.warn(\"Node \" + endpoint + \" \'leaving\' token mismatch. Long network partition?\");\r\n            tokenMetadata_.updateNormalToken(token, endpoint);\r\n        }\r\n\r\n        // at this point the endpoint is certainly a member with this token, so let\'s proceed\r\n        // normally\r\n        tokenMetadata_.addLeavingEndpoint(endpoint);\r\n        PendingRangeCalculatorService.instance.update();\r\n    }\r\n\r\n    /**\r\n     * Handle node leaving the ring. This will happen when a node is decommissioned\r\n     *\r\n     * @param endpoint If reason for leaving is decommission, endpoint is the leaving node.\r\n     * @param pieces STATE_LEFT,token\r\n     */\r\n    private void handleStateLeft(InetAddress endpoint, String[] pieces)\r\n    {\r\n        assert pieces.length >= 2;\r\n        Token token = getPartitioner().getTokenFactory().fromString(pieces[1]);\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Node \" + endpoint + \" state left, token \" + token);\r\n\r\n        excise(token, endpoint, extractExpireTime(pieces));\r\n    }\r\n\r\n    /**\r\n     * Handle node moving inside the ring.\r\n     *\r\n     * @param endpoint moving endpoint address\r\n     * @param pieces STATE_MOVING, token\r\n     */\r\n    private void handleStateMoving(InetAddress endpoint, String[] pieces)\r\n    {\r\n        assert pieces.length >= 2;\r\n        Token token = getPartitioner().getTokenFactory().fromString(pieces[1]);\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Node \" + endpoint + \" state moving, new token \" + token);\r\n\r\n        tokenMetadata_.addMovingEndpoint(token, endpoint);\r\n\r\n        PendingRangeCalculatorService.instance.update();\r\n    }\r\n\r\n    /**\r\n     * Handle notification that a node being actively removed from the ring via \'removetoken\'\r\n     *\r\n     * @param endpoint node\r\n     * @param pieces either REMOVED_TOKEN (node is gone) or REMOVING_TOKEN (replicas need to be restored)\r\n     */\r\n    private void handleStateRemoving(InetAddress endpoint, String[] pieces)\r\n    {\r\n        assert (pieces.length > 0);\r\n\r\n        if (endpoint.equals(FBUtilities.getBroadcastAddress()))\r\n        {\r\n            logger_.info(\"Received removeToken gossip about myself. Is this node rejoining after an explicit removetoken?\");\r\n            try\r\n            {\r\n                drain();\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                throw new RuntimeException(e);\r\n            }\r\n            return;\r\n        }\r\n        if (tokenMetadata_.isMember(endpoint))\r\n        {\r\n            String state = pieces[0];\r\n            Token removeToken = tokenMetadata_.getToken(endpoint);\r\n\r\n            if (VersionedValue.REMOVED_TOKEN.equals(state))\r\n            {\r\n                excise(removeToken, endpoint, extractExpireTime(pieces));\r\n            }\r\n            else if (VersionedValue.REMOVING_TOKEN.equals(state))\r\n            {\r\n                if (logger_.isDebugEnabled())\r\n                    logger_.debug(\"Token \" + removeToken + \" removed manually (endpoint was \" + endpoint + \")\");\r\n\r\n                // Note that the endpoint is being removed\r\n                tokenMetadata_.addLeavingEndpoint(endpoint);\r\n                PendingRangeCalculatorService.instance.update();\r\n\r\n                // find the endpoint coordinating this removal that we need to notify when we\'re done\r\n                String[] coordinator = Gossiper.instance.getEndpointStateForEndpoint(endpoint).getApplicationState(ApplicationState.REMOVAL_COORDINATOR).value.split(VersionedValue.DELIMITER_STR, -1);\r\n                Token coordtoken = getPartitioner().getTokenFactory().fromString(coordinator[1]);\r\n                // grab any data we are now responsible for and notify responsible node\r\n                restoreReplicaCount(endpoint, tokenMetadata_.getEndpoint(coordtoken));\r\n            }\r\n        }\r\n        else // now that the gossiper has told us about this nonexistent member, notify the gossiper to remove it\r\n            Gossiper.instance.removeEndpoint(endpoint);\r\n    }\r\n\r\n    private void excise(Token token, InetAddress endpoint)\r\n    {\r\n        HintedHandOffManager.instance.deleteHintsForEndpoint(endpoint);\r\n        Gossiper.instance.removeEndpoint(endpoint);\r\n        tokenMetadata_.removeEndpoint(endpoint);\r\n        tokenMetadata_.removeBootstrapToken(token);\r\n        PendingRangeCalculatorService.instance.update();\r\n        if (!isClientMode)\r\n        {\r\n            logger_.info(\"Removing token \" + token + \" for \" + endpoint);\r\n            SystemTable.removeToken(token);\r\n        }\r\n    }\r\n\r\n    private void excise(Token token, InetAddress endpoint, long expireTime)\r\n    {\r\n        addExpireTimeIfFound(endpoint, expireTime);\r\n        excise(token, endpoint);\r\n    }\r\n\r\n    protected void addExpireTimeIfFound(InetAddress endpoint, long expireTime)\r\n    {\r\n        if (expireTime != 0L)\r\n        {\r\n            Gossiper.instance.addExpireTimeForEndpoint(endpoint, expireTime);\r\n        }\r\n    }\r\n\r\n    protected long extractExpireTime(String[] pieces)\r\n    {\r\n        long expireTime = 0L;\r\n        if (pieces.length >= 3)\r\n        {\r\n            expireTime = Long.parseLong(pieces[2]);\r\n        }\r\n        return expireTime;\r\n    }\r\n\r\n    /**\r\n     * Finds living endpoints responsible for the given ranges\r\n     *\r\n     * @param table the table ranges belong to\r\n     * @param ranges the ranges to find sources for\r\n     * @return multimap of addresses to ranges the address is responsible for\r\n     */\r\n    private Multimap<InetAddress, Range<Token>> getNewSourceRanges(String table, Set<Range<Token>> ranges)\r\n    {\r\n        InetAddress myAddress = FBUtilities.getBroadcastAddress();\r\n        Multimap<Range<Token>, InetAddress> rangeAddresses = Table.open(table).getReplicationStrategy().getRangeAddresses(tokenMetadata_);\r\n        Multimap<InetAddress, Range<Token>> sourceRanges = HashMultimap.create();\r\n        IFailureDetector failureDetector = FailureDetector.instance;\r\n\r\n        // find alive sources for our new ranges\r\n        for (Range<Token> range : ranges)\r\n        {\r\n            Collection<InetAddress> possibleRanges = rangeAddresses.get(range);\r\n            IEndpointSnitch snitch = DatabaseDescriptor.getEndpointSnitch();\r\n            List<InetAddress> sources = snitch.getSortedListByProximity(myAddress, possibleRanges);\r\n\r\n            assert (!sources.contains(myAddress));\r\n\r\n            for (InetAddress source : sources)\r\n            {\r\n                if (failureDetector.isAlive(source))\r\n                {\r\n                    sourceRanges.put(source, range);\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n        return sourceRanges;\r\n    }\r\n\r\n    /**\r\n     * Sends a notification to a node indicating we have finished replicating data.\r\n     *\r\n     * @param local the local address\r\n     * @param remote node to send notification to\r\n     */\r\n    private void sendReplicationNotification(InetAddress local, InetAddress remote)\r\n    {\r\n        // notify the remote token\r\n        Message msg = new Message(local, StorageService.Verb.REPLICATION_FINISHED, new byte[0], Gossiper.instance.getVersion(remote));\r\n        IFailureDetector failureDetector = FailureDetector.instance;\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Notifying \" + remote.toString() + \" of replication completion\\n\");\r\n        while (failureDetector.isAlive(remote))\r\n        {\r\n            IAsyncResult iar = MessagingService.instance().sendRR(msg, remote);\r\n            try\r\n            {\r\n                iar.get(DatabaseDescriptor.getRpcTimeout(), TimeUnit.MILLISECONDS);\r\n                return; // done\r\n            }\r\n            catch(TimeoutException e)\r\n            {\r\n                // try again\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Called when an endpoint is removed from the ring. This function checks\r\n     * whether this node becomes responsible for new ranges as a\r\n     * consequence and streams data if needed.\r\n     *\r\n     * This is rather ineffective, but it does not matter so much\r\n     * since this is called very seldom\r\n     *\r\n     * @param endpoint the node that left\r\n     */\r\n    private void restoreReplicaCount(InetAddress endpoint, final InetAddress notifyEndpoint)\r\n    {\r\n        final Multimap<InetAddress, String> fetchSources = HashMultimap.create();\r\n        Multimap<String, Map.Entry<InetAddress, Collection<Range<Token>>>> rangesToFetch = HashMultimap.create();\r\n\r\n        final InetAddress myAddress = FBUtilities.getBroadcastAddress();\r\n\r\n        for (String table : Schema.instance.getNonSystemTables())\r\n        {\r\n            Multimap<Range<Token>, InetAddress> changedRanges = getChangedRangesForLeaving(table, endpoint);\r\n            Set<Range<Token>> myNewRanges = new HashSet<Range<Token>>();\r\n            for (Map.Entry<Range<Token>, InetAddress> entry : changedRanges.entries())\r\n            {\r\n                if (entry.getValue().equals(myAddress))\r\n                    myNewRanges.add(entry.getKey());\r\n            }\r\n            Multimap<InetAddress, Range<Token>> sourceRanges = getNewSourceRanges(table, myNewRanges);\r\n            for (Map.Entry<InetAddress, Collection<Range<Token>>> entry : sourceRanges.asMap().entrySet())\r\n            {\r\n                fetchSources.put(entry.getKey(), table);\r\n                rangesToFetch.put(table, entry);\r\n            }\r\n        }\r\n\r\n        for (final String table : rangesToFetch.keySet())\r\n        {\r\n            for (Map.Entry<InetAddress, Collection<Range<Token>>> entry : rangesToFetch.get(table))\r\n            {\r\n                final InetAddress source = entry.getKey();\r\n                Collection<Range<Token>> ranges = entry.getValue();\r\n                final IStreamCallback callback = new IStreamCallback()\r\n                {\r\n                    public void onSuccess()\r\n                    {\r\n                        synchronized (fetchSources)\r\n                        {\r\n                            fetchSources.remove(source, table);\r\n                            if (fetchSources.isEmpty())\r\n                                sendReplicationNotification(myAddress, notifyEndpoint);\r\n                        }\r\n                    }\r\n\r\n                    public void onFailure()\r\n                    {\r\n                        logger_.warn(\"Streaming from \" + source + \" failed\");\r\n                        onSuccess(); // calling onSuccess to send notification\r\n                    }\r\n                };\r\n                if (logger_.isDebugEnabled())\r\n                    logger_.debug(\"Requesting from \" + source + \" ranges \" + StringUtils.join(ranges, \", \"));\r\n                StreamIn.requestRanges(source, table, ranges, callback, OperationType.RESTORE_REPLICA_COUNT);\r\n            }\r\n        }\r\n    }\r\n\r\n    // needs to be modified to accept either a table or ARS.\r\n    private Multimap<Range<Token>, InetAddress> getChangedRangesForLeaving(String table, InetAddress endpoint)\r\n    {\r\n        // First get all ranges the leaving endpoint is responsible for\r\n        Collection<Range<Token>> ranges = getRangesForEndpoint(table, endpoint);\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Node \" + endpoint + \" ranges [\" + StringUtils.join(ranges, \", \") + \"]\");\r\n\r\n        Map<Range<Token>, List<InetAddress>> currentReplicaEndpoints = new HashMap<Range<Token>, List<InetAddress>>();\r\n\r\n        // Find (for each range) all nodes that store replicas for these ranges as well\r\n        for (Range<Token> range : ranges)\r\n            currentReplicaEndpoints.put(range, Table.open(table).getReplicationStrategy().calculateNaturalEndpoints(range.right, tokenMetadata_));\r\n\r\n        TokenMetadata temp = tokenMetadata_.cloneAfterAllLeft();\r\n\r\n        // endpoint might or might not be \'leaving\'. If it was not leaving (that is, removetoken\r\n        // command was used), it is still present in temp and must be removed.\r\n        if (temp.isMember(endpoint))\r\n            temp.removeEndpoint(endpoint);\r\n\r\n        Multimap<Range<Token>, InetAddress> changedRanges = HashMultimap.create();\r\n\r\n        // Go through the ranges and for each range check who will be\r\n        // storing replicas for these ranges when the leaving endpoint\r\n        // is gone. Whoever is present in newReplicaEndpoints list, but\r\n        // not in the currentReplicaEndpoints list, will be needing the\r\n        // range.\r\n        for (Range<Token> range : ranges)\r\n        {\r\n            Collection<InetAddress> newReplicaEndpoints = Table.open(table).getReplicationStrategy().calculateNaturalEndpoints(range.right, temp);\r\n            newReplicaEndpoints.removeAll(currentReplicaEndpoints.get(range));\r\n            if (logger_.isDebugEnabled())\r\n                if (newReplicaEndpoints.isEmpty())\r\n                    logger_.debug(\"Range \" + range + \" already in all replicas\");\r\n                else\r\n                    logger_.debug(\"Range \" + range + \" will be responsibility of \" + StringUtils.join(newReplicaEndpoints, \", \"));\r\n            changedRanges.putAll(range, newReplicaEndpoints);\r\n        }\r\n\r\n        return changedRanges;\r\n    }\r\n\r\n    public void onJoin(InetAddress endpoint, EndpointState epState)\r\n    {\r\n        for (Map.Entry<ApplicationState, VersionedValue> entry : epState.getApplicationStateMap().entrySet())\r\n        {\r\n            onChange(endpoint, entry.getKey(), entry.getValue());\r\n        }\r\n    }\r\n\r\n    public void onAlive(InetAddress endpoint, EndpointState state)\r\n    {\r\n        if (!isClientMode && getTokenMetadata().isMember(endpoint))\r\n            HintedHandOffManager.instance.scheduleHintDelivery(endpoint);\r\n    }\r\n\r\n    public void onRemove(InetAddress endpoint)\r\n    {\r\n        tokenMetadata_.removeEndpoint(endpoint);\r\n        PendingRangeCalculatorService.instance.update();\r\n    }\r\n\r\n    public void onDead(InetAddress endpoint, EndpointState state)\r\n    {\r\n        MessagingService.instance().convict(endpoint);\r\n    }\r\n\r\n    public void onRestart(InetAddress endpoint, EndpointState state)\r\n    {\r\n        // If we have restarted before the node was even marked down, we need to reset the connection pool\r\n        if (state.isAlive())\r\n            onDead(endpoint, state);\r\n    }\r\n\r\n    /** raw load value */\r\n    public double getLoad()\r\n    {\r\n        double bytes = 0;\r\n        for (String tableName : Schema.instance.getTables())\r\n        {\r\n            Table table = Table.open(tableName);\r\n            for (ColumnFamilyStore cfs : table.getColumnFamilyStores())\r\n                bytes += cfs.getLiveDiskSpaceUsed();\r\n        }\r\n        return bytes;\r\n    }\r\n\r\n    public String getLoadString()\r\n    {\r\n        return FileUtils.stringifyFileSize(getLoad());\r\n    }\r\n\r\n    public Map<String, String> getLoadMap()\r\n    {\r\n        Map<String, String> map = new HashMap<String, String>();\r\n        for (Map.Entry<InetAddress,Double> entry : LoadBroadcaster.instance.getLoadInfo().entrySet())\r\n        {\r\n            map.put(entry.getKey().getHostAddress(), FileUtils.stringifyFileSize(entry.getValue()));\r\n        }\r\n        // gossiper doesn\'t see its own updates, so we need to special-case the local node\r\n        map.put(FBUtilities.getBroadcastAddress().getHostAddress(), getLoadString());\r\n        return map;\r\n    }\r\n\r\n    public final void deliverHints(String host) throws UnknownHostException\r\n    {\r\n        HintedHandOffManager.instance.scheduleHintDelivery(host);\r\n    }\r\n\r\n    public Token getLocalToken()\r\n    {\r\n        Token token = SystemTable.getSavedToken();\r\n        assert token != null; // should not be called before initServer sets this\r\n        return token;\r\n    }\r\n\r\n    /* These methods belong to the MBean interface */\r\n\r\n    public String getToken()\r\n    {\r\n        return getLocalToken().toString();\r\n    }\r\n\r\n    public String getReleaseVersion()\r\n    {\r\n        return FBUtilities.getReleaseVersionString();\r\n    }\r\n\r\n    public String getSchemaVersion()\r\n    {\r\n        return Schema.instance.getVersion().toString();\r\n    }\r\n\r\n    public List<String> getLeavingNodes()\r\n    {\r\n        return stringify(tokenMetadata_.getLeavingEndpoints());\r\n    }\r\n\r\n    public List<String> getMovingNodes()\r\n    {\r\n        List<String> endpoints = new ArrayList<String>();\r\n\r\n        for (Pair<Token, InetAddress> node : tokenMetadata_.getMovingEndpoints())\r\n        {\r\n            endpoints.add(node.right.getHostAddress());\r\n        }\r\n\r\n        return endpoints;\r\n    }\r\n\r\n    public List<String> getJoiningNodes()\r\n    {\r\n        return stringify(tokenMetadata_.getBootstrapTokens().values());\r\n    }\r\n\r\n    public List<String> getLiveNodes()\r\n    {\r\n        return stringify(Gossiper.instance.getLiveMembers());\r\n    }\r\n\r\n    public List<String> getUnreachableNodes()\r\n    {\r\n        return stringify(Gossiper.instance.getUnreachableMembers());\r\n    }\r\n\r\n    private static String getCanonicalPath(String filename)\r\n    {\r\n        try\r\n        {\r\n            return new File(filename).getCanonicalPath();\r\n        }\r\n        catch (IOException e)\r\n        {\r\n            throw new IOError(e);\r\n        }\r\n    }\r\n\r\n    public String[] getAllDataFileLocations()\r\n    {\r\n        String[] locations = DatabaseDescriptor.getAllDataFileLocations();\r\n        for (int i = 0; i < locations.length; i++)\r\n            locations[i] = getCanonicalPath(locations[i]);\r\n        return locations;\r\n    }\r\n\r\n    public String getCommitLogLocation()\r\n    {\r\n        return getCanonicalPath(DatabaseDescriptor.getCommitLogLocation());\r\n    }\r\n\r\n    public String getSavedCachesLocation()\r\n    {\r\n        return getCanonicalPath(DatabaseDescriptor.getSavedCachesLocation());\r\n    }\r\n\r\n    private List<String> stringify(Iterable<InetAddress> endpoints)\r\n    {\r\n        List<String> stringEndpoints = new ArrayList<String>();\r\n        for (InetAddress ep : endpoints)\r\n        {\r\n            stringEndpoints.add(ep.getHostAddress());\r\n        }\r\n        return stringEndpoints;\r\n    }\r\n\r\n    public int getCurrentGenerationNumber()\r\n    {\r\n        return Gossiper.instance.getCurrentGenerationNumber(FBUtilities.getBroadcastAddress());\r\n    }\r\n\r\n    public void forceTableCleanup(String tableName, String... columnFamilies) throws IOException, ExecutionException, InterruptedException\r\n    {\r\n        if (tableName.equals(Table.SYSTEM_TABLE))\r\n            throw new RuntimeException(\"Cleanup of the system table is neither necessary nor wise\");\r\n\r\n        NodeId.OneShotRenewer nodeIdRenewer = new NodeId.OneShotRenewer();\r\n        for (ColumnFamilyStore cfStore : getValidColumnFamilies(tableName, columnFamilies))\r\n        {\r\n            cfStore.forceCleanup(nodeIdRenewer);\r\n        }\r\n    }\r\n\r\n    public void scrub(String tableName, String... columnFamilies) throws IOException, ExecutionException, InterruptedException\r\n    {\r\n        for (ColumnFamilyStore cfStore : getValidColumnFamilies(tableName, columnFamilies))\r\n            cfStore.scrub();\r\n    }\r\n\r\n    public void upgradeSSTables(String tableName, String... columnFamilies) throws IOException, ExecutionException, InterruptedException\r\n    {\r\n        for (ColumnFamilyStore cfStore : getValidColumnFamilies(tableName, columnFamilies))\r\n            cfStore.sstablesRewrite();\r\n    }\r\n\r\n    public void forceTableCompaction(String tableName, String... columnFamilies) throws IOException, ExecutionException, InterruptedException\r\n    {\r\n        for (ColumnFamilyStore cfStore : getValidColumnFamilies(tableName, columnFamilies))\r\n        {\r\n            cfStore.forceMajorCompaction();\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Takes the snapshot for the given tables. A snapshot name must be specified.\r\n     *\r\n     * @param tag the tag given to the snapshot; may not be null or empty\r\n     * @param tableNames the name of the tables to snapshot; empty means \"all.\"\r\n     */\r\n    public void takeSnapshot(String tag, String... tableNames) throws IOException\r\n    {\r\n        if (tag == null || tag.equals(\"\"))\r\n            throw new IOException(\"You must supply a snapshot name.\");\r\n\r\n        Iterable<Table> tables;\r\n        if (tableNames.length == 0)\r\n        {\r\n            tables = Table.all();\r\n        }\r\n        else\r\n        {\r\n            ArrayList<Table> t = new ArrayList<Table>(tableNames.length);\r\n            for (String table : tableNames)\r\n                t.add(getValidTable(table));\r\n            tables = t;\r\n        }\r\n\r\n        // Do a check to see if this snapshot exists before we actually snapshot\r\n        for (Table table : tables)\r\n            if (table.snapshotExists(tag))\r\n                throw new IOException(\"Snapshot \" + tag + \" already exists.\");\r\n\r\n\r\n        for (Table table : tables)\r\n            table.snapshot(tag, null);\r\n    }\r\n\r\n    /**\r\n     * Takes the snapshot of a specific column family. A snapshot name must be specified.\r\n     *\r\n     * @param tableName the keyspace which holds the specified column family\r\n     * @param columnFamilyName the column family to snapshot\r\n     * @param tag the tag given to the snapshot; may not be null or empty\r\n     */\r\n    public void takeColumnFamilySnapshot(String tableName, String columnFamilyName, String tag) throws IOException\r\n    {\r\n        if (tableName == null)\r\n            throw new IOException(\"You must supply a table name\");\r\n\r\n        if (columnFamilyName == null)\r\n            throw new IOException(\"You mus supply a column family name\");\r\n\r\n        if (tag == null || tag.equals(\"\"))\r\n            throw new IOException(\"You must supply a snapshot name.\");\r\n\r\n        Table table = getValidTable(tableName);\r\n        if (table.snapshotExists(tag))\r\n            throw new IOException(\"Snapshot \" + tag + \" already exists.\");\r\n\r\n        table.snapshot(tag, columnFamilyName);\r\n    }\r\n\r\n    private Table getValidTable(String tableName) throws IOException\r\n    {\r\n        if (!Schema.instance.getTables().contains(tableName))\r\n        {\r\n            throw new IOException(\"Table \" + tableName + \" does not exist\");\r\n        }\r\n        return Table.open(tableName);\r\n    }\r\n\r\n    /**\r\n     * Remove the snapshot with the given name from the given tables.\r\n     * If no tag is specified we will remove all snapshots.\r\n     */\r\n    public void clearSnapshot(String tag, String... tableNames) throws IOException\r\n    {\r\n        if(tag == null)\r\n            tag = \"\";\r\n\r\n        Iterable<Table> tables;\r\n        if (tableNames.length == 0)\r\n        {\r\n            tables = Table.all();\r\n        }\r\n        else\r\n        {\r\n            ArrayList<Table> tempTables = new ArrayList<Table>(tableNames.length);\r\n            for(String table : tableNames)\r\n                tempTables.add(getValidTable(table));\r\n            tables = tempTables;\r\n        }\r\n\r\n        for (Table table : tables)\r\n            table.clearSnapshot(tag);\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Cleared out snapshot directories\");\r\n    }\r\n\r\n    public Iterable<ColumnFamilyStore> getValidColumnFamilies(String tableName, String... cfNames) throws IOException\r\n    {\r\n        Table table = getValidTable(tableName);\r\n\r\n        if (cfNames.length == 0)\r\n            // all stores are interesting\r\n            return table.getColumnFamilyStores();\r\n\r\n        // filter out interesting stores\r\n        Set<ColumnFamilyStore> valid = new HashSet<ColumnFamilyStore>();\r\n        for (String cfName : cfNames)\r\n        {\r\n            ColumnFamilyStore cfStore = table.getColumnFamilyStore(cfName);\r\n            if (cfStore == null)\r\n            {\r\n                // this means there was a cf passed in that is not recognized in the keyspace. report it and continue.\r\n                logger_.warn(String.format(\"Invalid column family specified: %s. Proceeding with others.\", cfName));\r\n                continue;\r\n            }\r\n            valid.add(cfStore);\r\n        }\r\n        return valid;\r\n    }\r\n\r\n    /**\r\n     * Flush all memtables for a table and column families.\r\n     * @param tableName\r\n     * @param columnFamilies\r\n     * @throws IOException\r\n     */\r\n    public void forceTableFlush(final String tableName, final String... columnFamilies)\r\n                throws IOException, ExecutionException, InterruptedException\r\n    {\r\n        for (ColumnFamilyStore cfStore : getValidColumnFamilies(tableName, columnFamilies))\r\n        {\r\n            logger_.debug(\"Forcing flush on keyspace \" + tableName + \", CF \" + cfStore.getColumnFamilyName());\r\n            cfStore.forceBlockingFlush();\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Sends JMX notification to subscribers.\r\n     *\r\n     * @param type Message type\r\n     * @param message Message itself\r\n     * @param userObject Arbitrary object to attach to notification\r\n     */\r\n    public void sendNotification(String type, String message, Object userObject)\r\n    {\r\n        Notification jmxNotification = new Notification(type, jmxObjectName, notificationSerialNumber.incrementAndGet(), message);\r\n        jmxNotification.setUserData(userObject);\r\n        sendNotification(jmxNotification);\r\n    }\r\n\r\n    public int forceRepairAsync(final String tableName, final boolean isSequential, final boolean primaryRange, final String... columnFamilies)\r\n    {\r\n        final Collection<Range<Token>> ranges = primaryRange ? Collections.singletonList(getLocalPrimaryRange()) : getLocalRanges(tableName);\r\n        return forceRepairAsync(tableName, isSequential, ranges, columnFamilies);\r\n    }\r\n\r\n    public int forceRepairAsync(final String tableName, final boolean isSequential, final Collection<Range<Token>> ranges, final String... columnFamilies)\r\n    {\r\n        if (Table.SYSTEM_TABLE.equals(tableName))\r\n            return 0;\r\n\r\n        final int cmd = nextRepairCommand.incrementAndGet();\r\n        if (ranges.size() > 0)\r\n        {\r\n            new Thread(new WrappedRunnable()\r\n            {\r\n                protected void runMayThrow() throws Exception\r\n                {\r\n                    String message = String.format(\"Starting repair command #%d, repairing %d ranges for keyspace %s\", cmd, ranges.size(), tableName);\r\n                    logger_.info(message);\r\n                    sendNotification(\"repair\", message, new int[]{cmd, AntiEntropyService.Status.STARTED.ordinal()});\r\n\r\n                    List<AntiEntropyService.RepairFuture> futures = new ArrayList<AntiEntropyService.RepairFuture>(ranges.size());\r\n                    for (Range<Token> range : ranges)\r\n                    {\r\n                        AntiEntropyService.RepairFuture future;\r\n                        try\r\n                        {\r\n                            future = forceTableRepair(range, tableName, isSequential, columnFamilies);\r\n                        }\r\n                        catch (IllegalArgumentException e)\r\n                        {\r\n                            message = String.format(\"Repair session failed with error: %s\", e);\r\n                            sendNotification(\"repair\", message, new int[]{cmd, AntiEntropyService.Status.SESSION_FAILED.ordinal()});\r\n                            continue;\r\n                        }\r\n                        if (future == null)\r\n                            continue;\r\n                        futures.add(future);\r\n                        // wait for a session to be done with its differencing before starting the next one\r\n                        try\r\n                        {\r\n                            future.session.differencingDone.await();\r\n                        }\r\n                        catch (InterruptedException e)\r\n                        {\r\n                            message = \"Interrupted while waiting for the differencing of repair session \" + future.session + \" to be done. Repair may be imprecise.\";\r\n                            logger_.error(message, e);\r\n                            sendNotification(\"repair\", message, new int[]{cmd, AntiEntropyService.Status.SESSION_FAILED.ordinal()});\r\n                        }\r\n                    }\r\n                    for (AntiEntropyService.RepairFuture future : futures)\r\n                    {\r\n                        try\r\n                        {\r\n                            future.get();\r\n                            message = String.format(\"Repair session %s for range %s finished\", future.session.getName(), future.session.getRange().toString());\r\n                            sendNotification(\"repair\", message, new int[]{cmd, AntiEntropyService.Status.SESSION_SUCCESS.ordinal()});\r\n                        }\r\n                        catch (ExecutionException e)\r\n                        {\r\n                            message = String.format(\"Repair session %s for range %s failed with error %s\", future.session.getName(), future.session.getRange().toString(), e.getCause().getMessage());\r\n                            sendNotification(\"repair\", message, new int[]{cmd, AntiEntropyService.Status.SESSION_FAILED.ordinal()});\r\n                        }\r\n                        catch (Exception e)\r\n                        {\r\n                            message = String.format(\"Repair session %s for range %s failed with error %s\", future.session.getName(), future.session.getRange().toString(), e.getMessage());\r\n                            sendNotification(\"repair\", message, new int[]{cmd, AntiEntropyService.Status.SESSION_FAILED.ordinal()});\r\n                        }\r\n                    }\r\n                    sendNotification(\"repair\", String.format(\"Repair command #%d finished\", cmd), new int[]{cmd, AntiEntropyService.Status.FINISHED.ordinal()});\r\n                }\r\n            }).start();\r\n        }\r\n        return cmd;\r\n    }\r\n\r\n    public int forceRepairRangeAsync(String beginToken, String endToken, final String tableName, boolean isSequential, final String... columnFamilies)\r\n    {\r\n        Token parsedBeginToken = getPartitioner().getTokenFactory().fromString(beginToken);\r\n        Token parsedEndToken = getPartitioner().getTokenFactory().fromString(endToken);\r\n\r\n        logger_.info(\"starting user-requested repair of range ({}, {}] for keyspace {} and column families {}\",\r\n                new Object[] {parsedBeginToken, parsedEndToken, tableName, columnFamilies});\r\n        return forceRepairAsync(tableName, isSequential, Collections.singleton(new Range<Token>(parsedBeginToken, parsedEndToken)), columnFamilies);\r\n    }\r\n\r\n\r\n    /**\r\n     * Trigger proactive repair for a table and column families.\r\n     * @param tableName\r\n     * @param columnFamilies\r\n     * @throws IOException\r\n     */\r\n    public void forceTableRepair(final String tableName, boolean isSequential, final String... columnFamilies) throws IOException\r\n    {\r\n        if (Table.SYSTEM_TABLE.equals(tableName))\r\n            return;\r\n\r\n        Collection<Range<Token>> ranges = getLocalRanges(tableName);\r\n        int cmd = nextRepairCommand.incrementAndGet();\r\n        logger_.info(\"Starting repair command #{}, repairing {} ranges.\", cmd, ranges.size());\r\n\r\n        List<AntiEntropyService.RepairFuture> futures = new ArrayList<AntiEntropyService.RepairFuture>(ranges.size());\r\n        for (Range<Token> range : ranges)\r\n        {\r\n            AntiEntropyService.RepairFuture future = forceTableRepair(range, tableName, isSequential, columnFamilies);\r\n            if (future == null)\r\n                continue;\r\n            futures.add(future);\r\n            // wait for a session to be done with its differencing before starting the next one\r\n            try\r\n            {\r\n                future.session.differencingDone.await();\r\n            }\r\n            catch (InterruptedException e)\r\n            {\r\n                logger_.error(\"Interrupted while waiting for the differencing of repair session \" + future.session + \" to be done. Repair may be imprecise.\", e);\r\n            }\r\n        }\r\n\r\n        boolean failedSession = false;\r\n\r\n        // block until all repair sessions have completed\r\n        for (AntiEntropyService.RepairFuture future : futures)\r\n        {\r\n            try\r\n            {\r\n                future.get();\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                logger_.error(\"Repair session \" + future.session.getName() + \" failed.\", e);\r\n                failedSession = true;\r\n            }\r\n        }\r\n\r\n        if (failedSession)\r\n            throw new IOException(\"Repair command #\" + cmd + \": some repair session(s) failed (see log for details).\");\r\n        else\r\n            logger_.info(\"Repair command #{} completed successfully\", cmd);\r\n    }\r\n\r\n    public void forceTableRepairPrimaryRange(final String tableName, boolean isSequential, final String... columnFamilies) throws IOException\r\n    {\r\n        if (Table.SYSTEM_TABLE.equals(tableName))\r\n            return;\r\n\r\n        AntiEntropyService.RepairFuture future = forceTableRepair(getLocalPrimaryRange(), tableName, isSequential, columnFamilies);\r\n        if (future == null)\r\n            return;\r\n        try\r\n        {\r\n            future.get();\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            logger_.error(\"Repair session \" + future.session.getName() + \" failed.\", e);\r\n            throw new IOException(\"Some repair session(s) failed (see log for details).\");\r\n        }\r\n    }\r\n\r\n    public void forceTableRepairRange(String beginToken, String endToken, final String tableName, boolean isSequential, final String... columnFamilies) throws IOException\r\n    {\r\n        if (Table.SYSTEM_TABLE.equals(tableName))\r\n            return;\r\n\r\n        Token parsedBeginToken = getPartitioner().getTokenFactory().fromString(beginToken);\r\n        Token parsedEndToken = getPartitioner().getTokenFactory().fromString(endToken);\r\n\r\n        logger_.info(\"starting user-requested repair of range ({}, {}] for keyspace {} and column families {}\",\r\n                     new Object[] {parsedBeginToken, parsedEndToken, tableName, columnFamilies});\r\n        AntiEntropyService.RepairFuture future = forceTableRepair(new Range<Token>(parsedBeginToken, parsedEndToken), tableName, isSequential, columnFamilies);\r\n        if (future == null)\r\n            return;\r\n        try\r\n        {\r\n            future.get();\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            logger_.error(\"Repair session \" + future.session.getName() + \" failed.\", e);\r\n        }\r\n    }\r\n\r\n    public AntiEntropyService.RepairFuture forceTableRepair(final Range<Token> range, final String tableName, boolean isSequential, final String... columnFamilies) throws IOException\r\n    {\r\n        ArrayList<String> names = new ArrayList<String>();\r\n        for (ColumnFamilyStore cfStore : getValidColumnFamilies(tableName, columnFamilies))\r\n        {\r\n            names.add(cfStore.getColumnFamilyName());\r\n        }\r\n\r\n        if (names.isEmpty())\r\n        {\r\n            logger_.info(\"No column family to repair for keyspace \" + tableName);\r\n            return null;\r\n        }\r\n\r\n        return AntiEntropyService.instance.submitRepairSession(range, tableName, isSequential, names.toArray(new String[names.size()]));\r\n    }\r\n\r\n    public void forceTerminateAllRepairSessions() {\r\n        AntiEntropyService.instance.terminateSessions();\r\n    }\r\n\r\n    /* End of MBean interface methods */\r\n\r\n    /**\r\n     * This method returns the predecessor of the endpoint ep on the identifier\r\n     * space.\r\n     */\r\n    InetAddress getPredecessor(InetAddress ep)\r\n    {\r\n        Token token = tokenMetadata_.getToken(ep);\r\n        return tokenMetadata_.getEndpoint(tokenMetadata_.getPredecessor(token));\r\n    }\r\n\r\n    /*\r\n     * This method returns the successor of the endpoint ep on the identifier\r\n     * space.\r\n     */\r\n    public InetAddress getSuccessor(InetAddress ep)\r\n    {\r\n        Token token = tokenMetadata_.getToken(ep);\r\n        return tokenMetadata_.getEndpoint(tokenMetadata_.getSuccessor(token));\r\n    }\r\n\r\n    /**\r\n     * Get the primary range for the specified endpoint.\r\n     * @param ep endpoint we are interested in.\r\n     * @return range for the specified endpoint.\r\n     */\r\n    public Range<Token> getPrimaryRangeForEndpoint(InetAddress ep)\r\n    {\r\n        return tokenMetadata_.getPrimaryRangeFor(tokenMetadata_.getToken(ep));\r\n    }\r\n\r\n    /**\r\n     * Get all ranges an endpoint is responsible for (by table)\r\n     * @param ep endpoint we are interested in.\r\n     * @return ranges for the specified endpoint.\r\n     */\r\n    Collection<Range<Token>> getRangesForEndpoint(String table, InetAddress ep)\r\n    {\r\n        return Table.open(table).getReplicationStrategy().getAddressRanges().get(ep);\r\n    }\r\n\r\n    /**\r\n     * Get all ranges that span the ring given a set\r\n     * of tokens. All ranges are in sorted order of\r\n     * ranges.\r\n     * @return ranges in sorted order\r\n    */\r\n    public List<Range<Token>> getAllRanges(List<Token> sortedTokens)\r\n    {\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"computing ranges for \" + StringUtils.join(sortedTokens, \", \"));\r\n\r\n        if (sortedTokens.isEmpty())\r\n            return Collections.emptyList();\r\n        int size = sortedTokens.size();\r\n        List<Range<Token>> ranges = new ArrayList<Range<Token>>(size + 1);\r\n        for (int i = 1; i < size; ++i)\r\n        {\r\n            Range<Token> range = new Range<Token>(sortedTokens.get(i - 1), sortedTokens.get(i));\r\n            ranges.add(range);\r\n        }\r\n        Range<Token> range = new Range<Token>(sortedTokens.get(size - 1), sortedTokens.get(0));\r\n        ranges.add(range);\r\n\r\n        return ranges;\r\n    }\r\n\r\n    /**\r\n     * This method returns the N endpoints that are responsible for storing the\r\n     * specified key i.e for replication.\r\n     *\r\n     * @param table keyspace name also known as table\r\n     * @param cf Column family name\r\n     * @param key key for which we need to find the endpoint\r\n     * @return the endpoint responsible for this key\r\n     */\r\n    public List<InetAddress> getNaturalEndpoints(String table, String cf, String key)\r\n    {\r\n        CFMetaData cfMetaData = Schema.instance.getTableDefinition(table).cfMetaData().get(cf);\r\n        return getNaturalEndpoints(table, getPartitioner().getToken(cfMetaData.getKeyValidator().fromString(key)));\r\n    }\r\n\r\n    public List<InetAddress> getNaturalEndpoints(String table, ByteBuffer key)\r\n    {\r\n        return getNaturalEndpoints(table, getPartitioner().getToken(key));\r\n    }\r\n\r\n    /**\r\n     * This method returns the N endpoints that are responsible for storing the\r\n     * specified key i.e for replication.\r\n     *\r\n     * @param table keyspace name also known as table\r\n     * @param pos position for which we need to find the endpoint\r\n     * @return the endpoint responsible for this token\r\n     */\r\n    public List<InetAddress> getNaturalEndpoints(String table, RingPosition pos)\r\n    {\r\n        return Table.open(table).getReplicationStrategy().getNaturalEndpoints(pos);\r\n    }\r\n\r\n    /**\r\n     * This method attempts to return N endpoints that are responsible for storing the\r\n     * specified key i.e for replication.\r\n     *\r\n     * @param table keyspace name also known as table\r\n     * @param key key for which we need to find the endpoint\r\n     * @return the endpoint responsible for this key\r\n     */\r\n    public List<InetAddress> getLiveNaturalEndpoints(String table, ByteBuffer key)\r\n    {\r\n        return getLiveNaturalEndpoints(table, getPartitioner().decorateKey(key));\r\n    }\r\n\r\n    public List<InetAddress> getLiveNaturalEndpoints(String table, RingPosition pos)\r\n    {\r\n        List<InetAddress> endpoints = Table.open(table).getReplicationStrategy().getNaturalEndpoints(pos);\r\n        List<InetAddress> liveEps = new ArrayList<InetAddress>(endpoints.size());\r\n\r\n        for (InetAddress endpoint : endpoints)\r\n        {\r\n            if (FailureDetector.instance.isAlive(endpoint))\r\n                liveEps.add(endpoint);\r\n        }\r\n\r\n        return liveEps;\r\n    }\r\n\r\n    public void setLog4jLevel(String classQualifier, String rawLevel)\r\n    {\r\n        Level level = Level.toLevel(rawLevel);\r\n        org.apache.log4j.Logger.getLogger(classQualifier).setLevel(level);\r\n        logger_.info(\"set log level to \" + level + \" for classes under \'\" + classQualifier + \"\' (if the level doesn\'t look like \'\" + rawLevel + \"\' then log4j couldn\'t parse \'\" + rawLevel + \"\')\");\r\n    }\r\n\r\n    /**\r\n     * @return list of Token ranges (_not_ keys!) together with estimated key count,\r\n     *      breaking up the data this node is responsible for into pieces of roughly keysPerSplit\r\n     */\r\n    public List<Pair<Range<Token>, Long>> getSplits(String table, String cfName, Range<Token> range, int keysPerSplit)\r\n    {\r\n        Table t = Table.open(table);\r\n        ColumnFamilyStore cfs = t.getColumnFamilyStore(cfName);\r\n        List<DecoratedKey> keys = keySamples(Collections.singleton(cfs), range);\r\n\r\n        final long totalRowCountEstimate = (keys.size() + 1) * DatabaseDescriptor.getIndexInterval();\r\n\r\n        // splitCount should be much smaller than number of key samples, to avoid huge sampling error\r\n        final int minSamplesPerSplit = 4;\r\n        final int maxSplitCount = keys.size() / minSamplesPerSplit + 1;\r\n        final int splitCount = Math.max(1, Math.min(maxSplitCount, (int)(totalRowCountEstimate / keysPerSplit)));\r\n\r\n        List<Token> tokens = keysToTokens(range, keys);\r\n        return getSplits(tokens, splitCount);\r\n    }\r\n\r\n    private List<Pair<Range<Token>, Long>> getSplits(List<Token> tokens, int splitCount)\r\n    {\r\n        final double step = (double) (tokens.size() - 1) / splitCount;\r\n        int prevIndex = 0;\r\n        Token prevToken = tokens.get(0);\r\n        List<Pair<Range<Token>, Long>> splits = Lists.newArrayListWithExpectedSize(splitCount);\r\n        for (int i = 1; i <= splitCount; i++)\r\n        {\r\n            int index = (int) Math.round(i * step);\r\n            Token token = tokens.get(index);\r\n            long rowCountEstimate = (index - prevIndex) * DatabaseDescriptor.getIndexInterval();\r\n            splits.add(Pair.create(new Range<Token>(prevToken, token), rowCountEstimate));\r\n            prevIndex = index;\r\n            prevToken = token;\r\n        }\r\n        return splits;\r\n    }\r\n\r\n    private List<Token> keysToTokens(Range<Token> range, List<DecoratedKey> keys)\r\n    {\r\n        List<Token> tokens = Lists.newArrayListWithExpectedSize(keys.size() + 2);\r\n        tokens.add(range.left);\r\n        for (DecoratedKey key : keys)\r\n            tokens.add(key.token);\r\n        tokens.add(range.right);\r\n        return tokens;\r\n    }\r\n\r\n    private List<DecoratedKey> keySamples(Iterable<ColumnFamilyStore> cfses, Range<Token> range)\r\n    {\r\n        List<DecoratedKey> keys = new ArrayList<DecoratedKey>();\r\n        for (ColumnFamilyStore cfs : cfses)\r\n            Iterables.addAll(keys, cfs.keySamples(range));\r\n        FBUtilities.sortSampledKeys(keys, range);\r\n        return keys;\r\n    }\r\n\r\n    /** return a token to which if a node bootstraps it will get about 1/2 of this node\'s range */\r\n    public Token getBootstrapToken()\r\n    {\r\n        Range<Token> range = getLocalPrimaryRange();\r\n\r\n        List<DecoratedKey> keys = keySamples(ColumnFamilyStore.allUserDefined(), range);\r\n\r\n        Token token;\r\n        if (keys.size() < 3)\r\n        {\r\n            token = getPartitioner().midpoint(range.left, range.right);\r\n            logger_.debug(\"Used midpoint to assign token \" + token);\r\n        }\r\n        else\r\n        {\r\n            token = keys.get(keys.size() / 2).token;\r\n            logger_.debug(\"Used key sample of size \" + keys.size() + \" to assign token \" + token);\r\n        }\r\n        if (tokenMetadata_.getEndpoint(token) != null && tokenMetadata_.isMember(tokenMetadata_.getEndpoint(token)))\r\n            throw new RuntimeException(\"Chose token \" + token + \" which is already in use by \" + tokenMetadata_.getEndpoint(token) + \" -- specify one manually with initial_token\");\r\n        // Hack to prevent giving nodes tokens with DELIMITER_STR in them (which is fine in a row key/token)\r\n        if (token instanceof StringToken)\r\n        {\r\n            token = new StringToken(((String)token.token).replaceAll(VersionedValue.DELIMITER_STR, \"\"));\r\n            if (tokenMetadata_.getNormalAndBootstrappingTokenToEndpointMap().containsKey(token))\r\n                throw new RuntimeException(\"Unable to compute unique token for new node -- specify one manually with initial_token\");\r\n        }\r\n        return token;\r\n    }\r\n\r\n    /**\r\n     * Broadcast leaving status and update local tokenMetadata_ accordingly\r\n     */\r\n    private void startLeaving()\r\n    {\r\n        Gossiper.instance.addLocalApplicationState(ApplicationState.STATUS, valueFactory.leaving(getLocalToken()));\r\n        tokenMetadata_.addLeavingEndpoint(FBUtilities.getBroadcastAddress());\r\n        PendingRangeCalculatorService.instance.update();\r\n    }\r\n\r\n    public void decommission() throws InterruptedException\r\n    {\r\n        if (!tokenMetadata_.isMember(FBUtilities.getBroadcastAddress()))\r\n            throw new UnsupportedOperationException(\"local node is not a member of the token ring yet\");\r\n        if (tokenMetadata_.cloneAfterAllLeft().sortedTokens().size() < 2)\r\n            throw new UnsupportedOperationException(\"no other normal nodes in the ring; decommission would be pointless\");\r\n        PendingRangeCalculatorService.instance.blockUntilFinished();\r\n        for (String table : Schema.instance.getNonSystemTables())\r\n        {\r\n            if (tokenMetadata_.getPendingRanges(table, FBUtilities.getBroadcastAddress()).size() > 0)\r\n                throw new UnsupportedOperationException(\"data is currently moving to this node; unable to leave the ring\");\r\n        }\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"DECOMMISSIONING\");\r\n        startLeaving();\r\n        setMode(Mode.LEAVING, \"sleeping \" + RING_DELAY + \" ms for pending range setup\", true);\r\n        Thread.sleep(RING_DELAY);\r\n\r\n        Runnable finishLeaving = new Runnable()\r\n        {\r\n            public void run()\r\n            {\r\n                stopRPCServer();\r\n                Gossiper.instance.stop();\r\n                MessagingService.instance().shutdown();\r\n                StageManager.shutdownNow();\r\n                setMode(Mode.DECOMMISSIONED, true);\r\n                // let op be responsible for killing the process\r\n            }\r\n        };\r\n        unbootstrap(finishLeaving);\r\n    }\r\n\r\n    private void leaveRing()\r\n    {\r\n        SystemTable.setBootstrapState(SystemTable.BootstrapState.NEEDS_BOOTSTRAP);\r\n        tokenMetadata_.removeEndpoint(FBUtilities.getBroadcastAddress());\r\n        PendingRangeCalculatorService.instance.update();\r\n\r\n        Gossiper.instance.addLocalApplicationState(ApplicationState.STATUS, valueFactory.left(getLocalToken(),Gossiper.computeExpireTime()));\r\n        int delay = Math.max(RING_DELAY, Gossiper.intervalInMillis * 2);\r\n        logger_.info(\"Announcing that I have left the ring for \" + delay + \"ms\");\r\n        try\r\n        {\r\n            Thread.sleep(delay);\r\n        }\r\n        catch (InterruptedException e)\r\n        {\r\n            throw new AssertionError(e);\r\n        }\r\n    }\r\n\r\n    private void unbootstrap(final Runnable onFinish)\r\n    {\r\n        Map<String, Multimap<Range<Token>, InetAddress>> rangesToStream = new HashMap<String, Multimap<Range<Token>, InetAddress>>();\r\n\r\n        for (final String table : Schema.instance.getNonSystemTables())\r\n        {\r\n            Multimap<Range<Token>, InetAddress> rangesMM = getChangedRangesForLeaving(table, FBUtilities.getBroadcastAddress());\r\n\r\n            if (logger_.isDebugEnabled())\r\n                logger_.debug(\"Ranges needing transfer are [\" + StringUtils.join(rangesMM.keySet(), \",\") + \"]\");\r\n\r\n            rangesToStream.put(table, rangesMM);\r\n        }\r\n\r\n        setMode(Mode.LEAVING, \"streaming data to other nodes\", true);\r\n\r\n        CountDownLatch latch = streamRanges(rangesToStream);\r\n\r\n        // wait for the transfer runnables to signal the latch.\r\n        logger_.debug(\"waiting for stream aks.\");\r\n        try\r\n        {\r\n            latch.await();\r\n        }\r\n        catch (InterruptedException e)\r\n        {\r\n            throw new RuntimeException(e);\r\n        }\r\n        logger_.debug(\"stream acks all received.\");\r\n        leaveRing();\r\n        onFinish.run();\r\n    }\r\n\r\n    public void move(String newToken) throws IOException, InterruptedException, ConfigurationException\r\n    {\r\n        getPartitioner().getTokenFactory().validate(newToken);\r\n        move(getPartitioner().getTokenFactory().fromString(newToken));\r\n    }\r\n\r\n    /**\r\n     * move the node to new token or find a new token to boot to according to load\r\n     *\r\n     * @param newToken new token to boot to, or if null, find balanced token to boot to\r\n     *\r\n     * @throws IOException on any I/O operation error\r\n     */\r\n    private void move(Token newToken) throws IOException\r\n    {\r\n        if (newToken == null)\r\n            throw new IOException(\"Can\'t move to the undefined (null) token.\");\r\n\r\n        if (tokenMetadata_.sortedTokens().contains(newToken))\r\n            throw new IOException(\"target token \" + newToken + \" is already owned by another node.\");\r\n\r\n        // address of the current node\r\n        InetAddress localAddress = FBUtilities.getBroadcastAddress();\r\n        List<String> tablesToProcess = Schema.instance.getNonSystemTables();\r\n\r\n        PendingRangeCalculatorService.instance.blockUntilFinished();\r\n        // checking if data is moving to this node\r\n        for (String table : tablesToProcess)\r\n        {\r\n            if (tokenMetadata_.getPendingRanges(table, localAddress).size() > 0)\r\n                throw new UnsupportedOperationException(\"data is currently moving to this node; unable to leave the ring\");\r\n        }\r\n\r\n        Gossiper.instance.addLocalApplicationState(ApplicationState.STATUS, valueFactory.moving(newToken));\r\n        setMode(Mode.MOVING, String.format(\"Moving %s from %s to %s.\", localAddress, getLocalToken(), newToken), true);\r\n\r\n        IEndpointSnitch snitch = DatabaseDescriptor.getEndpointSnitch();\r\n\r\n        Map<String, Multimap<InetAddress, Range<Token>>> rangesToFetch = new HashMap<String, Multimap<InetAddress, Range<Token>>>();\r\n        Map<String, Multimap<Range<Token>, InetAddress>> rangesToStreamByTable = new HashMap<String, Multimap<Range<Token>, InetAddress>>();\r\n\r\n        TokenMetadata tokenMetaClone = tokenMetadata_.cloneAfterAllSettled();\r\n\r\n        // for each of the non system tables calculating new ranges\r\n        // which current node will handle after move to the new token\r\n        for (String table : tablesToProcess)\r\n        {\r\n            // replication strategy of the current keyspace (aka table)\r\n            AbstractReplicationStrategy strategy = Table.open(table).getReplicationStrategy();\r\n\r\n            // getting collection of the currently used ranges by this keyspace\r\n            Collection<Range<Token>> currentRanges = getRangesForEndpoint(table, localAddress);\r\n            // collection of ranges which this node will serve after move to the new token\r\n            Collection<Range<Token>> updatedRanges = strategy.getPendingAddressRanges(tokenMetadata_, newToken, localAddress);\r\n\r\n            // ring ranges and endpoints associated with them\r\n            // this used to determine what nodes should we ping about range data\r\n            Multimap<Range<Token>, InetAddress> rangeAddresses = strategy.getRangeAddresses(tokenMetadata_);\r\n\r\n            // calculated parts of the ranges to request/stream from/to nodes in the ring\r\n            Pair<Set<Range<Token>>, Set<Range<Token>>> rangesPerTable = calculateStreamAndFetchRanges(currentRanges, updatedRanges);\r\n\r\n            /**\r\n             * In this loop we are going through all ranges \"to fetch\" and determining\r\n             * nodes in the ring responsible for data we are interested in\r\n             */\r\n            Multimap<Range<Token>, InetAddress> rangesToFetchWithPreferredEndpoints = ArrayListMultimap.create();\r\n            for (Range<Token> toFetch : rangesPerTable.right)\r\n            {\r\n                for (Range<Token> range : rangeAddresses.keySet())\r\n                {\r\n                    if (range.contains(toFetch))\r\n                    {\r\n                        List<InetAddress> endpoints = snitch.getSortedListByProximity(localAddress, rangeAddresses.get(range));\r\n                        // storing range and preferred endpoint set\r\n                        rangesToFetchWithPreferredEndpoints.putAll(toFetch, endpoints);\r\n                    }\r\n                }\r\n            }\r\n\r\n            // calculating endpoints to stream current ranges to if needed\r\n            // in some situations node will handle current ranges as part of the new ranges\r\n            Multimap<Range<Token>, InetAddress> rangeWithEndpoints = HashMultimap.create();\r\n\r\n            for (Range<Token> toStream : rangesPerTable.left)\r\n            {\r\n                Set<InetAddress> currentEndpoints = ImmutableSet.copyOf(strategy.calculateNaturalEndpoints(toStream.right, tokenMetadata_));\r\n                Set<InetAddress> newEndpoints = ImmutableSet.copyOf(strategy.calculateNaturalEndpoints(toStream.right, tokenMetaClone));\r\n                rangeWithEndpoints.putAll(toStream, Sets.difference(newEndpoints, currentEndpoints));\r\n            }\r\n\r\n            // associating table with range-to-endpoints map\r\n            rangesToStreamByTable.put(table, rangeWithEndpoints);\r\n\r\n            Multimap<InetAddress, Range<Token>> workMap = RangeStreamer.getWorkMap(rangesToFetchWithPreferredEndpoints);\r\n            rangesToFetch.put(table, workMap);\r\n\r\n            if (logger_.isDebugEnabled())\r\n                logger_.debug(\"Table {}: work map {}.\", table, workMap);\r\n        }\r\n\r\n        if (!rangesToStreamByTable.isEmpty() || !rangesToFetch.isEmpty())\r\n        {\r\n            setMode(Mode.MOVING, String.format(\"Sleeping %s ms before start streaming/fetching ranges\", RING_DELAY), true);\r\n            try\r\n            {\r\n                Thread.sleep(RING_DELAY);\r\n            }\r\n            catch (InterruptedException e)\r\n            {\r\n                throw new RuntimeException(\"Sleep interrupted \" + e.getMessage());\r\n            }\r\n\r\n            setMode(Mode.MOVING, \"fetching new ranges and streaming old ranges\", true);\r\n            if (logger_.isDebugEnabled())\r\n                logger_.debug(\"[Move->STREAMING] Work Map: \" + rangesToStreamByTable);\r\n\r\n            CountDownLatch streamLatch = streamRanges(rangesToStreamByTable);\r\n\r\n            if (logger_.isDebugEnabled())\r\n                logger_.debug(\"[Move->FETCHING] Work Map: \" + rangesToFetch);\r\n\r\n            CountDownLatch fetchLatch = requestRanges(rangesToFetch);\r\n\r\n            try\r\n            {\r\n                streamLatch.await();\r\n                fetchLatch.await();\r\n            }\r\n            catch (InterruptedException e)\r\n            {\r\n                throw new RuntimeException(\"Interrupted latch while waiting for stream/fetch ranges to finish: \" + e.getMessage());\r\n            }\r\n        }\r\n\r\n        setToken(newToken); // setting new token as we have everything settled\r\n\r\n        if (logger_.isDebugEnabled())\r\n            logger_.debug(\"Successfully moved to new token {}\", getLocalToken());\r\n    }\r\n\r\n    /**\r\n     * Get the status of a token removal.\r\n     */\r\n    public String getRemovalStatus()\r\n    {\r\n        if (removingNode == null) {\r\n            return \"No token removals in process.\";\r\n        }\r\n        return String.format(\"Removing token (%s). Waiting for replication confirmation from [%s].\",\r\n                             tokenMetadata_.getToken(removingNode),\r\n                             StringUtils.join(replicatingNodes, \",\"));\r\n    }\r\n\r\n    /**\r\n     * Force a remove operation to complete. This may be necessary if a remove operation\r\n     * blocks forever due to node/stream failure. removeToken() must be called\r\n     * first, this is a last resort measure.  No further attempt will be made to restore replicas.\r\n     */\r\n    public void forceRemoveCompletion()\r\n    {\r\n        if (!replicatingNodes.isEmpty()  || !tokenMetadata_.getLeavingEndpoints().isEmpty())\r\n        {\r\n            logger_.warn(\"Removal not confirmed for for \" + StringUtils.join(this.replicatingNodes, \",\"));\r\n            for (InetAddress endpoint : tokenMetadata_.getLeavingEndpoints())\r\n            {\r\n                Token token = tokenMetadata_.getToken(endpoint);\r\n                Gossiper.instance.advertiseTokenRemoved(endpoint, token);\r\n                excise(token, endpoint);\r\n            }\r\n            replicatingNodes.clear();\r\n            removingNode = null;\r\n        }\r\n        else\r\n        {\r\n            throw new UnsupportedOperationException(\"No tokens to force removal on, call \'removetoken\' first\");\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Remove a node that has died, attempting to restore the replica count.\r\n     * If the node is alive, decommission should be attempted.  If decommission\r\n     * fails, then removeToken should be called.  If we fail while trying to\r\n     * restore the replica count, finally forceRemoveCompleteion should be\r\n     * called to forcibly remove the node without regard to replica count.\r\n     *\r\n     * @param tokenString token for the node\r\n     */\r\n    public void removeToken(String tokenString)\r\n    {\r\n        InetAddress myAddress = FBUtilities.getBroadcastAddress();\r\n        Token localToken = tokenMetadata_.getToken(myAddress);\r\n        Token token = getPartitioner().getTokenFactory().fromString(tokenString);\r\n        InetAddress endpoint = tokenMetadata_.getEndpoint(token);\r\n\r\n        if (endpoint == null)\r\n            throw new UnsupportedOperationException(\"Token not found.\");\r\n\r\n        if (endpoint.equals(myAddress))\r\n             throw new UnsupportedOperationException(\"Cannot remove node\'s own token\");\r\n\r\n        if (Gossiper.instance.getLiveMembers().contains(endpoint))\r\n            throw new UnsupportedOperationException(\"Node \" + endpoint + \" is alive and owns this token. Use decommission command to remove it from the ring\");\r\n\r\n        // A leaving endpoint that is dead is already being removed.\r\n        if (tokenMetadata_.isLeaving(endpoint))\r\n            logger_.warn(\"Node \" + endpoint + \" is already being removed, continuing removal anyway\");\r\n\r\n        if (!replicatingNodes.isEmpty())\r\n            throw new UnsupportedOperationException(\"This node is already processing a removal. Wait for it to complete, or use \'removetoken force\' if this has failed.\");\r\n\r\n        // Find the endpoints that are going to become responsible for data\r\n        for (String table : Schema.instance.getNonSystemTables())\r\n        {\r\n            // if the replication factor is 1 the data is lost so we shouldn\'t wait for confirmation\r\n            if (Table.open(table).getReplicationStrategy().getReplicationFactor() == 1)\r\n                continue;\r\n\r\n            // get all ranges that change ownership (that is, a node needs\r\n            // to take responsibility for new range)\r\n            Multimap<Range<Token>, InetAddress> changedRanges = getChangedRangesForLeaving(table, endpoint);\r\n            IFailureDetector failureDetector = FailureDetector.instance;\r\n            for (InetAddress ep : changedRanges.values())\r\n            {\r\n                if (failureDetector.isAlive(ep))\r\n                    replicatingNodes.add(ep);\r\n                else\r\n                    logger_.warn(\"Endpoint \" + ep + \" is down and will not receive data for re-replication of \" + endpoint);\r\n            }\r\n        }\r\n        removingNode = endpoint;\r\n\r\n        tokenMetadata_.addLeavingEndpoint(endpoint);\r\n        PendingRangeCalculatorService.instance.update();\r\n        // the gossiper will handle spoofing this node\'s state to REMOVING_TOKEN for us\r\n        // we add our own token so other nodes to let us know when they\'re done\r\n        Gossiper.instance.advertiseRemoving(endpoint, token, localToken);\r\n\r\n        // kick off streaming commands\r\n        restoreReplicaCount(endpoint, myAddress);\r\n\r\n        // wait for ReplicationFinishedVerbHandler to signal we\'re done\r\n        while (!replicatingNodes.isEmpty())\r\n        {\r\n            try\r\n            {\r\n                Thread.sleep(100);\r\n            }\r\n            catch (InterruptedException e)\r\n            {\r\n                throw new AssertionError(e);\r\n            }\r\n        }\r\n\r\n        excise(token, endpoint);\r\n\r\n        // gossiper will indicate the token has left\r\n        Gossiper.instance.advertiseTokenRemoved(endpoint, token);\r\n\r\n        replicatingNodes.clear();\r\n        removingNode = null;\r\n    }\r\n\r\n    public void confirmReplication(InetAddress node)\r\n    {\r\n        // replicatingNodes can be empty in the case where this node used to be a removal coordinator,\r\n        // but restarted before all \'replication finished\' messages arrived. In that case, we\'ll\r\n        // still go ahead and acknowledge it.\r\n        if (!replicatingNodes.isEmpty())\r\n        {\r\n            replicatingNodes.remove(node);\r\n        }\r\n        else\r\n        {\r\n            logger_.info(\"Received unexpected REPLICATION_FINISHED message from \" + node\r\n                         + \". Was this node recently a removal coordinator?\");\r\n        }\r\n    }\r\n\r\n    public boolean isClientMode()\r\n    {\r\n        return isClientMode;\r\n    }\r\n\r\n    public synchronized void requestGC()\r\n    {\r\n        if (hasUnreclaimedSpace())\r\n        {\r\n            logger_.info(\"requesting GC to free disk space\");\r\n            System.gc();\r\n            try\r\n            {\r\n                Thread.sleep(1000);\r\n            }\r\n            catch (InterruptedException e)\r\n            {\r\n                throw new AssertionError(e);\r\n            }\r\n        }\r\n    }\r\n\r\n    private boolean hasUnreclaimedSpace()\r\n    {\r\n        for (ColumnFamilyStore cfs : ColumnFamilyStore.all())\r\n        {\r\n            if (cfs.hasUnreclaimedSpace())\r\n                return true;\r\n        }\r\n        return false;\r\n    }\r\n\r\n    public String getOperationMode()\r\n    {\r\n        return operationMode.toString();\r\n    }\r\n\r\n    public String getDrainProgress()\r\n    {\r\n        return String.format(\"Drained %s/%s ColumnFamilies\", remainingCFs, totalCFs);\r\n    }\r\n\r\n    /**\r\n     * Shuts node off to writes, empties memtables and the commit log.\r\n     * There are two differences between drain and the normal shutdown hook:\r\n     * - Drain waits for in-progress streaming to complete\r\n     * - Drain flushes *all* columnfamilies (shutdown hook only flushes non-durable CFs)\r\n     */\r\n    public synchronized void drain() throws IOException, InterruptedException, ExecutionException\r\n    {\r\n        ExecutorService mutationStage = StageManager.getStage(Stage.MUTATION);\r\n        if (mutationStage.isTerminated())\r\n        {\r\n            logger_.warn(\"Cannot drain node (did it already happen?)\");\r\n            return;\r\n        }\r\n        setMode(Mode.DRAINING, \"starting drain process\", true);\r\n        stopRPCServer();\r\n        optionalTasks.shutdown();\r\n        Gossiper.instance.stop();\r\n\r\n        setMode(Mode.DRAINING, \"shutting down MessageService\", false);\r\n        MessagingService.instance().shutdown();\r\n        setMode(Mode.DRAINING, \"waiting for streaming\", false);\r\n        MessagingService.instance().waitForStreaming();\r\n\r\n        setMode(Mode.DRAINING, \"clearing mutation stage\", false);\r\n        mutationStage.shutdown();\r\n        mutationStage.awaitTermination(3600, TimeUnit.SECONDS);\r\n\r\n        StorageProxy.instance.verifyNoHintsInProgress();\r\n\r\n        setMode(Mode.DRAINING, \"flushing column families\", false);\r\n        List<ColumnFamilyStore> cfses = new ArrayList<ColumnFamilyStore>();\r\n        for (String tableName : Schema.instance.getNonSystemTables())\r\n        {\r\n            Table table = Table.open(tableName);\r\n            cfses.addAll(table.getColumnFamilyStores());\r\n        }\r\n        totalCFs = remainingCFs = cfses.size();\r\n        for (ColumnFamilyStore cfs : cfses)\r\n        {\r\n            cfs.forceBlockingFlush();\r\n            remainingCFs--;\r\n        }\r\n\r\n        ColumnFamilyStore.postFlushExecutor.shutdown();\r\n        ColumnFamilyStore.postFlushExecutor.awaitTermination(60, TimeUnit.SECONDS);\r\n\r\n        CommitLog.instance.shutdownBlocking();\r\n\r\n        // wait for miscellaneous tasks like sstable and commitlog segment deletion\r\n        tasks.shutdown();\r\n        if (!tasks.awaitTermination(1, TimeUnit.MINUTES))\r\n            logger_.warn(\"Miscellaneous task executor still busy after one minute; proceeding with shutdown\");\r\n\r\n        setMode(Mode.DRAINED, true);\r\n    }\r\n\r\n    // Never ever do this at home. Used by tests.\r\n    IPartitioner setPartitionerUnsafe(IPartitioner newPartitioner)\r\n    {\r\n        IPartitioner oldPartitioner = DatabaseDescriptor.getPartitioner();\r\n        DatabaseDescriptor.setPartitioner(newPartitioner);\r\n        valueFactory = new VersionedValue.VersionedValueFactory(getPartitioner());\r\n        return oldPartitioner;\r\n    }\r\n\r\n    TokenMetadata setTokenMetadataUnsafe(TokenMetadata tmd)\r\n    {\r\n        TokenMetadata old = tokenMetadata_;\r\n        tokenMetadata_ = tmd;\r\n        return old;\r\n    }\r\n\r\n    public void truncate(String keyspace, String columnFamily) throws UnavailableException, TimeoutException, IOException\r\n    {\r\n        StorageProxy.truncateBlocking(keyspace, columnFamily);\r\n    }\r\n\r\n    public Map<String, Float> getOwnership()\r\n    {\r\n        List<Token> sortedTokens = new ArrayList<Token>(tokenMetadata_.getTokenToEndpointMapForReading().keySet());\r\n        Collections.sort(sortedTokens);\r\n        Map<Token, Float> token_map = getPartitioner().describeOwnership(sortedTokens);\r\n        Map<String, Float> string_map = new HashMap<String, Float>();\r\n        for(Map.Entry<Token, Float> entry : token_map.entrySet())\r\n        {\r\n            string_map.put(entry.getKey().toString(), entry.getValue());\r\n        }\r\n        return string_map;\r\n    }\r\n\r\n    public Map<String, Float> effectiveOwnership(String keyspace) throws ConfigurationException\r\n    {\r\n        Map<String, Float> effective = Maps.newHashMap();\r\n        if (Schema.instance.getNonSystemTables().size() <= 0)\r\n            throw new ConfigurationException(\"Couldn\'t find any Non System Keyspaces to infer replication topology\");\r\n        if (keyspace == null && !hasSameReplication(Schema.instance.getNonSystemTables()))\r\n            throw new ConfigurationException(\"Non System keyspaces doesnt have the same topology\");\r\n\r\n        if (keyspace == null)\r\n            keyspace = Schema.instance.getNonSystemTables().get(0);\r\n\r\n        List<Token> sortedTokens = new ArrayList<Token>(tokenMetadata_.getTokenToEndpointMapForReading().keySet());\r\n        Collections.sort(sortedTokens);\r\n        Map<Token, Float> ownership = getPartitioner().describeOwnership(sortedTokens);\r\n\r\n        for (Entry<InetAddress, Collection<Range<Token>>> ranges : constructEndpointToRangeMap(keyspace).entrySet())\r\n        {\r\n            Token token = tokenMetadata_.getToken(ranges.getKey());\r\n            for (Range<Token> range: ranges.getValue())\r\n            {\r\n                float value = effective.get(token.toString()) == null ? 0.0F : effective.get(token.toString());\r\n                effective.put(token.toString(), value + ownership.get(range.left));\r\n            }\r\n        }\r\n        return effective;\r\n    }\r\n\r\n    private boolean hasSameReplication(List<String> list)\r\n    {\r\n        if (list.isEmpty())\r\n            return false;\r\n\r\n        for (int i = 0; i < list.size() -1; i++)\r\n        {\r\n            KSMetaData ksm1 = Schema.instance.getKSMetaData(list.get(i));\r\n            KSMetaData ksm2 = Schema.instance.getKSMetaData(list.get(i + 1));\r\n            if (!ksm1.strategyClass.equals(ksm2.strategyClass) ||\r\n                    !Iterators.elementsEqual(ksm1.strategyOptions.entrySet().iterator(),\r\n                                             ksm2.strategyOptions.entrySet().iterator()))\r\n                return false;\r\n        }\r\n        return true;\r\n    }\r\n\r\n    public List<String> getKeyspaces()\r\n    {\r\n        List<String> tableslist = new ArrayList<String>(Schema.instance.getTables());\r\n        return Collections.unmodifiableList(tableslist);\r\n    }\r\n\r\n    public void updateSnitch(String epSnitchClassName, Boolean dynamic, Integer dynamicUpdateInterval, Integer dynamicResetInterval, Double dynamicBadnessThreshold) throws ConfigurationException\r\n    {\r\n        IEndpointSnitch oldSnitch = DatabaseDescriptor.getEndpointSnitch();\r\n\r\n        // new snitch registers mbean during construction\r\n        IEndpointSnitch newSnitch = FBUtilities.construct(epSnitchClassName, \"snitch\");\r\n        if (dynamic)\r\n        {\r\n            DatabaseDescriptor.setDynamicUpdateInterval(dynamicUpdateInterval);\r\n            DatabaseDescriptor.setDynamicResetInterval(dynamicResetInterval);\r\n            DatabaseDescriptor.setDynamicBadnessThreshold(dynamicBadnessThreshold);\r\n            newSnitch = new DynamicEndpointSnitch(newSnitch);\r\n        }\r\n\r\n        // point snitch references to the new instance\r\n        DatabaseDescriptor.setEndpointSnitch(newSnitch);\r\n        for (String ks : Schema.instance.getTables())\r\n        {\r\n            Table.open(ks).getReplicationStrategy().snitch = newSnitch;\r\n        }\r\n\r\n        if (oldSnitch instanceof DynamicEndpointSnitch)\r\n            ((DynamicEndpointSnitch)oldSnitch).unregisterMBean();\r\n    }\r\n\r\n    /**\r\n     * Flushes the two largest memtables by ops and by throughput\r\n     */\r\n    public void flushLargestMemtables()\r\n    {\r\n        ColumnFamilyStore largest = null;\r\n        for (ColumnFamilyStore cfs : ColumnFamilyStore.all())\r\n        {\r\n            long total = cfs.getTotalMemtableLiveSize();\r\n\r\n            if (total > 0 && (largest == null || total > largest.getTotalMemtableLiveSize()))\r\n            {\r\n                logger_.debug(total + \" estimated memtable size for \" + cfs);\r\n                largest = cfs;\r\n            }\r\n        }\r\n        if (largest == null)\r\n        {\r\n            logger_.info(\"Unable to reduce heap usage since there are no dirty column families\");\r\n            return;\r\n        }\r\n\r\n        logger_.warn(\"Flushing \" + largest + \" to relieve memory pressure\");\r\n        largest.forceFlush();\r\n    }\r\n\r\n    /**\r\n     * Seed data to the endpoints that will be responsible for it at the future\r\n     *\r\n     * @param rangesToStreamByTable tables and data ranges with endpoints included for each\r\n     * @return latch to count down\r\n     */\r\n    private CountDownLatch streamRanges(final Map<String, Multimap<Range<Token>, InetAddress>> rangesToStreamByTable)\r\n    {\r\n        final CountDownLatch latch = new CountDownLatch(rangesToStreamByTable.keySet().size());\r\n        for (Map.Entry<String, Multimap<Range<Token>, InetAddress>> entry : rangesToStreamByTable.entrySet())\r\n        {\r\n            Multimap<Range<Token>, InetAddress> rangesWithEndpoints = entry.getValue();\r\n\r\n            if (rangesWithEndpoints.isEmpty())\r\n            {\r\n                latch.countDown();\r\n                continue;\r\n            }\r\n\r\n            final String table = entry.getKey();\r\n\r\n            final Set<Map.Entry<Range<Token>, InetAddress>> pending = new HashSet<Map.Entry<Range<Token>, InetAddress>>(rangesWithEndpoints.entries());\r\n\r\n            for (final Map.Entry<Range<Token>, InetAddress> endPointEntry : rangesWithEndpoints.entries())\r\n            {\r\n                final Range<Token> range = endPointEntry.getKey();\r\n                final InetAddress newEndpoint = endPointEntry.getValue();\r\n\r\n                final IStreamCallback callback = new IStreamCallback()\r\n                {\r\n                    public void onSuccess()\r\n                    {\r\n                        synchronized (pending)\r\n                        {\r\n                            pending.remove(endPointEntry);\r\n\r\n                            if (pending.isEmpty())\r\n                                latch.countDown();\r\n                        }\r\n                    }\r\n\r\n                    public void onFailure()\r\n                    {\r\n                        logger_.warn(\"Streaming to \" + endPointEntry + \" failed\");\r\n                        onSuccess(); // calling onSuccess for latch countdown\r\n                    }\r\n                };\r\n\r\n                StageManager.getStage(Stage.STREAM).execute(new Runnable()\r\n                {\r\n                    public void run()\r\n                    {\r\n                        // TODO each call to transferRanges re-flushes, this is potentially a lot of waste\r\n                        StreamOut.transferRanges(newEndpoint, Table.open(table), Arrays.asList(range), callback, OperationType.UNBOOTSTRAP);\r\n                    }\r\n                });\r\n            }\r\n        }\r\n        return latch;\r\n    }\r\n\r\n    /**\r\n     * Used to request ranges from endpoints in the ring (will block until all data is fetched and ready)\r\n     * @param ranges ranges to fetch as map of the preferred address and range collection\r\n     * @return latch to count down\r\n     */\r\n    private CountDownLatch requestRanges(final Map<String, Multimap<InetAddress, Range<Token>>> ranges)\r\n    {\r\n        final CountDownLatch latch = new CountDownLatch(ranges.keySet().size());\r\n        for (Map.Entry<String, Multimap<InetAddress, Range<Token>>> entry : ranges.entrySet())\r\n        {\r\n            Multimap<InetAddress, Range<Token>> endpointWithRanges = entry.getValue();\r\n\r\n            if (endpointWithRanges.isEmpty())\r\n            {\r\n                latch.countDown();\r\n                continue;\r\n            }\r\n\r\n            final String table = entry.getKey();\r\n            final Set<InetAddress> pending = new HashSet<InetAddress>(endpointWithRanges.keySet());\r\n\r\n            // Send messages to respective folks to stream data over to me\r\n            for (final InetAddress source: endpointWithRanges.keySet())\r\n            {\r\n                Collection<Range<Token>> toFetch = endpointWithRanges.get(source);\r\n\r\n                final IStreamCallback callback = new IStreamCallback()\r\n                {\r\n                    public void onSuccess()\r\n                    {\r\n                        pending.remove(source);\r\n\r\n                        if (pending.isEmpty())\r\n                            latch.countDown();\r\n                    }\r\n\r\n                    public void onFailure()\r\n                    {\r\n                        logger_.warn(\"Streaming from \" + source + \" failed\");\r\n                        onSuccess(); // calling onSuccess for latch countdown\r\n                    }\r\n                };\r\n\r\n                if (logger_.isDebugEnabled())\r\n                    logger_.debug(\"Requesting from \" + source + \" ranges \" + StringUtils.join(toFetch, \", \"));\r\n\r\n                // sending actual request\r\n                StreamIn.requestRanges(source, table, toFetch, callback, OperationType.BOOTSTRAP);\r\n            }\r\n        }\r\n        return latch;\r\n    }\r\n\r\n    /**\r\n     * Calculate pair of ranges to stream/fetch for given two range collections\r\n     * (current ranges for table and ranges after move to new token)\r\n     *\r\n     * @param current collection of the ranges by current token\r\n     * @param updated collection of the ranges after token is changed\r\n     * @return pair of ranges to stream/fetch for given current and updated range collections\r\n     */\r\n    public Pair<Set<Range<Token>>, Set<Range<Token>>> calculateStreamAndFetchRanges(Collection<Range<Token>> current, Collection<Range<Token>> updated)\r\n    {\r\n        Set<Range<Token>> toStream = new HashSet<Range<Token>>();\r\n        Set<Range<Token>> toFetch  = new HashSet<Range<Token>>();\r\n\r\n\r\n        for (Range r1 : current)\r\n        {\r\n            boolean intersect = false;\r\n            for (Range r2 : updated)\r\n            {\r\n                if (r1.intersects(r2))\r\n                {\r\n                    // adding difference ranges to fetch from a ring\r\n                    toStream.addAll(r1.subtract(r2));\r\n                    intersect = true;\r\n                    break;\r\n                }\r\n            }\r\n            if (!intersect)\r\n            {\r\n                toStream.add(r1); // should seed whole old range\r\n            }\r\n        }\r\n\r\n        for (Range r2 : updated)\r\n        {\r\n            boolean intersect = false;\r\n            for (Range r1 : current)\r\n            {\r\n                if (r2.intersects(r1))\r\n                {\r\n                    // adding difference ranges to fetch from a ring\r\n                    toFetch.addAll(r2.subtract(r1));\r\n                    intersect = true;\r\n                    break;\r\n                }\r\n            }\r\n            if (!intersect)\r\n            {\r\n                toFetch.add(r2); // should fetch whole old range\r\n            }\r\n        }\r\n\r\n        return new Pair<Set<Range<Token>>, Set<Range<Token>>>(toStream, toFetch);\r\n    }\r\n\r\n    public void bulkLoad(String directory)\r\n    {\r\n        File dir = new File(directory);\r\n\r\n        if (!dir.exists() || !dir.isDirectory())\r\n            throw new IllegalArgumentException(\"Invalid directory \" + directory);\r\n\r\n        SSTableLoader.Client client = new SSTableLoader.Client()\r\n        {\r\n            @Override\r\n            public void init(String keyspace)\r\n            {\r\n                try\r\n                {\r\n                    setPartitioner(DatabaseDescriptor.getPartitioner());\r\n                    for (Map.Entry<Range<Token>, List<InetAddress>> entry : StorageService.instance.getRangeToAddressMap(keyspace).entrySet())\r\n                    {\r\n                        Range<Token> range = entry.getKey();\r\n                        for (InetAddress endpoint : entry.getValue())\r\n                            addRangeForEndpoint(range, endpoint);\r\n                    }\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    throw new RuntimeException(e);\r\n                }\r\n            }\r\n\r\n            @Override\r\n            public boolean validateColumnFamily(String keyspace, String cfName)\r\n            {\r\n                return Schema.instance.getCFMetaData(keyspace, cfName) != null;\r\n            }\r\n        };\r\n\r\n        SSTableLoader loader = new SSTableLoader(dir, client, new OutputHandler.LogOutput());\r\n        try\r\n        {\r\n            loader.stream().get();\r\n        }\r\n        catch (Exception e)\r\n        {\r\n            throw new RuntimeException(e);\r\n        }\r\n    }\r\n\r\n    public int getExceptionCount()\r\n    {\r\n        return AbstractCassandraDaemon.exceptions.get();\r\n    }\r\n\r\n    public void rescheduleFailedDeletions()\r\n    {\r\n        SSTableDeletingTask.rescheduleFailedTasks();\r\n    }\r\n\r\n    /**\r\n     * #{@inheritDoc}\r\n     */\r\n    public void loadNewSSTables(String ksName, String cfName)\r\n    {\r\n        ColumnFamilyStore.loadNewSSTables(ksName, cfName);\r\n    }\r\n\r\n    /**\r\n     * #{@inheritDoc}\r\n     */\r\n    public List<String> sampleKeyRange() // do not rename to getter - see CASSANDRA-4452 for details\r\n    {\r\n        List<DecoratedKey> keys = keySamples(ColumnFamilyStore.allUserDefined(), getLocalPrimaryRange());\r\n\r\n        List<String> sampledKeys = new ArrayList<String>(keys.size());\r\n        for (DecoratedKey key : keys)\r\n            sampledKeys.add(key.getToken().toString());\r\n        return sampledKeys;\r\n    }\r\n\r\n    public void rebuildSecondaryIndex(String ksName, String cfName, String... idxNames)\r\n    {\r\n        ColumnFamilyStore.rebuildSecondaryIndex(ksName, cfName, idxNames);\r\n    }\r\n\r\n    public void resetLocalSchema() throws IOException\r\n    {\r\n        MigrationManager.resetLocalSchema();\r\n    }\r\n}','cassandra','Public Class','org.apache.cassandra.service.StorageService',0,10,'gc'),(8,'dt7.png','private void genMapRedTasks(QB qb) throws SemanticException {\r\n    FetchWork fetch = null;\r\n    List<Task<? extends Serializable>> mvTask = new ArrayList<Task<? extends Serializable>>();\r\n    FetchTask fetchTask = null;\r\n\r\n    QBParseInfo qbParseInfo = qb.getParseInfo();\r\n\r\n    // Does this query need reduce job\r\n    if (qb.isSelectStarQuery() && qbParseInfo.getDestToClusterBy().isEmpty()\r\n        && qbParseInfo.getDestToDistributeBy().isEmpty()\r\n        && qbParseInfo.getDestToOrderBy().isEmpty()\r\n        && qbParseInfo.getDestToSortBy().isEmpty()) {\r\n      boolean noMapRed = false;\r\n\r\n      Iterator<Map.Entry<String, Table>> iter = qb.getMetaData()\r\n          .getAliasToTable().entrySet().iterator();\r\n      Table tab = (iter.next()).getValue();\r\n      if (!tab.isPartitioned()) {\r\n        if (qbParseInfo.getDestToWhereExpr().isEmpty()) {\r\n          fetch = new FetchWork(tab.getPath().toString(), Utilities\r\n              .getTableDesc(tab), qb.getParseInfo().getOuterQueryLimit());\r\n          noMapRed = true;\r\n          inputs.add(new ReadEntity(tab));\r\n        }\r\n      } else {\r\n\r\n        if (topOps.size() == 1) {\r\n          TableScanOperator ts = (TableScanOperator) topOps.values().toArray()[0];\r\n\r\n          // check if the pruner only contains partition columns\r\n          if (PartitionPruner.onlyContainsPartnCols(topToTable.get(ts),\r\n              opToPartPruner.get(ts))) {\r\n\r\n            PrunedPartitionList partsList = null;\r\n            try {\r\n              partsList = opToPartList.get(ts);\r\n              if (partsList == null) {\r\n                partsList = PartitionPruner.prune(topToTable.get(ts),\r\n                    opToPartPruner.get(ts), conf, (String) topOps.keySet()\r\n                    .toArray()[0], prunedPartitions);\r\n                opToPartList.put(ts, partsList);\r\n              }\r\n            } catch (HiveException e) {\r\n              // Has to use full name to make sure it does not conflict with\r\n              // org.apache.commons.lang.StringUtils\r\n              LOG.error(org.apache.hadoop.util.StringUtils.stringifyException(e));\r\n              throw new SemanticException(e.getMessage(), e);\r\n            }\r\n\r\n            // If there is any unknown partition, create a map-reduce job for\r\n            // the filter to prune correctly\r\n            if ((partsList.getUnknownPartns().size() == 0)) {\r\n              List<String> listP = new ArrayList<String>();\r\n              List<PartitionDesc> partP = new ArrayList<PartitionDesc>();\r\n\r\n              Set<Partition> parts = partsList.getConfirmedPartns();\r\n              Iterator<Partition> iterParts = parts.iterator();\r\n              while (iterParts.hasNext()) {\r\n                Partition part = iterParts.next();\r\n\r\n                listP.add(part.getPartitionPath().toString());\r\n                try {\r\n                  partP.add(Utilities.getPartitionDesc(part));\r\n                } catch (HiveException e) {\r\n                  throw new SemanticException(e.getMessage(), e);\r\n                }\r\n                inputs.add(new ReadEntity(part));\r\n              }\r\n\r\n              fetch = new FetchWork(listP, partP, qb.getParseInfo()\r\n                  .getOuterQueryLimit());\r\n              noMapRed = true;\r\n            }\r\n          }\r\n        }\r\n      }\r\n\r\n      if (noMapRed) {\r\n        if (fetch.getTblDesc() != null) {\r\n          PlanUtils.configureInputJobPropertiesForStorageHandler(\r\n            fetch.getTblDesc());\r\n        } else if ( (fetch.getPartDesc() != null) && (!fetch.getPartDesc().isEmpty())){\r\n            PartitionDesc pd0 = fetch.getPartDesc().get(0);\r\n            TableDesc td = pd0.getTableDesc();\r\n            if ((td != null)&&(td.getProperties() != null)\r\n                && td.getProperties().containsKey(\r\n                    org.apache.hadoop.hive.metastore.api.Constants.META_TABLE_STORAGE)){\r\n              PlanUtils.configureInputJobPropertiesForStorageHandler(td);\r\n            }\r\n        }\r\n        fetchTask = (FetchTask) TaskFactory.get(fetch, conf);\r\n        setFetchTask(fetchTask);\r\n\r\n        // remove root tasks if any\r\n        rootTasks.clear();\r\n        return;\r\n      }\r\n    }\r\n\r\n    // determine the query qualifies reduce input size for LIMIT\r\n    // The query only qualifies when there are only one top operator\r\n    // and there is no transformer or UDTF and no block sampling\r\n    // is used.\r\n    if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVELIMITOPTENABLE)\r\n        && ctx.getTryCount() == 0 && topOps.size() == 1\r\n        && !globalLimitCtx.ifHasTransformOrUDTF() &&\r\n        nameToSplitSample.isEmpty()) {\r\n\r\n      // Here we recursively check:\r\n      // 1. whether there are exact one LIMIT in the query\r\n      // 2. whether there is no aggregation, group-by, distinct, sort by,\r\n      //    distributed by, or table sampling in any of the sub-query.\r\n      // The query only qualifies if both conditions are satisfied.\r\n      //\r\n      // Example qualified queries:\r\n      //    CREATE TABLE ... AS SELECT col1, col2 FROM tbl LIMIT ..\r\n      //    INSERT OVERWRITE TABLE ... SELECT col1, hash(col2), split(col1)\r\n      //                               FROM ... LIMIT...\r\n      //    SELECT * FROM (SELECT col1 as col2 (SELECT * FROM ...) t1 LIMIT ...) t2);\r\n      //\r\n      Integer tempGlobalLimit = checkQbpForGlobalLimit(qb);\r\n\r\n      // query qualify for the optimization\r\n      if (tempGlobalLimit != null && tempGlobalLimit != 0)  {\r\n        TableScanOperator ts = (TableScanOperator) topOps.values().toArray()[0];\r\n        Table tab = topToTable.get(ts);\r\n\r\n        if (!tab.isPartitioned()) {\r\n          if (qbParseInfo.getDestToWhereExpr().isEmpty()) {\r\n            globalLimitCtx.enableOpt(tempGlobalLimit);\r\n          }\r\n        } else {\r\n          // check if the pruner only contains partition columns\r\n          if (PartitionPruner.onlyContainsPartnCols(tab,\r\n              opToPartPruner.get(ts))) {\r\n\r\n            PrunedPartitionList partsList = null;\r\n            try {\r\n              partsList = opToPartList.get(ts);\r\n              if (partsList == null) {\r\n                partsList = PartitionPruner.prune(tab,\r\n                    opToPartPruner.get(ts), conf, (String) topOps.keySet()\r\n                    .toArray()[0], prunedPartitions);\r\n                opToPartList.put(ts, partsList);\r\n              }\r\n            } catch (HiveException e) {\r\n              // Has to use full name to make sure it does not conflict with\r\n              // org.apache.commons.lang.StringUtils\r\n              LOG.error(org.apache.hadoop.util.StringUtils.stringifyException(e));\r\n              throw new SemanticException(e.getMessage(), e);\r\n            }\r\n\r\n            // If there is any unknown partition, create a map-reduce job for\r\n            // the filter to prune correctly\r\n            if ((partsList.getUnknownPartns().size() == 0)) {\r\n              globalLimitCtx.enableOpt(tempGlobalLimit);\r\n            }\r\n          }\r\n        }\r\n        if (globalLimitCtx.isEnable()) {\r\n          LOG.info(\"Qualify the optimize that reduces input size for \'limit\' for limit \"\r\n              + globalLimitCtx.getGlobalLimit());\r\n        }\r\n      }\r\n    }\r\n\r\n    // In case of a select, use a fetch task instead of a move task\r\n    if (qb.getIsQuery()) {\r\n      if ((!loadTableWork.isEmpty()) || (loadFileWork.size() != 1)) {\r\n        throw new SemanticException(ErrorMsg.GENERIC_ERROR.getMsg());\r\n      }\r\n      String cols = loadFileWork.get(0).getColumns();\r\n      String colTypes = loadFileWork.get(0).getColumnTypes();\r\n\r\n      String resFileFormat = HiveConf.getVar(conf, HiveConf.ConfVars.HIVEQUERYRESULTFILEFORMAT);\r\n      TableDesc resultTab = PlanUtils.getDefaultQueryOutputTableDesc(cols, colTypes, resFileFormat);\r\n\r\n      fetch = new FetchWork(new Path(loadFileWork.get(0).getSourceDir()).toString(),\r\n          resultTab, qb.getParseInfo().getOuterQueryLimit());\r\n\r\n      fetchTask = (FetchTask) TaskFactory.get(fetch, conf);\r\n      setFetchTask(fetchTask);\r\n\r\n      // For the FetchTask, the limit optimiztion requires we fetch all the rows\r\n      // in memory and count how many rows we get. It\'s not practical if the\r\n      // limit factor is too big\r\n      int fetchLimit = HiveConf.getIntVar(conf, HiveConf.ConfVars.HIVELIMITOPTMAXFETCH);\r\n      if (globalLimitCtx.isEnable() && globalLimitCtx.getGlobalLimit() > fetchLimit) {\r\n        LOG.info(\"For FetchTask, LIMIT \" + globalLimitCtx.getGlobalLimit() + \" > \" + fetchLimit\r\n            + \". Doesn\'t qualify limit optimiztion.\");\r\n        globalLimitCtx.disableOpt();\r\n      }\r\n\r\n    } else {\r\n      for (LoadTableDesc ltd : loadTableWork) {\r\n        Task<MoveWork> tsk = TaskFactory.get(new MoveWork(null, null, ltd, null, false),\r\n            conf);\r\n        mvTask.add(tsk);\r\n        // Check to see if we are stale\'ing any indexes and auto-update them if we want\r\n        if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVEINDEXAUTOUPDATE)) {\r\n          IndexUpdater indexUpdater = new IndexUpdater(loadTableWork, getInputs(), conf);\r\n          try {\r\n            List<Task<? extends Serializable>> indexUpdateTasks = indexUpdater.generateUpdateTasks();\r\n            for (Task<? extends Serializable> updateTask : indexUpdateTasks) {\r\n              tsk.addDependentTask(updateTask);\r\n            }\r\n          } catch (HiveException e) {\r\n            console.printInfo(\"WARNING: could not auto-update stale indexes, indexes are not in of sync\");\r\n          }\r\n        }\r\n      }\r\n\r\n\r\n      boolean oneLoadFile = true;\r\n      for (LoadFileDesc lfd : loadFileWork) {\r\n        if (qb.isCTAS()) {\r\n          assert (oneLoadFile); // should not have more than 1 load file for\r\n          // CTAS\r\n          // make the movetask\'s destination directory the table\'s destination.\r\n          String location = qb.getTableDesc().getLocation();\r\n          if (location == null) {\r\n            // get the table\'s default location\r\n            Table dumpTable;\r\n            Path targetPath;\r\n            try {\r\n              dumpTable = db.newTable(qb.getTableDesc().getTableName());\r\n              if (!db.databaseExists(dumpTable.getDbName())) {\r\n                throw new SemanticException(\"ERROR: The database \" + dumpTable.getDbName()\r\n                    + \" does not exist.\");\r\n              }\r\n              Warehouse wh = new Warehouse(conf);\r\n              targetPath = wh.getTablePath(db.getDatabase(dumpTable.getDbName()), dumpTable\r\n                  .getTableName());\r\n            } catch (HiveException e) {\r\n              throw new SemanticException(e);\r\n            } catch (MetaException e) {\r\n              throw new SemanticException(e);\r\n            }\r\n\r\n            location = targetPath.toString();\r\n          }\r\n          lfd.setTargetDir(location);\r\n\r\n          oneLoadFile = false;\r\n        }\r\n        mvTask.add(TaskFactory.get(new MoveWork(null, null, null, lfd, false),\r\n            conf));\r\n      }\r\n    }\r\n\r\n    // generate map reduce plans\r\n    ParseContext tempParseContext = getParseContext();\r\n    GenMRProcContext procCtx = new GenMRProcContext(\r\n        conf,\r\n        new HashMap<Operator<? extends Serializable>, Task<? extends Serializable>>(),\r\n        new ArrayList<Operator<? extends Serializable>>(), tempParseContext,\r\n        mvTask, rootTasks,\r\n        new LinkedHashMap<Operator<? extends Serializable>, GenMapRedCtx>(),\r\n        inputs, outputs);\r\n\r\n    // create a walker which walks the tree in a DFS manner while maintaining\r\n    // the operator stack.\r\n    // The dispatcher generates the plan from the operator tree\r\n    Map<Rule, NodeProcessor> opRules = new LinkedHashMap<Rule, NodeProcessor>();\r\n    opRules.put(new RuleRegExp(new String(\"R1\"), \"TS%\"), new GenMRTableScan1());\r\n    opRules.put(new RuleRegExp(new String(\"R2\"), \"TS%.*RS%\"),\r\n        new GenMRRedSink1());\r\n    opRules.put(new RuleRegExp(new String(\"R3\"), \"RS%.*RS%\"),\r\n        new GenMRRedSink2());\r\n    opRules.put(new RuleRegExp(new String(\"R4\"), \"FS%\"), new GenMRFileSink1());\r\n    opRules.put(new RuleRegExp(new String(\"R5\"), \"UNION%\"), new GenMRUnion1());\r\n    opRules.put(new RuleRegExp(new String(\"R6\"), \"UNION%.*RS%\"),\r\n        new GenMRRedSink3());\r\n    opRules.put(new RuleRegExp(new String(\"R6\"), \"MAPJOIN%.*RS%\"),\r\n        new GenMRRedSink4());\r\n    opRules.put(new RuleRegExp(new String(\"R7\"), \"TS%.*MAPJOIN%\"),\r\n        MapJoinFactory.getTableScanMapJoin());\r\n    opRules.put(new RuleRegExp(new String(\"R8\"), \"RS%.*MAPJOIN%\"),\r\n        MapJoinFactory.getReduceSinkMapJoin());\r\n    opRules.put(new RuleRegExp(new String(\"R9\"), \"UNION%.*MAPJOIN%\"),\r\n        MapJoinFactory.getUnionMapJoin());\r\n    opRules.put(new RuleRegExp(new String(\"R10\"), \"MAPJOIN%.*MAPJOIN%\"),\r\n        MapJoinFactory.getMapJoinMapJoin());\r\n    opRules.put(new RuleRegExp(new String(\"R11\"), \"MAPJOIN%SEL%\"),\r\n        MapJoinFactory.getMapJoin());\r\n\r\n    // The dispatcher fires the processor corresponding to the closest matching\r\n    // rule and passes the context along\r\n    Dispatcher disp = new DefaultRuleDispatcher(new GenMROperator(), opRules,\r\n        procCtx);\r\n\r\n    GraphWalker ogw = new GenMapRedWalker(disp);\r\n    ArrayList<Node> topNodes = new ArrayList<Node>();\r\n    topNodes.addAll(topOps.values());\r\n    ogw.startWalking(topNodes, null);\r\n\r\n    // reduce sink does not have any kids - since the plan by now has been\r\n    // broken up into multiple\r\n    // tasks, iterate over all tasks.\r\n    // For each task, go over all operators recursively\r\n    for (Task<? extends Serializable> rootTask : rootTasks) {\r\n      breakTaskTree(rootTask);\r\n    }\r\n\r\n    // For each task, set the key descriptor for the reducer\r\n    for (Task<? extends Serializable> rootTask : rootTasks) {\r\n      setKeyDescTaskTree(rootTask);\r\n    }\r\n\r\n    PhysicalContext physicalContext = new PhysicalContext(conf,\r\n        getParseContext(), ctx, rootTasks, fetchTask);\r\n    PhysicalOptimizer physicalOptimizer = new PhysicalOptimizer(\r\n        physicalContext, conf);\r\n    physicalOptimizer.optimize();\r\n\r\n    // For each operator, generate the counters if needed\r\n    if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.HIVEJOBPROGRESS)) {\r\n      for (Task<? extends Serializable> rootTask : rootTasks) {\r\n        generateCountersTask(rootTask);\r\n      }\r\n    }\r\n\r\n    decideExecMode(rootTasks, ctx, globalLimitCtx);\r\n\r\n    if (qb.isCTAS()) {\r\n      // generate a DDL task and make it a dependent task of the leaf\r\n      CreateTableDesc crtTblDesc = qb.getTableDesc();\r\n\r\n      validateCreateTable(crtTblDesc);\r\n\r\n      // Clear the output for CTAS since we don\'t need the output from the\r\n      // mapredWork, the\r\n      // DDLWork at the tail of the chain will have the output\r\n      getOutputs().clear();\r\n\r\n      Task<? extends Serializable> crtTblTask = TaskFactory.get(new DDLWork(\r\n          getInputs(), getOutputs(), crtTblDesc), conf);\r\n\r\n      // find all leaf tasks and make the DDLTask as a dependent task of all of\r\n      // them\r\n      HashSet<Task<? extends Serializable>> leaves = new HashSet<Task<? extends Serializable>>();\r\n      getLeafTasks(rootTasks, leaves);\r\n      assert (leaves.size() > 0);\r\n      for (Task<? extends Serializable> task : leaves) {\r\n        if (task instanceof StatsTask){\r\n          //StatsTask require table to already exist\r\n          for (Task<? extends Serializable> parentOfStatsTask : task.getParentTasks()){\r\n            parentOfStatsTask.addDependentTask(crtTblTask);\r\n          }\r\n          for (Task<? extends Serializable> parentOfCrtTblTask : crtTblTask.getParentTasks()){\r\n            parentOfCrtTblTask.removeDependentTask(task);\r\n          }\r\n          crtTblTask.addDependentTask(task);\r\n        } else {\r\n          task.addDependentTask(crtTblTask);\r\n        }\r\n      }\r\n    }\r\n\r\n    if (globalLimitCtx.isEnable() && fetchTask != null) {\r\n      int fetchLimit = HiveConf.getIntVar(conf, HiveConf.ConfVars.HIVELIMITOPTMAXFETCH);\r\n        LOG.info(\"set least row check for FetchTask: \" + globalLimitCtx.getGlobalLimit());\r\n        fetchTask.getWork().setLeastNumRows(globalLimitCtx.getGlobalLimit());\r\n    }\r\n\r\n    if (globalLimitCtx.isEnable() && globalLimitCtx.getLastReduceLimitDesc() != null) {\r\n      LOG.info(\"set least row check for LimitDesc: \" + globalLimitCtx.getGlobalLimit());\r\n      globalLimitCtx.getLastReduceLimitDesc().setLeastRows(globalLimitCtx.getGlobalLimit());\r\n      List<ExecDriver> mrTasks = Utilities.getMRTasks(rootTasks);\r\n      for (ExecDriver tsk : mrTasks) {\r\n        tsk.setRetryCmdWhenFail(true);\r\n      }\r\n    }\r\n  }','hive','Private Method','org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genMapRedTasks',0,4,'lm'),(9,'dt8.png','public ResolvedModuleRevision getDependency(DependencyDescriptor dd, ResolveData data)\r\n            throws ParseException {\r\n        IvyContext context = IvyContext.pushNewCopyContext();\r\n        try {\r\n            ResolvedModuleRevision mr = data.getCurrentResolvedModuleRevision();\r\n            if (mr != null) {\r\n                if (shouldReturnResolvedModule(dd, mr)) {\r\n                    return mr;\r\n                }\r\n            }\r\n            \r\n            if (isForce()) {\r\n                dd = dd.clone(ModuleRevisionId.newInstance(\r\n                    dd.getDependencyRevisionId(), \"latest.integration\"));\r\n            }\r\n            DependencyDescriptor systemDd = dd;\r\n            DependencyDescriptor nsDd = fromSystem(dd);\r\n            context.setDependencyDescriptor(systemDd);\r\n            context.setResolveData(data);\r\n            \r\n            clearIvyAttempts();\r\n            clearArtifactAttempts();\r\n            ModuleRevisionId systemMrid = systemDd.getDependencyRevisionId();\r\n            ModuleRevisionId nsMrid = nsDd.getDependencyRevisionId();\r\n            \r\n            checkRevision(systemMrid);\r\n\r\n            boolean isDynamic = getAndCheckIsDynamic(systemMrid);\r\n\r\n            // we first search for the dependency in cache\r\n            ResolvedModuleRevision rmr = null;\r\n            rmr = findModuleInCache(systemDd, data);\r\n            if (rmr != null) {\r\n                if (rmr.getDescriptor().isDefault() && rmr.getResolver() != this) {\r\n                    Message.verbose(\"\\t\" + getName() + \": found revision in cache: \" \r\n                        + systemMrid\r\n                        + \" (resolved by \" + rmr.getResolver().getName()\r\n                        + \"): but it\'s a default one, maybe we can find a better one\");\r\n                } else if (isForce() && rmr.getResolver() != this) {\r\n                    Message.verbose(\"\\t\" + getName() + \": found revision in cache: \" \r\n                        + systemMrid\r\n                        + \" (resolved by \" + rmr.getResolver().getName()\r\n                        + \"): but we are in force mode, let\'s try to find one ourself\");\r\n                } else {\r\n                    Message.verbose(\"\\t\" + getName() + \": revision in cache: \" + systemMrid);\r\n                    return checkLatest(systemDd, checkForcedResolvedModuleRevision(rmr), data);\r\n                }\r\n            }\r\n            \r\n            checkInterrupted();\r\n            \r\n            ResolvedResource ivyRef = findIvyFileRef(nsDd, data);\r\n            checkInterrupted();\r\n\r\n            // get module descriptor\r\n            ModuleDescriptor nsMd;\r\n            ModuleDescriptor systemMd = null;\r\n            if (ivyRef == null) {\r\n                if (!isAllownomd()) {\r\n                    throw new UnresolvedDependencyException(\r\n                        \"\\t\" + getName() + \": no ivy file found for \" + systemMrid, false);\r\n                }\r\n                nsMd = DefaultModuleDescriptor.newDefaultInstance(nsMrid, nsDd\r\n                    .getAllDependencyArtifacts());\r\n                ResolvedResource artifactRef = findFirstArtifactRef(nsMd, nsDd, data);\r\n                checkInterrupted();\r\n                if (artifactRef == null) {\r\n                    throw new UnresolvedDependencyException(\"\\t\" + getName() \r\n                        + \": no ivy file nor artifact found for \" + systemMrid, false);\r\n                } else {\r\n                    long lastModified = artifactRef.getLastModified();\r\n                    if (lastModified != 0 && nsMd instanceof DefaultModuleDescriptor) {\r\n                        ((DefaultModuleDescriptor) nsMd).setLastModified(lastModified);\r\n                    }\r\n                    Message.verbose(\"\\t\" + getName() + \": no ivy file found for \" + systemMrid\r\n                        + \": using default data\");\r\n                    if (isDynamic) {\r\n                        nsMd.setResolvedModuleRevisionId(ModuleRevisionId.newInstance(nsMrid,\r\n                            artifactRef.getRevision()));\r\n                    }\r\n                    systemMd = toSystem(nsMd);\r\n                    MetadataArtifactDownloadReport madr = \r\n                        new MetadataArtifactDownloadReport(systemMd.getMetadataArtifact());\r\n                    madr.setDownloadStatus(DownloadStatus.NO);\r\n                    madr.setSearched(true);\r\n                    rmr = new ResolvedModuleRevision(this, this, systemMd, madr, isForce());\r\n                }\r\n            } else {\r\n                if (ivyRef instanceof MDResolvedResource) {\r\n                    rmr = ((MDResolvedResource) ivyRef).getResolvedModuleRevision();\r\n                }\r\n                if (rmr == null) {\r\n                    rmr = parse(ivyRef, systemDd, data);\r\n                    if (rmr == null) {\r\n                        throw new UnresolvedDependencyException();\r\n                    }\r\n                }\r\n                if (!rmr.getReport().isDownloaded() \r\n                        && rmr.getReport().getLocalFile() != null) {\r\n                    return checkLatest(systemDd, checkForcedResolvedModuleRevision(rmr), data);\r\n                } else {\r\n                    nsMd = rmr.getDescriptor();\r\n\r\n                    // check descriptor data is in sync with resource revision and names\r\n                    systemMd = toSystem(nsMd);\r\n                    if (isCheckconsistency()) {\r\n                        checkDescriptorConsistency(systemMrid, systemMd, ivyRef);\r\n                        checkDescriptorConsistency(nsMrid, nsMd, ivyRef);\r\n                    } else {\r\n                        if (systemMd instanceof DefaultModuleDescriptor) {\r\n                            DefaultModuleDescriptor defaultMd = (DefaultModuleDescriptor) systemMd;\r\n                            ModuleRevisionId revision = getRevision(ivyRef, systemMrid, systemMd);\r\n                            defaultMd.setModuleRevisionId(revision);\r\n                            defaultMd.setResolvedModuleRevisionId(revision);\r\n                        } else {\r\n                            Message.warn(\r\n                              \"consistency disabled with instance of non DefaultModuleDescriptor...\"\r\n                              + \" module info can\'t be updated, so consistency check will be done\");\r\n                            checkDescriptorConsistency(nsMrid, nsMd, ivyRef);\r\n                            checkDescriptorConsistency(systemMrid, systemMd, ivyRef);\r\n                        }\r\n                    }\r\n                    rmr = new ResolvedModuleRevision(\r\n                        this, this, systemMd, toSystem(rmr.getReport()), isForce());\r\n                }\r\n            }\r\n\r\n            resolveAndCheckRevision(systemMd, systemMrid, ivyRef, isDynamic);\r\n            resolveAndCheckPublicationDate(systemDd, systemMd, systemMrid, data);\r\n            checkNotConvertedExclusionRule(systemMd, ivyRef, data);\r\n\r\n            cacheModuleDescriptor(systemMd, systemMrid, ivyRef, rmr);            \r\n            \r\n            return checkLatest(systemDd, checkForcedResolvedModuleRevision(rmr), data);\r\n        } catch (UnresolvedDependencyException ex) {\r\n            if (ex.getMessage().length() > 0) {\r\n                if (ex.isError()) {\r\n                    Message.error(ex.getMessage());\r\n                } else {\r\n                    Message.verbose(ex.getMessage());\r\n                }\r\n            }\r\n            return data.getCurrentResolvedModuleRevision();\r\n        } finally {\r\n            IvyContext.popContext();\r\n        }\r\n    }','ivy','Public Method','org.apache.ivy.plugins.resolver.BasicResolver.getDependency',0,7,'lm'),(10,'dt9.png','public boolean check(List<LogicalOperator> nodes) throws OptimizerException {\r\n        try {\r\n            LOFilter filter = (LOFilter) getOperator(nodes);\r\n            List<LogicalOperator> predecessors = (mPlan.getPredecessors(filter) == null ? null\r\n                    : new ArrayList<LogicalOperator>(mPlan\r\n                            .getPredecessors(filter)));\r\n\r\n            // if there are no predecessors return false\r\n            if (predecessors == null) {\r\n                return false;\r\n            }\r\n\r\n            // if the filter has no predecessors or more than one predecessor\r\n            // return false\r\n            if (predecessors.size() == 0 || predecessors.size() > 1) {\r\n                return false;\r\n            }\r\n                \r\n            LogicalOperator predecessor = predecessors.get(0);\r\n\r\n            // if the predecessor is one of LOLoad/LOStore/LOStream/LOLimit/LONative\r\n            // return false\r\n            if (predecessor instanceof LOLoad || predecessor instanceof LOStore\r\n                    || predecessor instanceof LOStream\r\n                    || predecessor instanceof LOLimit \r\n                    || predecessor instanceof LONative) {\r\n                return false;\r\n            }\r\n            \r\n            // TODO\r\n            // for now filters cannot be combined\r\n            // remove this check when filters can be combined\r\n            if (predecessor instanceof LOFilter)\r\n                return false;\r\n\r\n            // TODO\r\n            // same rule as filters\r\n            if (predecessor instanceof LOSplitOutput) {\r\n                return false;\r\n            }\r\n            if (predecessor instanceof LOSplit) {\r\n                return false;\r\n            }\r\n\r\n            UDFFinder udfFinder = new UDFFinder(filter.getComparisonPlan());\r\n            udfFinder.visit();\r\n\r\n            // if the filter\'s inner plan contains any UDF then return false\r\n            if (udfFinder.foundAnyUDF()) {\r\n                return false;\r\n            }\r\n\r\n            CastFinder castFinder = new CastFinder(filter.getComparisonPlan());\r\n            castFinder.visit();\r\n\r\n            // if the filter\'s inner plan contains any casts then return false\r\n            if (castFinder.foundAnyCast()) {\r\n                return false;\r\n            }\r\n\r\n            List<RequiredFields> filterRequiredFields = filter\r\n                    .getRequiredFields();\r\n            if (filterRequiredFields == null) {\r\n                return false;\r\n            }\r\n            RequiredFields requiredField = filterRequiredFields.get(0);\r\n\r\n            // the filter\'s conditions contain constant expression\r\n            // return false\r\n            if (requiredField.needNoFields()) {\r\n                return false;\r\n            }\r\n\r\n            // if the predecessor is a multi-input operator then detailed\r\n            // checks are required\r\n            if (predecessor instanceof LOCross\r\n                    || predecessor instanceof LOUnion\r\n                    || predecessor instanceof LOCogroup\r\n                    || predecessor instanceof LOJoin) {\r\n\r\n                // check if the filter\'s required fields in conjunction with the\r\n                // predecessor\'s projection map. If the filter needs more than\r\n                // one input then the filter\'s expressions have to be split\r\n\r\n                List<LogicalOperator> grandParents = mPlan\r\n                        .getPredecessors(predecessor);\r\n\r\n                // if the predecessor does not have predecessors return false\r\n                if (grandParents == null || grandParents.size() == 0) {\r\n                    return false;\r\n                }\r\n                \r\n                // check if the predecessor is a group by\r\n                if (grandParents.size() == 1) {\r\n                    if (predecessor instanceof LOCogroup) {\r\n                        mSwap = true;\r\n                        return true;\r\n                    } else {\r\n                        // only a group by can have a single input\r\n                        return false;\r\n                    }\r\n                }\r\n\r\n                if (requiredField.needAllFields()) {\r\n                    return false;\r\n                }\r\n\r\n                Pair<Boolean, Set<Integer>> mappingResult = isRequiredFieldMapped(requiredField, predecessor.getProjectionMap());\r\n                boolean mapped = mappingResult.first;\r\n                Set<Integer> grandParentIndexes = mappingResult.second;\r\n                if (!mapped) {\r\n                    return false;\r\n                }\r\n                \r\n                // TODO\r\n                // the filter\'s conditions requires more than one input of its\r\n                // predecessor\r\n                // when the filter\'s conditions are splittable return true\r\n                if ((grandParentIndexes == null)\r\n                        || (grandParentIndexes.size() == 0)\r\n                        || (grandParentIndexes.size() > 1)) {\r\n                    return false;\r\n                }\r\n\r\n                if (predecessor instanceof LOCogroup) {\r\n                    // check for outer\r\n                    if (isAnyOuter((LOCogroup) predecessor)) {\r\n                        return false;\r\n                    }\r\n                }\r\n                \r\n                mPushBeforeInput = grandParentIndexes.iterator().next();\r\n                \r\n                if (predecessor instanceof LOJoin) {\r\n                    boolean otherBranchContainOuter = false;\r\n                    boolean sawInner = false;\r\n                    for (int i=0;i<=mPlan.getSuccessors(predecessor).size();i++) {\r\n                        // We do not push filter if any other branch is outer\r\n                        // See PIG-1289\r\n                        // Also in LOJoin, innerFlag==true indicate that branch is the outer join side\r\n                        // which has the exact opposite semantics\r\n                        // If all innerFlag is true, that implies a regular join\r\n                        // If all innerFlag is false, means a outer join, in this case, we can not push up filter for any path (See PIG-1507)\r\n                        if (i!=mPushBeforeInput && ((LOJoin)predecessor).getInnerFlags()[i]) {\r\n                            otherBranchContainOuter = true;\r\n                        }\r\n                        if (((LOJoin)predecessor).getInnerFlags()[i]==false) {\r\n                            sawInner = true;\r\n                        }\r\n                    }\r\n                    if (!otherBranchContainOuter && ((LOJoin)predecessor).getInnerFlags()[mPushBeforeInput]==false) // all innerFlag is false, implies an outer join\r\n                    {\r\n                        mPushBeforeInput = -1;\r\n                        return false;\r\n                    }\r\n                    if (otherBranchContainOuter && sawInner) // If it is not a regular join and the path we push is on inner side\r\n                    {\r\n                        mPushBeforeInput = -1;\r\n                        return false;\r\n                    }\r\n                }\r\n                \r\n                mPushBefore = true;\r\n                return true;\r\n\r\n            } else if (predecessor instanceof LOForEach) {\r\n\r\n                LOForEach loForEach = (LOForEach) predecessor;\r\n                List<Boolean> mFlatten = loForEach.getFlatten();\r\n                boolean hasFlatten = false;\r\n                for (Boolean b : mFlatten) {\r\n                    if (b.equals(true)) {\r\n                        hasFlatten = true;\r\n                    }\r\n                }\r\n\r\n                // TODO\r\n                // A better check is to examine each column in the filter\'s\r\n                // required fields. If the column is the result of a flatten\r\n                // then\r\n                // return false else return true\r\n\r\n                // for now if the foreach has a flatten then return false\r\n                if (hasFlatten) {\r\n                    return false;\r\n                }\r\n\r\n                Pair<Boolean, Set<Integer>> mappingResult = isRequiredFieldMapped(requiredField, predecessor.getProjectionMap());\r\n                boolean mapped = mappingResult.first;\r\n                \r\n                // Check if it is a direct mapping, that is, project optionally followed by cast, so if project->project, it is not\r\n                // considered as a mapping\r\n                for (Pair<Integer, Integer> pair : requiredField.getFields())\r\n                {\r\n                    if (!isFieldSimple(loForEach.getForEachPlans().get(pair.second)))\r\n                    {\r\n                        mapped = false;\r\n                        break;\r\n                    }\r\n                }\r\n                \r\n                if (!mapped) {\r\n                    return false;\r\n                }\r\n            }\r\n\r\n            mSwap = true;\r\n            return true;\r\n        } catch (OptimizerException oe) {\r\n            throw oe;\r\n        } catch (Exception e) {\r\n            int errCode = 2149;\r\n            String msg = \"Internal error while trying to check if filters can be pushed up.\";\r\n            throw new OptimizerException(msg, errCode, PigException.BUG, e);\r\n        }\r\n    }','pig','Public Method','org.apache.pig.impl.logicalLayer.optimizer.PushUpFilter.check',0,10,'lm'),(11,'dt10.png','public CrawlDatum distributeScoreToOutlink(Text fromUrl, Text toUrl, ParseData parseData, CrawlDatum target, CrawlDatum adjust, int allCount, int validCount) throws ScoringFilterException {\r\n    return adjust;\r\n  }','nutch','Public Method','org.apache.nutch.scoring.tld.TLDScoringFilter.distributeScoreToOutlink',0,4,'lpl'),(12,'dt11.png','public BenchmarkResults benchmark(int seeds, int depth, int threads, int maxPerHost,\r\n        long topN, boolean delete, String plugins) throws Exception {\r\n    Configuration conf = getConf();\r\n    conf.set(\"http.proxy.host\", \"localhost\");\r\n    conf.setInt(\"http.proxy.port\", 8181);\r\n    conf.set(\"http.agent.name\", \"test\");\r\n    conf.set(\"http.robots.agents\", \"test,*\");\r\n    if (!plugins.equals(\"default\")) {\r\n      conf.set(\"plugin.includes\", plugins);\r\n    }\r\n    conf.setInt(Generator.GENERATOR_MAX_COUNT, maxPerHost);\r\n    conf.set(Generator.GENERATOR_COUNT_MODE, Generator.GENERATOR_COUNT_VALUE_HOST);\r\n    JobConf job = new NutchJob(getConf());    \r\n    FileSystem fs = FileSystem.get(job);\r\n    Path dir = new Path(getConf().get(\"hadoop.tmp.dir\"),\r\n            \"bench-\" + System.currentTimeMillis());\r\n    fs.mkdirs(dir);\r\n    Path rootUrlDir = new Path(dir, \"seed\");\r\n    fs.mkdirs(rootUrlDir);\r\n    createSeeds(fs, rootUrlDir, seeds);\r\n\r\n    if (LOG.isInfoEnabled()) {\r\n      LOG.info(\"crawl started in: \" + dir);\r\n      LOG.info(\"rootUrlDir = \" + rootUrlDir);\r\n      LOG.info(\"threads = \" + threads);\r\n      LOG.info(\"depth = \" + depth);      \r\n    }\r\n    BenchmarkResults res = new BenchmarkResults();\r\n    res.delete = delete;\r\n    res.depth = depth;\r\n    res.plugins = plugins;\r\n    res.seeds = seeds;\r\n    res.threads = threads;\r\n    res.topN = topN;\r\n    Path crawlDb = new Path(dir + \"/crawldb\");\r\n    Path linkDb = new Path(dir + \"/linkdb\");\r\n    Path segments = new Path(dir + \"/segments\");\r\n    res.elapsed = System.currentTimeMillis();\r\n    Injector injector = new Injector(getConf());\r\n    Generator generator = new Generator(getConf());\r\n    Fetcher fetcher = new Fetcher(getConf());\r\n    ParseSegment parseSegment = new ParseSegment(getConf());\r\n    CrawlDb crawlDbTool = new CrawlDb(getConf());\r\n    LinkDb linkDbTool = new LinkDb(getConf());\r\n      \r\n    // initialize crawlDb\r\n    long start = System.currentTimeMillis();\r\n    injector.inject(crawlDb, rootUrlDir);\r\n    long delta = System.currentTimeMillis() - start;\r\n    res.addTiming(\"inject\", \"0\", delta);\r\n    int i;\r\n    for (i = 0; i < depth; i++) {             // generate new segment\r\n      start = System.currentTimeMillis();\r\n      Path[] segs = generator.generate(crawlDb, segments, -1, topN, System\r\n          .currentTimeMillis());\r\n      delta = System.currentTimeMillis() - start;\r\n      res.addTiming(\"generate\", i + \"\", delta);\r\n      if (segs == null) {\r\n        LOG.info(\"Stopping at depth=\" + i + \" - no more URLs to fetch.\");\r\n        break;\r\n      }\r\n      start = System.currentTimeMillis();\r\n      fetcher.fetch(segs[0], threads);  // fetch it\r\n      delta = System.currentTimeMillis() - start;\r\n      res.addTiming(\"fetch\", i + \"\", delta);\r\n      if (!Fetcher.isParsing(job)) {\r\n        start = System.currentTimeMillis();\r\n        parseSegment.parse(segs[0]);    // parse it, if needed\r\n        delta = System.currentTimeMillis() - start;\r\n        res.addTiming(\"parse\", i + \"\", delta);\r\n      }\r\n      start = System.currentTimeMillis();\r\n      crawlDbTool.update(crawlDb, segs, true, true); // update crawldb\r\n      delta = System.currentTimeMillis() - start;\r\n      res.addTiming(\"update\", i + \"\", delta);\r\n      start = System.currentTimeMillis();\r\n      linkDbTool.invert(linkDb, segs, true, true, false); // invert links\r\n      delta = System.currentTimeMillis() - start;\r\n      res.addTiming(\"invert\", i + \"\", delta);\r\n      // delete data\r\n      if (delete) {\r\n        for (Path p : segs) {\r\n          fs.delete(p, true);\r\n        }\r\n      }\r\n    }\r\n    if (i == 0) {\r\n      LOG.warn(\"No URLs to fetch - check your seed list and URL filters.\");\r\n    }\r\n    if (LOG.isInfoEnabled()) { LOG.info(\"crawl finished: \" + dir); }\r\n    res.elapsed = System.currentTimeMillis() - res.elapsed;\r\n    CrawlDbReader dbreader = new CrawlDbReader();\r\n    dbreader.processStatJob(crawlDb.toString(), conf, false);\r\n    return res;\r\n  }','nutch','Public Method','org.apache.nutch.tools.Benchmark.benchmark',0,7,'lpl'),(13,'dt12.png','public FSDataOutputStream create(Path f, FsPermission permission,\r\n      boolean overwrite, int bufferSize, short replication, long blockSize,\r\n      Progressable progress) throws IOException {\r\n    return super.create(swizzleParamPath(f), permission,\r\n        overwrite, bufferSize, replication, blockSize, progress);\r\n  }','hive','Public Method','org.apache.hadoop.fs.ProxyFileSystem.create',0,10,'lpl');
/*!40000 ALTER TABLE `ms_dtModel` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Dumping data for table `ms_dtModel_tasks`
--

LOCK TABLES `ms_dtModel_tasks` WRITE;
/*!40000 ALTER TABLE `ms_dtModel_tasks` DISABLE KEYS */;
INSERT INTO `ms_dtModel_tasks` VALUES (3,2,1),(4,2,2),(5,3,1),(6,3,2),(7,4,1),(8,4,2),(9,5,1),(10,5,2),(11,6,1),(12,6,2),(13,7,1),(14,7,2),(15,8,1),(16,8,2),(17,9,1),(18,9,2),(19,10,1),(20,10,2),(21,11,1),(22,11,2),(23,12,1),(24,12,2),(25,13,1),(26,13,2);
/*!40000 ALTER TABLE `ms_dtModel_tasks` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Dumping data for table `ms_task`
--

LOCK TABLES `ms_task` WRITE;
/*!40000 ALTER TABLE `ms_task` DISABLE KEYS */;
INSERT INTO `ms_task` VALUES (1,'Task1','ID',1),(2,'Task2','CC',2);
/*!40000 ALTER TABLE `ms_task` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2019-12-04 13:08:31
